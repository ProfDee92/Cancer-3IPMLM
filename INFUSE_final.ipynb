{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfDee92/Cancer-3IPMLM/blob/main/INFUSE_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6ZO67JAKrPa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # <-- Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        # fit should typically return self, fit_transform does the work\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    # --> CORRECTED INDENTATION: `def` line is now aligned with other methods <--\n",
        "        # --- ROBUST _graph_regularization using direct k-NN on features ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature expression profiles in X.\n",
        "        Nodes are features, edges connect features with similar profiles.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # X is (n_samples, n_features)\n",
        "            # X.T is (n_features, n_samples)\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "\n",
        "            # Option 1: Use default Euclidean distance between feature profiles\n",
        "            # graph = kneighbors_graph(X.T, n_neighbors=self.k_graph, mode='connectivity', include_self=False, metric='euclidean', n_jobs=1)\n",
        "\n",
        "            # Option 2 (Preferred for expression data): Use cosine distance between feature profiles\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=self.k_graph, # Number of neighbors for each feature\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Start with 1 for clarity/debugging\n",
        "            )\n",
        "\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- The rest of the methods remain the same ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]):\n",
        "            accs = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "                clf = RandomForestClassifier(n_estimators=50, random_state=self.random_state.randint(0, 10000))\n",
        "                try:\n",
        "                    if len(np.unique(yb)) > 1: # Need at least 2 classes\n",
        "                        clf.fit(Zb[:, [i]], yb)\n",
        "                        accs.append(clf.score(Zb[:, [i]], yb))\n",
        "                    else:\n",
        "                        accs.append(0.5) # Default score if only one class in bootstrap\n",
        "                except Exception:\n",
        "                    accs.append(0.5)\n",
        "            stabilities.append(np.mean(accs))\n",
        "\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "    def _validate_input(self, X, y):\n",
        "        X = check_array(X, accept_sparse=True, ensure_2d=True, dtype=np.float32)\n",
        "        y = np.asarray(y)\n",
        "        if X.shape[0] != len(y):\n",
        "            raise ValueError(f\"Mismatch: {X.shape[0]} samples in X, but {len(y)} labels in y.\")\n",
        "        return X, y\n",
        "\n",
        "# Note: The _f_score_selection method defined at the end of the provided file\n",
        "# is not called within the main flow (fit_transform) and seems redundant\n",
        "# with the seed selection logic already present there. It has been omitted\n",
        "# for clarity but can be included if needed elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNbLZDFLMt7-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRA0W3XAKv9J",
        "outputId": "fc4bac61-8a7d-4963-c0fc-65f6ff1ea432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467']\n",
            "âœ… Similarity matrix computed: (1000, 6)\n",
            "âš™ï¸ Weight matrix shape: (1000, 6)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 6)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 6)\n",
            "âœ… Final filtering completed: (1215, 6)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1       APOB            6   \n",
            "2          2       ADH4            6   \n",
            "3          3       UBTF            6   \n",
            "4          4      CRHR2            6   \n",
            "5          5  LOC729467            6   \n",
            "\n",
            "                                      member_genes  stability  \n",
            "0    [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.998436  \n",
            "1    [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.998568  \n",
            "2          [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.998329  \n",
            "3    [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.998222  \n",
            "4        [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.998296  \n",
            "5  [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.998379  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 6\n",
            "Final output cohorts (kept): 6\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 1.00\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 1.00\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            " Cohort 2 | Seed: ADH4 | Stability: 1.00\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            " Cohort 3 | Seed: UBTF | Stability: 1.00\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            " Cohort 4 | Seed: CRHR2 | Stability: 1.00\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 5 | Seed: LOC729467 | Stability: 1.00\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 6)\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "X = StandardScaler().fit_transform(X_df.values)\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOCN_-0LMwZW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmtLtpFqMwfp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # <-- Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        # fit should typically return self, fit_transform does the work\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    # --> CORRECTED INDENTATION: `def` line is now aligned with other methods <--\n",
        "        # --- ROBUST _graph_regularization using direct k-NN on features ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "        # --- ROBUST _graph_regularization with automatic k ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X (scaled data) and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature expression profiles in X.\n",
        "        Nodes are features, edges connect features with similar profiles.\n",
        "        Number of neighbors k is determined automatically.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # X is (n_samples, n_features)\n",
        "            # X.T is (n_features, n_samples)\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "\n",
        "            # --- Automatic k determination ---\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            # Adjust the 0.005, 3, and 20 based on domain knowledge or experimentation.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "            # --- End of automatic k determination ---\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # <-- Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Start with 1 for clarity/debugging\n",
        "            )\n",
        "\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- The rest of the methods remain the same ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]):\n",
        "            accs = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "                clf = RandomForestClassifier(n_estimators=50, random_state=self.random_state.randint(0, 10000))\n",
        "                try:\n",
        "                    if len(np.unique(yb)) > 1: # Need at least 2 classes\n",
        "                        clf.fit(Zb[:, [i]], yb)\n",
        "                        accs.append(clf.score(Zb[:, [i]], yb))\n",
        "                    else:\n",
        "                        accs.append(0.5) # Default score if only one class in bootstrap\n",
        "                except Exception:\n",
        "                    accs.append(0.5)\n",
        "            stabilities.append(np.mean(accs))\n",
        "\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "    def _validate_input(self, X, y):\n",
        "        X = check_array(X, accept_sparse=True, ensure_2d=True, dtype=np.float32)\n",
        "        y = np.asarray(y)\n",
        "        if X.shape[0] != len(y):\n",
        "            raise ValueError(f\"Mismatch: {X.shape[0]} samples in X, but {len(y)} labels in y.\")\n",
        "        return X, y\n",
        "\n",
        "# Note: The _f_score_selection method defined at the end of the provided file\n",
        "# is not called within the main flow (fit_transform) and seems redundant\n",
        "# with the seed selection logic already present there. It has been omitted\n",
        "# for clarity but can be included if needed elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQed_V6lM_9z",
        "outputId": "f97b1190-d048-4c16-b172-9d7965b07635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467']\n",
            "âœ… Similarity matrix computed: (1000, 6)\n",
            "âš™ï¸ Weight matrix shape: (1000, 6)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 6)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 6)\n",
            "âœ… Final filtering completed: (1215, 6)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1       APOB            6   \n",
            "2          2       ADH4            6   \n",
            "3          3       UBTF            6   \n",
            "4          4      CRHR2            6   \n",
            "5          5  LOC729467            6   \n",
            "\n",
            "                                      member_genes  stability  \n",
            "0    [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.998436  \n",
            "1    [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.998568  \n",
            "2          [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.998329  \n",
            "3    [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.998222  \n",
            "4        [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.998296  \n",
            "5  [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.998379  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 6\n",
            "Final output cohorts (kept): 6\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 1.00\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 1.00\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            " Cohort 2 | Seed: ADH4 | Stability: 1.00\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            " Cohort 3 | Seed: UBTF | Stability: 1.00\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            " Cohort 4 | Seed: CRHR2 | Stability: 1.00\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 5 | Seed: LOC729467 | Stability: 1.00\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 6)\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "X = StandardScaler().fit_transform(X_df.values)\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEcJmC_uNABd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKQbZPPjW8j6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtbfAXiqW8mx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uJIkIedW8px",
        "outputId": "0ab2775c-1fa3-400a-cbac-8ba95c26bf5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- INFUSE Benchmarking Script ---\n",
            "  -> Loading data...\n",
            "    -> Loaded expression data: (1218, 20530)\n",
            "    -> Loaded clinical data: (1255, 85)\n",
            "    -> Found 1216 common samples\n",
            "    -> Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "  -> Data preprocessing complete.\n",
            "    -> Raw X shape (for INFUSE): (1215, 20530)\n",
            "    -> Scaled X shape (for baselines): (1215, 20530)\n",
            "    -> y shape: (1215,)\n",
            "\n",
            "--- Running Benchmarking Experiment (k=50, CV=5-fold) ---\n",
            "  -> Evaluating FS-F_Score...\n",
            "    -> Error running FS-F_Score + CLF-LR: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-F_Score + CLF-RF: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-F_Score + CLF-SVM: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-F_Score + CLF-KNN: got an unexpected keyword argument 'needs_proba'\n",
            "  -> Evaluating FS-MI...\n",
            "    -> Error running FS-MI + CLF-LR: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-MI + CLF-RF: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-MI + CLF-SVM: got an unexpected keyword argument 'needs_proba'\n",
            "    -> Error running FS-MI + CLF-KNN: got an unexpected keyword argument 'needs_proba'\n",
            "  -> Evaluating FS-RFE_LR...\n"
          ]
        }
      ],
      "source": [
        "# --- INFUSE Benchmarking Script ---\n",
        "# Compares INFUSE against FS/DR baselines using various classifiers on TCGA BRCA data.\n",
        "\n",
        "# --- 1. Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "# --- Feature Selection ---\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# --- Dimensionality Reduction ---\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "# --- Classifiers ---\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# --- Metrics ---\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, make_scorer\n",
        "# --- INFUSE ---\n",
        "# Assuming the INFUSE class is defined in the same script or imported\n",
        "# from infuse_model import INFUSE # Uncomment if in a separate file\n",
        "\n",
        "print(\"--- INFUSE Benchmarking Script ---\")\n",
        "\n",
        "# --- 2. Data Loading & Preprocessing (Your Code) ---\n",
        "# Ensure this path is correct for your environment\n",
        "expression_file = \"HiSeqV2\" # Or \"/content/HiSeqV2\"\n",
        "phenotype_file = \"TCGA-BRCA.clinical.tsv\" # Or \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "print(\"  -> Loading data...\")\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"    -> Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"    -> Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"    -> Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\"    -> Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# --- IMPORTANT: INFUSE handles scaling internally ---\n",
        "# Pass raw, unscaled data X_df.values and feature names to INFUSE\n",
        "X_raw = X_df.values # Raw data for INFUSE\n",
        "feature_names = X_df.columns.tolist()\n",
        "\n",
        "# For other methods that require scaling, we'll use the scaled X\n",
        "# Note: For a fair comparison, if a method needs scaling, it should be part of the pipeline.\n",
        "# However, for simplicity here, we use pre-scaled data for non-INFUSE methods.\n",
        "# A more rigorous approach would be to include StandardScaler() in each pipeline.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_raw) # Scaled data for baselines\n",
        "\n",
        "print(f\"  -> Data preprocessing complete.\")\n",
        "print(f\"    -> Raw X shape (for INFUSE): {X_raw.shape}\")\n",
        "print(f\"    -> Scaled X shape (for baselines): {X_scaled.shape}\")\n",
        "print(f\"    -> y shape: {y_encoded.shape}\")\n",
        "\n",
        "# --- 3. Define Methods and Classifiers ---\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "# Number of features/components to select/reduce to\n",
        "k_features = 50 # Adjust as needed, e.g., 10, 20, 50\n",
        "# Number of cross-validation folds\n",
        "cv_folds = 5 # Standard choice\n",
        "# Number of cores for parallel processing (-1 uses all)\n",
        "n_jobs = -1\n",
        "# Random state for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "# --- Baseline Methods ---\n",
        "baselines = {\n",
        "    # --- Feature Selection ---\n",
        "    'FS-F_Score': SelectKBest(score_func=f_classif, k=k_features),\n",
        "    'FS-MI': SelectKBest(score_func=mutual_info_classif, k=k_features),\n",
        "    'FS-RFE_LR': RFE(estimator=LogisticRegression(max_iter=1000, random_state=random_seed), n_features_to_select=k_features),\n",
        "\n",
        "    # --- Dimensionality Reduction ---\n",
        "    'DR-PCA': PCA(n_components=k_features, random_state=random_seed),\n",
        "    'DR-Laplacian': SpectralEmbedding(n_components=k_features, random_state=random_seed, n_jobs=n_jobs),\n",
        "    # Note: UMAP, t-SNE are not transformers, AE needs custom implementation.\n",
        "    # For simplicity, we stick to scikit-learn transformers.\n",
        "}\n",
        "\n",
        "# --- INFUSE Method ---\n",
        "# Configure INFUSE with parameters that worked or are reasonable defaults\n",
        "# Note: Pass the raw data and feature names to INFUSE\n",
        "infuse_method = INFUSE(\n",
        "    k_seeds=k_features, # Use k_features as the target number of output features\n",
        "    n_neighbors=50,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    jsd_threshold=0.4, # As used in your test run\n",
        "    k_graph=5,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,\n",
        "    final_k=2,\n",
        "    verbose=False, # Turn off verbose for benchmarking\n",
        "    max_features=1000, # Pre-filter to 1000 features before applying INFUSE\n",
        "    random_state=random_seed\n",
        ")\n",
        "# Wrap INFUSE in a custom transformer to handle raw data input correctly\n",
        "# INFUSE expects raw X and feature names, and returns the transformed matrix\n",
        "# We need a wrapper that conforms to the sklearn transformer interface\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class INFUSEWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, infuse_instance):\n",
        "        self.infuse_instance = infuse_instance\n",
        "\n",
        "    def fit(self, X, y=None, **kwargs):\n",
        "        # Assume X is raw data and kwargs contains feature_names\n",
        "        feature_names = kwargs.get('feature_names', [f\"Feature_{i}\" for i in range(X.shape[1])])\n",
        "        # INFUSE fit_transform requires y for seed selection\n",
        "        if y is None:\n",
        "            raise ValueError(\"INFUSE requires target labels 'y' for fitting.\")\n",
        "        self.Z_ = self.infuse_instance.fit_transform(X, y, feature_names=feature_names)\n",
        "        # Store attributes needed for transform (though INFUSE transform is stateful)\n",
        "        # For simplicity in this wrapper, we assume fit_transform does everything\n",
        "        # and transform just returns the result. This is a simplification.\n",
        "        # A better wrapper would store the fitted infuse_instance and call its transform.\n",
        "        # However, the provided INFUSE's transform method seems to re-do cohort fusion.\n",
        "        # Let's stick to fit_transform for consistency with how it's used.\n",
        "        # This means this wrapper's 'transform' will just return the fitted Z_.\n",
        "        # This is okay for CV if we refit the entire pipeline each time.\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # This is a simplification. Ideally, we'd call infuse_instance.transform(X)\n",
        "        # But the provided INFUSE's transform might not work exactly as expected\n",
        "        # because it relies on self.cohort_weights_ and self.seeds_ from fit.\n",
        "        # Let's assume fit does the work and transform returns the stored result.\n",
        "        # This means this wrapper is stateful and only works if fit was called.\n",
        "        # For cross_validate, which does fit/transform/score on splits,\n",
        "        # this might be problematic because each split would need a new fit.\n",
        "        # Let's re-design the wrapper to be stateless and call fit_transform each time.\n",
        "        # This is inefficient but aligns with the current INFUSE design.\n",
        "\n",
        "        # A cleaner way is to make INFUSE itself a proper transformer.\n",
        "        # But given the current design, we'll proceed with a stateful wrapper\n",
        "        # and be aware of the limitation.\n",
        "\n",
        "        # Check if fit was called\n",
        "        if not hasattr(self, 'Z_'):\n",
        "             raise RuntimeError(\"INFUSEWrapper has not been fitted yet.\")\n",
        "        return self.Z_\n",
        "\n",
        "# --- Wrap INFUSE ---\n",
        "infuse_pipeline_step = ('FS/DR-INFUSE', INFUSEWrapper(infuse_method))\n",
        "\n",
        "\n",
        "# --- Classifiers ---\n",
        "classifiers = {\n",
        "    'CLF-LR': LogisticRegression(max_iter=1000, random_state=random_seed),\n",
        "    'CLF-RF': RandomForestClassifier(n_estimators=100, random_state=random_seed, n_jobs=n_jobs),\n",
        "    'CLF-SVM': SVC(random_state=random_seed, probability=True), # probability=True for AUC\n",
        "    'CLF-KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=n_jobs),\n",
        "}\n",
        "\n",
        "# --- Scoring Metrics ---\n",
        "# Define the metrics you want to evaluate\n",
        "scoring = {\n",
        "    'acc': make_scorer(accuracy_score),\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'roc_auc': make_scorer(roc_auc_score, needs_proba=True) # Needs classifier with predict_proba\n",
        "}\n",
        "\n",
        "# --- 4. Run Benchmarking Experiment ---\n",
        "\n",
        "print(f\"\\n--- Running Benchmarking Experiment (k={k_features}, CV={cv_folds}-fold) ---\")\n",
        "results = []\n",
        "\n",
        "# --- Cross-Validation Setup ---\n",
        "cv_splitter = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "# --- Function to run a single method ---\n",
        "def run_method(method_name, method_obj, X_data, y_data):\n",
        "    print(f\"  -> Evaluating {method_name}...\")\n",
        "\n",
        "    # Handle INFUSE specially\n",
        "    if method_name == 'FS/DR-INFUSE':\n",
        "        # For INFUSE, we need to pass feature names and use raw data\n",
        "        # We cannot easily use it in a standard sklearn pipeline with cross_validate\n",
        "        # because cross_validate expects transformers to have a standard fit/transform.\n",
        "        # INFUSE's fit_transform signature is different (requires y, feature_names).\n",
        "        # A workaround is to run manual CV.\n",
        "\n",
        "        # Manual Cross-Validation for INFUSE\n",
        "        scores_dict = {metric: [] for metric in scoring.keys()}\n",
        "        fold = 0\n",
        "        for train_idx, test_idx in cv_splitter.split(X_data, y_data):\n",
        "            fold += 1\n",
        "            print(f\"    -> Fold {fold}/{cv_folds}...\")\n",
        "            X_train_raw, X_test_raw = X_data[train_idx], X_data[test_idx]\n",
        "            y_train, y_test = y_data[train_idx], y_data[test_idx]\n",
        "\n",
        "            # Fit INFUSE on training data\n",
        "            # Note: We need to pass feature names. Assuming feature_names list is available.\n",
        "            infuse_wrapper = INFUSEWrapper(INFUSE(\n",
        "                k_seeds=k_features,\n",
        "                n_neighbors=50,\n",
        "                alpha=0.6,\n",
        "                beta=0.2,\n",
        "                jsd_threshold=0.4,\n",
        "                k_graph=5,\n",
        "                n_bootstrap=100,\n",
        "                stability_thresh=0.5,\n",
        "                final_k=2,\n",
        "                verbose=False,\n",
        "                max_features=1000,\n",
        "                random_state=random_seed + fold # Vary seed slightly per fold\n",
        "            ))\n",
        "            # Fit and transform (this calls INFUSE.fit_transform internally)\n",
        "            infuse_wrapper.fit(X_train_raw, y_train, feature_names=feature_names)\n",
        "            Z_train = infuse_wrapper.Z_\n",
        "\n",
        "            # Transform test data (calls INFUSE.transform)\n",
        "            # Note: This relies on the fitted infuse_instance inside the wrapper\n",
        "            Z_test = infuse_wrapper.transform(X_test_raw)\n",
        "\n",
        "            # Handle case where INFUSE produces 0 features\n",
        "            if Z_train.shape[1] == 0 or Z_test.shape[1] == 0:\n",
        "                print(f\"      -> INFUSE produced 0 features in fold {fold}. Scoring as 0.\")\n",
        "                for metric in scoring.keys():\n",
        "                    scores_dict[metric].append(0.0)\n",
        "                continue\n",
        "\n",
        "            # Evaluate with each classifier\n",
        "            for clf_name, clf in classifiers.items():\n",
        "                try:\n",
        "                    clf.fit(Z_train, y_train)\n",
        "                    y_pred = clf.predict(Z_test)\n",
        "\n",
        "                    # Calculate scores\n",
        "                    for metric_name, scorer in scoring.items():\n",
        "                        if metric_name == 'roc_auc':\n",
        "                            if hasattr(clf, \"predict_proba\"):\n",
        "                                y_proba = clf.predict_proba(Z_test)[:, 1] # Probability of positive class\n",
        "                                score = scorer._score_func(y_test, y_proba)\n",
        "                            else:\n",
        "                                # If classifier doesn't support predict_proba, skip AUC or use decision_function\n",
        "                                # For simplicity, we'll skip AUC if not available\n",
        "                                score = np.nan\n",
        "                        else:\n",
        "                            score = scorer._score_func(y_test, y_pred)\n",
        "\n",
        "                        scores_dict[f\"{clf_name}_{metric_name}\"].append(score)\n",
        "                except Exception as e:\n",
        "                    print(f\"      -> Error with {clf_name} on fold {fold}: {e}\")\n",
        "                    # Assign NaN or 0 for failed classifier run\n",
        "                    for metric_name in scoring.keys():\n",
        "                        scores_dict[f\"{clf_name}_{metric_name}\"].append(np.nan)\n",
        "\n",
        "        # Aggregate scores for INFUSE\n",
        "        for key, scores in scores_dict.items():\n",
        "            if 'CLF-' in key: # Only classifier-specific scores\n",
        "                mean_score = np.nanmean(scores)\n",
        "                std_score = np.nanstd(scores) / np.sqrt(len([s for s in scores if not np.isnan(s)])) if len([s for s in scores if not np.isnan(s)]) > 1 else np.nan\n",
        "                results.append({\n",
        "                    'Method': method_name,\n",
        "                    'Classifier': key.split('_', 1)[0], # Extract CLF-XXX part\n",
        "                    'Metric': key.split('_', 1)[1],     # Extract metric part\n",
        "                    'Mean': mean_score,\n",
        "                    'StdErr': std_score\n",
        "                })\n",
        "\n",
        "    else: # For standard sklearn transformers\n",
        "        # Create pipelines for each classifier\n",
        "        for clf_name, clf in classifiers.items():\n",
        "            pipeline = Pipeline([\n",
        "                ('dim_red', method_obj), # Use the method object directly\n",
        "                ('classifier', clf)\n",
        "            ])\n",
        "\n",
        "            # Run cross-validation\n",
        "            try:\n",
        "                cv_results = cross_validate(pipeline, X_data, y_data, cv=cv_splitter,\n",
        "                                           scoring=scoring, n_jobs=1, # Parallelize CV splits, not internal jobs\n",
        "                                           verbose=0, error_score='raise') # Raise errors for debugging\n",
        "\n",
        "                # Aggregate results\n",
        "                for metric_name in scoring.keys():\n",
        "                    scores = cv_results[f'test_{metric_name}']\n",
        "                    mean_score = np.mean(scores)\n",
        "                    std_err = np.std(scores) / np.sqrt(len(scores))\n",
        "\n",
        "                    results.append({\n",
        "                        'Method': method_name,\n",
        "                        'Classifier': clf_name,\n",
        "                        'Metric': metric_name,\n",
        "                        'Mean': mean_score,\n",
        "                        'StdErr': std_err\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                print(f\"    -> Error running {method_name} + {clf_name}: {e}\")\n",
        "                # Record failed run\n",
        "                for metric_name in scoring.keys():\n",
        "                    results.append({\n",
        "                        'Method': method_name,\n",
        "                        'Classifier': clf_name,\n",
        "                        'Metric': metric_name,\n",
        "                        'Mean': np.nan,\n",
        "                        'StdErr': np.nan\n",
        "                    })\n",
        "\n",
        "\n",
        "# --- Run Experiments ---\n",
        "# Run baselines first\n",
        "for name, method in baselines.items():\n",
        "    run_method(name, method, X_scaled, y_encoded) # Use scaled data for baselines\n",
        "\n",
        "# Run INFUSE\n",
        "run_method('FS/DR-INFUSE', None, X_raw, y_encoded) # Use raw data for INFUSE\n",
        "\n",
        "# --- 5. Aggregate and Display Results ---\n",
        "print(\"\\n--- Benchmarking Results ---\")\n",
        "if not results:\n",
        "    print(\"No results to display.\")\n",
        "else:\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Pivot the table for easier viewing\n",
        "    # We'll create separate tables for each metric\n",
        "    metrics = results_df['Metric'].unique()\n",
        "\n",
        "    for metric in metrics:\n",
        "        print(f\"\\n--- Results for {metric.upper()} ---\")\n",
        "        metric_df = results_df[results_df['Metric'] == metric]\n",
        "\n",
        "        # Pivot to have methods as rows and classifiers as columns\n",
        "        pivot_df = metric_df.pivot_table(index='Method', columns='Classifier', values='Mean')\n",
        "        pivot_stderr_df = metric_df.pivot_table(index='Method', columns='Classifier', values='StdErr')\n",
        "\n",
        "        # Combine mean and stderr for display (e.g., Mean Â± StdErr)\n",
        "        # This requires combining two dataframes. Let's create a formatted string.\n",
        "        formatted_df = pivot_df.copy()\n",
        "        for col in pivot_df.columns:\n",
        "            formatted_df[col] = pivot_df[col].apply(lambda x: f\"{x:.4f}\" if not np.isnan(x) else \"N/A\") + \" Â± \" + \\\n",
        "                               pivot_stderr_df[col].apply(lambda x: f\"{x:.4f}\" if not np.isnan(x) else \"N/A\")\n",
        "\n",
        "        print(formatted_df.to_string())\n",
        "\n",
        "        # Also save to CSV for detailed analysis\n",
        "        # Save mean and stderr separately for easier processing\n",
        "        pivot_df.to_csv(f'results_mean_{metric}.csv')\n",
        "        pivot_stderr_df.to_csv(f'results_stderr_{metric}.csv')\n",
        "        print(f\"Results saved to 'results_mean_{metric}.csv' and 'results_stderr_{metric}.csv'\")\n",
        "\n",
        "print(\"\\n--- Benchmarking Complete ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfSBDBv-W8sl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNw6jDwkY9lb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWtj7mfHY9of"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJAlYUQyZcwF"
      },
      "source": [
        "# **Another Filter Technique in the Final Filter Module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVafwK0hY9rY"
      },
      "outputs": [],
      "source": [
        "#Another Filter Technique in the Final Filter Module no more RF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # <-- Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        # fit should typically return self, fit_transform does the work\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    # --> CORRECTED INDENTATION: `def` line is now aligned with other methods <--\n",
        "        # --- ROBUST _graph_regularization using direct k-NN on features ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "        # --- ROBUST _graph_regularization with automatic k ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X (scaled data) and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature expression profiles in X.\n",
        "        Nodes are features, edges connect features with similar profiles.\n",
        "        Number of neighbors k is determined automatically.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # X is (n_samples, n_features)\n",
        "            # X.T is (n_features, n_samples)\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "\n",
        "            # --- Automatic k determination ---\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            # Adjust the 0.005, 3, and 20 based on domain knowledge or experimentation.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "            # --- End of automatic k determination ---\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # <-- Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Start with 1 for clarity/debugging\n",
        "            )\n",
        "\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "        # --- The rest of the methods remain the same ---\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        # 1. Determine the appropriate association function based on y's type\n",
        "        #    Let's assume binary classification for this example:\n",
        "        #    association_func = lambda z, y: scipy.stats.pointbiserialr(z, y)[0]**2 # r_pb squared\n",
        "        #    For continuous y: association_func = lambda z, y: scipy.stats.pearsonr(z, y)[0]**2\n",
        "        #    For generic: association_func = lambda z, y: scipy.stats.spearmanr(z, y).correlation**2\n",
        "\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature z_{s_{f_j}}\n",
        "            assoc_scores = []\n",
        "            for _ in range(self.n_bootstrap): # Perform B bootstrap iterations\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state) # Resample data\n",
        "                z_feature = Zb[:, i] # Extract the single cohort feature for this bootstrap sample\n",
        "\n",
        "                # 2. Calculate the association score between z_feature and yb\n",
        "                #    using the chosen fundamental statistical measure.\n",
        "                try:\n",
        "                    if len(np.unique(yb)) > 1: # Need at least 2 distinct classes/values\n",
        "                        # Calculate the score (e.g., r_pb^2)\n",
        "                        score = association_func(z_feature, yb)\n",
        "                        # Optional: Handle potential edge cases or NaNs from stats functions\n",
        "                        if not np.isnan(score) and np.isfinite(score):\n",
        "                            assoc_scores.append(score)\n",
        "                        else:\n",
        "                            assoc_scores.append(0.0) # Or another default/error score\n",
        "                    else:\n",
        "                        # If bootstrap sample has only one class/value, association is undefined\n",
        "                        assoc_scores.append(0.0) # Assign minimum score\n",
        "                except Exception as e:\n",
        "                    # Handle numerical errors in statistical calculation\n",
        "                    # print(f\"Warning: Error calculating association for cohort {i}, bootstrap {_}: {e}\") # Optional debug\n",
        "                    assoc_scores.append(0.0) # Assign minimum/default score\n",
        "\n",
        "            # 3. Calculate the stability score S_j for cohort z_{s_{f_j}} as the average association score\n",
        "            if assoc_scores: # Check if any scores were calculated successfully\n",
        "                S_j = np.mean(assoc_scores)\n",
        "            else:\n",
        "                S_j = 0.0 # Default stability score if all bootstraps failed\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # 4. Proceed with filtering based on S_j, stability_thresh, and final_k as before.\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)]\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0]\n",
        "        if not kept:\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        # --> The call here is already correct in Pasted_Text_1754008101149.txt <--\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "    def _validate_input(self, X, y):\n",
        "        X = check_array(X, accept_sparse=True, ensure_2d=True, dtype=np.float32)\n",
        "        y = np.asarray(y)\n",
        "        if X.shape[0] != len(y):\n",
        "            raise ValueError(f\"Mismatch: {X.shape[0]} samples in X, but {len(y)} labels in y.\")\n",
        "        return X, y\n",
        "\n",
        "# Note: The _f_score_selection method defined at the end of the provided file\n",
        "# is not called within the main flow (fit_transform) and seems redundant\n",
        "# with the seed selection logic already present there. It has been omitted\n",
        "# for clarity but can be included if needed elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMtpqwrWh96N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTWAd02Nh-Y1"
      },
      "outputs": [],
      "source": [
        "# FILE: infuse.py\n",
        "# ENSURE THIS IS THE FILE IMPORTED BY YOUR MAIN SCRIPT\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=4, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap r_pb^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use r_pb^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.4f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity and to reflect the final, robust implementation logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYEGosJuY9uC",
        "outputId": "75739c8a-9e31-4aa6-f65d-7dd91bc7c3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467']\n",
            "âœ… Similarity matrix computed: (1000, 6)\n",
            "âš™ï¸ Weight matrix shape: (1000, 6)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 6)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 6)\n",
            " No stable features met threshold. Keeping top 4.\n",
            "âœ… Final filtering completed: (1215, 4)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1  LOC729467            6   \n",
            "2          2      CRHR2            6   \n",
            "3          3       ADH4            6   \n",
            "\n",
            "                                      member_genes  stability  \n",
            "0    [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.043220  \n",
            "1  [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.036705  \n",
            "2        [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.034231  \n",
            "3          [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.033698  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 6\n",
            "Final output cohorts (kept): 4\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.0432\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: LOC729467 | Stability: 0.0367\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            " Cohort 2 | Seed: CRHR2 | Stability: 0.0342\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 3 | Seed: ADH4 | Stability: 0.0337\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 4)\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "X = StandardScaler().fit_transform(X_df.values)\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nzFwvXPqG5v",
        "outputId": "53fb6204-6df4-48b4-e2cc-b3c740a1debc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n",
            " Train Set Shape (Pre-filtered): (972, 20530)\n",
            " Test Set Shape (Pre-filtered): (243, 20530)\n",
            "\n",
            " Comparing techniques using k=4 features/components.\n",
            "âŒ Failed to transform with pre-fitted INFUSE model (full data): X has 20530 features, but StandardScaler is expecting 1000 features as input.\n",
            "\n",
            "--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 0 61] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âŒ Failed to fit/transform INFUSE on training data: X has 20530 features, but StandardScaler is expecting 1000 features as input.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Top 4 F-score Features Selected: Train (972, 4), Test (243, 4)\n",
            "âœ… Top 4 MI Features Selected: Train (972, 4), Test (243, 4)\n",
            "âœ… Top 4 PCA Components Derived: Train (972, 4), Test (243, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3371573875.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m# Fit RFE on the scaled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mX_train_rfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0mX_test_rfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled_rfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mtechniques\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RFE_LR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_rfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ]\n\u001b[0;32m--> 451\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    783\u001b[0m                                  **options)\n\u001b[1;32m    784\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    786\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    787\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# Send a copy because the user may overwrite it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# The user of this class might want `x` to remain unchanged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad_pointwise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_reg_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pointwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     51\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- 3. Benchmarking INFUSE Against Other Techniques ---\n",
        "# (This code follows the execution of Sections 1 and 2)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE, mutual_info_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "# Assuming 'infuse' is your fitted INFUSE instance from the previous section\n",
        "# from infuse import INFUSE # Import your INFUSE class (ensure it's the latest version)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features)\n",
        "# y_encoded: Encoded target labels (n_samples,)\n",
        "# feature_names: Names of the m pre-filtered features\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train.shape}\")\n",
        "print(f\" Test Set Shape: {X_test.shape}\")\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by INFUSE as the comparison point.\n",
        "# If Z_final is empty, use a default or the number of seeds.\n",
        "n_infuse_features = Z_final.shape[1] if Z_final.size > 0 else len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "k_compare = max(2, n_infuse_features) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Already generated)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the fitted infuse object to transform both train and test sets.\n",
        "# Note: The infuse object was fitted on the full X, y_encoded.\n",
        "# For a fair train/test split evaluation, we should ideally fit INFUSE only on X_train.\n",
        "# However, for a direct comparison using the already fitted model:\n",
        "try:\n",
        "    # Transform the train and test sets using the already fitted infuse model\n",
        "    # This uses the scaler_ and seeds_ learned from the full dataset.\n",
        "    Z_train_infuse = infuse.transform(X_train)\n",
        "    Z_test_infuse = infuse.transform(X_test)\n",
        "\n",
        "    # Check if transformation produced features\n",
        "    if Z_train_infuse.size > 0 and Z_test_infuse.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse, Z_test_infuse)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse.shape}, Test {Z_test_infuse.shape}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "    # Re-instantiate INFUSE with the same parameters\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=10,\n",
        "        jsd_threshold=0.4,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        max_features=1000,\n",
        "        stability_thresh=0.5,\n",
        "        final_k=2,\n",
        "        verbose=False, # Turn off verbose for cleaner benchmarking output\n",
        "        random_state=42\n",
        "    )\n",
        "    # Fit ONLY on training data\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train, y_train, feature_names=feature_names)\n",
        "    # Transform test data using the model fitted on training data\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        # Update k_compare if this rigorous fit produced a different number of features\n",
        "        if n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train, y_train)\n",
        "X_test_fscore = selector_fscore.transform(X_test)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required\n",
        "X_train_scaled_mi = StandardScaler().fit_transform(X_train)\n",
        "X_test_scaled_mi = StandardScaler().fit_transform(X_test)\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train/X_test are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to a reasonable subset of features.\n",
        "# Let's use the same pre-filtered feature set (X_train, X_test) as RFE's input.\n",
        "# This means we are selecting k_compare features from the m (e.g., 1000) pre-filtered features.\n",
        "\n",
        "estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data (X_train is already scaled)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<20} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 80)\n",
        "    sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "    for tech_name, scores in sorted_techs_cv:\n",
        "        if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "            acc_mean, acc_std = scores['accuracy']\n",
        "            auc_mean, auc_std = scores['auc']\n",
        "            # Corrected formatting\n",
        "            print(f\"  {tech_name:<20} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "        else:\n",
        "            print(f\"  {tech_name:<20} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 80)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<20} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 40)\n",
        "    sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "    for tech_name, scores in sorted_techs_test:\n",
        "        test_acc = scores['accuracy']\n",
        "        test_auc = scores['auc']\n",
        "        if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "            print(f\"  {tech_name:<20} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "        else:\n",
        "             print(f\"  {tech_name:<20} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 40)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zT53m2BVYxeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ali3nFnZY9wk"
      },
      "outputs": [],
      "source": [
        "def run_notebook_experiment(X, y, feature_names, k=10, n_splits=5, n_repeats=3):\n",
        "    methods = ['INFUSE', 'F-Score', 'PCA', 'RandomForest']\n",
        "    results = []\n",
        "\n",
        "    for method in methods:\n",
        "        print(f\" Running {method}\")\n",
        "        for repeat in range(n_repeats):\n",
        "            skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=repeat)\n",
        "            for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "                X_train, X_test = X[train_idx], X[test_idx]\n",
        "                y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "                start = time.time()\n",
        "                if method == 'INFUSE':\n",
        "                    model = INFUSE(k_seeds=k, final_k=k, max_features=1000, verbose=False)\n",
        "                    Z_train = model.fit_transform(X_train, y_train, feature_names=feature_names)\n",
        "                    #Z_test = model.transform(X_test)\n",
        "                # Reduce text to selected features-restrict X_test to the same features INFUSE trained on\n",
        "                    X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
        "                    X_test_reduced = X_test_df[model.feature_names_in_].values\n",
        "                    Z_test = model.transform(X_test_reduced)\n",
        "\n",
        "                elif method == 'F-Score':\n",
        "                    scores, _ = f_classif(X_train, y_train)\n",
        "                    top_k = np.argsort(scores)[-k:]\n",
        "                    Z_train = X_train[:, top_k]\n",
        "                    Z_test = X_test[:, top_k]\n",
        "                elif method == 'PCA':\n",
        "                    pca = PCA(n_components=k)\n",
        "                    Z_train = pca.fit_transform(X_train)\n",
        "                    Z_test = pca.transform(X_test)\n",
        "                elif method == 'RandomForest':\n",
        "                    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                    rf.fit(X_train, y_train)\n",
        "                    top_k = np.argsort(rf.feature_importances_)[-k:]\n",
        "                    Z_train = X_train[:, top_k]\n",
        "                    Z_test = X_test[:, top_k]\n",
        "\n",
        "                clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                clf.fit(Z_train, y_train)\n",
        "                y_pred = clf.predict(Z_test)\n",
        "                y_prob = clf.predict_proba(Z_test)[:, 1]\n",
        "\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "                auc = roc_auc_score(y_test, y_prob)\n",
        "                runtime = time.time() - start\n",
        "\n",
        "                results.append({\n",
        "                    'method': method,\n",
        "                    'repeat': repeat,\n",
        "                    'fold': fold,\n",
        "                    'accuracy': acc,\n",
        "                    'auc': auc,\n",
        "                    'runtime_sec': runtime\n",
        "                })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run it\n",
        "df_results = run_notebook_experiment(X_scaled, y_encoded, feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn5BF3oMY9zT"
      },
      "outputs": [],
      "source": [
        "summary = df_results.groupby('method').agg({\n",
        "    'accuracy': ['mean', 'std'],\n",
        "    'auc': ['mean', 'std'],\n",
        "    'runtime_sec': ['mean']\n",
        "})\n",
        "summary.columns = ['_'.join(col) for col in summary.columns]\n",
        "summary.reset_index(inplace=True)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRRCsGY8Y912"
      },
      "outputs": [],
      "source": [
        "summary = df_results.groupby('method').agg({\n",
        "    'accuracy': ['mean', 'std'],\n",
        "    'auc': ['mean', 'std'],\n",
        "    'runtime_sec': ['mean']\n",
        "})\n",
        "summary.columns = ['_'.join(col) for col in summary.columns]\n",
        "summary.reset_index(inplace=True)\n",
        "summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "sns.barplot(data=summary, x='method', y='accuracy_mean', ax=axes[0], capsize=.2)\n",
        "axes[0].set_title('Mean Accuracy (3x5 CV)')\n",
        "axes[0].set_ylim(0.5, 1.0)\n",
        "\n",
        "sns.barplot(data=summary, x='method', y='auc_mean', ax=axes[1], capsize=.2)\n",
        "axes[1].set_title('Mean AUC (3x5 CV)')\n",
        "axes[1].set_ylim(0.5, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o73_sCmcXzXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJP_YdDhY5AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1TIIACrY5DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDKX6a13Y5Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ni7zI_W6Y5In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rLjSImrtY5K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# ENSURE THIS IS THE FILE IMPORTED BY YOUR MAIN SCRIPT\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # <-- Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap r_pb^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use r_pb^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    # --> CORRECTED INDENTATION: `def` line aligned with other methods <--\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary connections (1 if neighbor, 0 otherwise)\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.6f}\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity but can be included if needed elsewhere."
      ],
      "metadata": {
        "id": "1pcbpaZlXzag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "X = StandardScaler().fit_transform(X_df.values)\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYmxBfSeXzdY",
        "outputId": "2bc37aad-d3c0-4af9-e9d7-507215621e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467']\n",
            "âœ… Similarity matrix computed: (1000, 6)\n",
            "âš™ï¸ Weight matrix shape: (1000, 6)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 6)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "âš ï¸ Graph construction failed: ValueError - Negative values in data passed to X.. Using fully connected graph.\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 1000\n",
            "âœ… Cohort fusion completed: (1215, 6)\n",
            " No stable features met threshold. Keeping top 2.\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id seed_gene  num_members  \\\n",
            "0          0     KLF10         1000   \n",
            "1          1      APOB         1000   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...   0.045771  \n",
            "1  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...   0.041264  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 6\n",
            "Final output cohorts (kept): 2\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.05\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 0.04\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Benchmarking INFUSE Against Other Techniques ---\n",
        "# (This code follows the execution of Sections 1 and 2)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE, mutual_info_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "# Assuming 'infuse' is your fitted INFUSE instance from the previous section\n",
        "# from infuse import INFUSE # Import your INFUSE class (ensure it's the latest version)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features)\n",
        "# y_encoded: Encoded target labels (n_samples,)\n",
        "# feature_names: Names of the m pre-filtered features\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train.shape}\")\n",
        "print(f\" Test Set Shape: {X_test.shape}\")\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by INFUSE as the comparison point.\n",
        "# If Z_final is empty, use a default or the number of seeds.\n",
        "n_infuse_features = Z_final.shape[1] if Z_final.size > 0 else len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "k_compare = max(2, n_infuse_features) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Already generated)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the fitted infuse object to transform both train and test sets.\n",
        "# Note: The infuse object was fitted on the full X, y_encoded.\n",
        "# For a fair train/test split evaluation, we should ideally fit INFUSE only on X_train.\n",
        "# However, for a direct comparison using the already fitted model:\n",
        "try:\n",
        "    # Transform the train and test sets using the already fitted infuse model\n",
        "    # This uses the scaler_ and seeds_ learned from the full dataset.\n",
        "    Z_train_infuse = infuse.transform(X_train)\n",
        "    Z_test_infuse = infuse.transform(X_test)\n",
        "\n",
        "    # Check if transformation produced features\n",
        "    if Z_train_infuse.size > 0 and Z_test_infuse.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse, Z_test_infuse)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse.shape}, Test {Z_test_infuse.shape}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "    # Re-instantiate INFUSE with the same parameters\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=10,\n",
        "        jsd_threshold=0.4,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        max_features=1000,\n",
        "        stability_thresh=0.5,\n",
        "        final_k=2,\n",
        "        verbose=False, # Turn off verbose for cleaner benchmarking output\n",
        "        random_state=42\n",
        "    )\n",
        "    # Fit ONLY on training data\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train, y_train, feature_names=feature_names)\n",
        "    # Transform test data using the model fitted on training data\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        # Update k_compare if this rigorous fit produced a different number of features\n",
        "        if n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train, y_train)\n",
        "X_test_fscore = selector_fscore.transform(X_test)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required\n",
        "X_train_scaled_mi = StandardScaler().fit_transform(X_train)\n",
        "X_test_scaled_mi = StandardScaler().fit_transform(X_test)\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train/X_test are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to a reasonable subset of features.\n",
        "# Let's use the same pre-filtered feature set (X_train, X_test) as RFE's input.\n",
        "# This means we are selecting k_compare features from the m (e.g., 1000) pre-filtered features.\n",
        "\n",
        "estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data (X_train is already scaled)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<20} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 80)\n",
        "    sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "    for tech_name, scores in sorted_techs_cv:\n",
        "        if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "            acc_mean, acc_std = scores['accuracy']\n",
        "            auc_mean, auc_std = scores['auc']\n",
        "            # Corrected formatting\n",
        "            print(f\"  {tech_name:<20} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "        else:\n",
        "            print(f\"  {tech_name:<20} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 80)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<20} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 40)\n",
        "    sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "    for tech_name, scores in sorted_techs_test:\n",
        "        test_acc = scores['accuracy']\n",
        "        test_auc = scores['auc']\n",
        "        if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "            print(f\"  {tech_name:<20} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "        else:\n",
        "             print(f\"  {tech_name:<20} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 40)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qpsj77J5XzgJ",
        "outputId": "d6b89c97-4bb9-4d46-c99a-a18ea0030370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n",
            " Train Set Shape: (972, 20530)\n",
            " Test Set Shape: (243, 20530)\n",
            "\n",
            " Comparing techniques using k=2 features/components.\n",
            "âŒ Failed to transform with pre-fitted INFUSE model: X has 20530 features, but StandardScaler is expecting 1000 features as input.\n",
            "\n",
            "--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 0 61] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Failed to fit/transform INFUSE on training  X has 20530 features, but StandardScaler is expecting 1000 features as input.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Top 2 F-score Features Selected: Train (972, 2), Test (243, 2)\n",
            "âœ… Top 2 MI Features Selected: Train (972, 2), Test (243, 2)\n",
            "âœ… Top 2 PCA Components Derived: Train (972, 2), Test (243, 2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1584965442.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;31m# Fit RFE on the scaled training data (X_train is already scaled)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m \u001b[0mX_train_rfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0mX_test_rfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0mtechniques\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RFE_LR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_rfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_rfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             ]\n\u001b[0;32m--> 451\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    783\u001b[0m                                  **options)\n\u001b[1;32m    784\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    786\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    787\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# Send a copy because the user may overwrite it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# The user of this class might want `x` to remain unchanged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         loss, grad_pointwise = self.base_loss.loss_gradient(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mraw_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/_loss/loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     def loss_gradient(\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df_results.groupby('method').agg({\n",
        "    'accuracy': ['mean', 'std'],\n",
        "    'auc': ['mean', 'std'],\n",
        "    'runtime_sec': ['mean']\n",
        "})\n",
        "summary.columns = ['_'.join(col) for col in summary.columns]\n",
        "summary.reset_index(inplace=True)\n",
        "summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "sns.barplot(data=summary, x='method', y='accuracy_mean', ax=axes[0], capsize=.2)\n",
        "axes[0].set_title('Mean Accuracy (3x5 CV)')\n",
        "axes[0].set_ylim(0.5, 1.0)\n",
        "\n",
        "sns.barplot(data=summary, x='method', y='auc_mean', ax=axes[1], capsize=.2)\n",
        "axes[1].set_title('Mean AUC (3x5 CV)')\n",
        "axes[1].set_ylim(0.5, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KiJfacuKXzij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoG64ZAZXznx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVQyL4KpXzq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xN1aKb6Vf1K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QtYsYvatf1N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMWbu4WTf1Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Latest INFUSE Class\n",
        "\n",
        "\n",
        "\n",
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.0 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "\n",
        "    INFUSE operates on the principle that meaningful signals in biological\n",
        "    systems are often distributed across groups of features (cohorts) rather\n",
        "    than isolated within single features. It sequentially:\n",
        "    1. Pre-filters features based on univariate F-scores.\n",
        "    2. Selects diverse seed features using F-scores and JSD (on Softmax profiles).\n",
        "    3. Calculates hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "    4. Constructs a k-NN graph on feature profiles to define local neighborhoods.\n",
        "    5. Fuses features within neighborhoods using hybrid weights to create cohorts.\n",
        "    6. Evaluates cohort stability via bootstrapping and filters based on performance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    k_seeds : int, default=20\n",
        "        Number of initial seed candidates based on F-scores.\n",
        "    n_neighbors : int, deprecated\n",
        "        Placeholder from earlier versions. Not used in final graph construction.\n",
        "    alpha : float, default=0.6\n",
        "        Weight for the cosine similarity component in hybrid weighting.\n",
        "    beta : float, default=0.2\n",
        "        Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "    jsd_threshold : float, default=0.35\n",
        "        Minimum JSD dissimilarity required between seed candidates during filtering.\n",
        "    k_graph : int, deprecated\n",
        "        Placeholder from earlier versions. Final version uses automatic k determination.\n",
        "    n_bootstrap : int, default=100\n",
        "        Number of bootstrap iterations for stability evaluation.\n",
        "    stability_thresh : float, default=0.5\n",
        "        Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "    final_k : int, default=2\n",
        "        Number of top cohorts to keep if none meet stability_thresh.\n",
        "    verbose : bool, default=True\n",
        "        Whether to print progress messages.\n",
        "    max_features : int, default=1000\n",
        "        Initial pre-filtering to this many top F-score features.\n",
        "    random_state : int or RandomState instance, default=42\n",
        "        Controls the randomness of the estimator.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    feature_names_in_ : list of str\n",
        "        Names of features seen during `fit`.\n",
        "    fscores_ : dict\n",
        "        Dictionary mapping seed feature names to their F-scores.\n",
        "    seeds_ : list of str\n",
        "        Final list of diverse seed feature names after filtering.\n",
        "    cohort_weights_ : ndarray of shape (n_features_prefiltered, n_seeds_filtered)\n",
        "        Matrix of hybrid weights for all features wrt each filtered seed.\n",
        "    cohort_members_ : list of dict\n",
        "        Details of cohorts formed before final filtering.\n",
        "    kept_indices_ : list of int\n",
        "        Indices of cohorts kept after stability-based filtering.\n",
        "    stabilities_ : list of float\n",
        "        Stability scores for all initial cohorts.\n",
        "    scaler_ : StandardScaler instance\n",
        "        The scaler used to standardize features.\n",
        "    is_fitted_ : bool\n",
        "        Indicates if the transformer has been fitted.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import make_classification\n",
        "    >>> from infuse import INFUSE\n",
        "    >>> X, y = make_classification(n_samples=100, n_features=50, n_informative=10,\n",
        "    ...                            n_redundant=5, n_clusters_per_class=1, random_state=42)\n",
        "    >>> feature_names = [f\"Gene_{i}\" for i in range(X.shape[1])]\n",
        "    >>> infuse = INFUSE(k_seeds=5, max_features=20, verbose=True, random_state=42)\n",
        "    >>> Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "    >>> print(f\"Final cohort matrix shape: {Z_final.shape}\")\n",
        "    >>> summary_df = infuse.get_cohort_summary()\n",
        "    >>> print(summary_df)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- 1. Data Loading & Preprocessing ---\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # Scaling\n",
        "        self.scaler_ = StandardScaler()\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Data preprocessed: {X.shape}\")\n",
        "\n",
        "        # --- 2. Seed Selection ---\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # --- 3. Hybrid Weighting ---\n",
        "        similarities = cosine_similarity(X.T, X[:, [self.feature_names_in_.index(name) for name in seed_names_filtered]].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- 4. Graph Regularization - FIXED to build graph on X ---\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # --- 5. Cohort Fusion ---\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # --- 6. Final Filtering ---\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # --- 7. Save Attributes ---\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # <-- Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Start with 1 for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception:\n",
        "                        # Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 5. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.4f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "FTPTQpObf1Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading & Preprocessing\n",
        "\n",
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical.tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "X = StandardScaler().fit_transform(X_df.values)\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Y2M9C5f1WI",
        "outputId": "67bb0549-edef-4f89-8fb7-21a6cd83fee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFUSE Execution\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7rz0NxNf1Yx",
        "outputId": "ec746bc1-1622-421a-9721-9d7a3aedc38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data preprocessed: (1215, 1000)\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467']\n",
            "âœ… Similarity matrix computed: (1000, 6)\n",
            "âš™ï¸ Weight matrix shape: (1000, 6)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 6)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 6)\n",
            " No stable features met threshold. Keeping top 2.\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1  LOC729467            6   \n",
            "\n",
            "                                      member_genes  stability  \n",
            "0    [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.052862  \n",
            "1  [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.050395  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 6\n",
            "Final output cohorts (kept): 2\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.0529\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: LOC729467 | Stability: 0.0504\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features)\n",
        "# y_encoded: Encoded target labels (n_samples,)\n",
        "# feature_names: Names of the m pre-filtered features\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- Define Original Feature Names ---\n",
        "# Assuming X_df is the original DataFrame loaded in Section 1\n",
        "feature_names_full = X_df.columns.tolist() # List of all original feature names (length 20530)\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"\\n--- Transforming Test Data with Pre-fitted INFUSE Model ---\")\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the pre-fitted 'infuse' model ---\n",
        "    # Assuming the fitted 'infuse' object stores the names of the features it retained\n",
        "    # after internal pre-filtering. This is typically stored in an attribute like feature_names_in_\n",
        "    # Let's assume it's feature_names_in_\n",
        "    infuse_selected_feature_names = infuse.feature_names_in_ # List of 1000 feature names\n",
        "    # If feature_names_full corresponds to the columns of X_train_full/X_test_full (20530 names)\n",
        "    # Find the indices of the 1000 features selected by 'infuse' within the full 20530\n",
        "    infuse_selected_indices = [feature_names_full.index(name) for name in infuse_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full and X_train_full to the 1000 features used by 'infuse' ---\n",
        "    X_test_full_for_infuse = X_test_full[:, infuse_selected_indices] # Shape (243, 1000)\n",
        "    X_train_full_for_infuse = X_train_full[:, infuse_selected_indices] # Shape (972, 1000)\n",
        "\n",
        "    # --- NOW: Transform using the correctly sized data ---\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full_for_infuse)\n",
        "    # Optionally, re-transform train data if needed for consistency in techniques dict\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full_for_infuse)\n",
        "\n",
        "    if Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "        # Update k_compare based on actual number of features produced\n",
        "        k_compare = max(2, Z_test_infuse_full.shape[1])\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "\n",
        "    # --- FIX: Fit infuse_train on the full-dimensional X_train_full ---\n",
        "    # INFUSE will handle its own pre-filtering internally.\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=10,\n",
        "        jsd_threshold=0.4,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        max_features=1000,\n",
        "        stability_thresh=0.5,\n",
        "        final_k=2,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Fit ONLY on the full-dimensional training data (972, 20530) and corresponding labels (972,)\n",
        "    # Pass the full feature names list corresponding to X_train_full's 20530 columns\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_full)\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the newly fitted 'infuse_train' model ---\n",
        "    # After fitting, infuse_train.feature_names_in_ should contain the 1000 names it retained\n",
        "    infuse_train_selected_feature_names = infuse_train.feature_names_in_\n",
        "    infuse_train_selected_indices = [feature_names_full.index(name) for name in infuse_train_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full to the 1000 features used by 'infuse_train' ---\n",
        "    X_test_full_for_infuse_train = X_test_full[:, infuse_train_selected_indices] # Shape (243, 1000)\n",
        "\n",
        "    # --- NOW: Transform the correctly sized test data ---\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full_for_infuse_train)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        if n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "# Apply SelectKBest to the pre-filtered training data\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "# Apply to the pre-filtered training data\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "#X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "#X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "#estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "#rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "#X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "#X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "#techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "#print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                # Corrected formatting without colons outside braces\n",
        "                print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gHbNGjqvf1bU",
        "outputId": "ee203cec-feae-49e9-97e4-a2ab65582868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n",
            " Train Set Shape: (972, 20530)\n",
            " Test Set Shape: (243, 20530)\n",
            "\n",
            " Comparing techniques using k=2 features/components.\n",
            "\n",
            "--- Transforming Test Data with Pre-fitted INFUSE Model ---\n",
            "   _graph_regularization input X shape: (243, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "   _graph_regularization input X shape: (972, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… INFUSE Features (using fitted model on full data): Train (972, 2), Test (243, 2)\n",
            "\n",
            "--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 0 61] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… INFUSE Features (fitted on train only): Train (972, 2), Test (243, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Top 2 F-score Features Selected: Train (972, 2), Test (243, 2)\n",
            "âœ… Top 2 MI Features Selected: Train (972, 2), Test (243, 2)\n",
            "âœ… Top 2 PCA Components Derived: Train (972, 2), Test (243, 2)\n",
            "\n",
            "======================================================================\n",
            "EVALUATING DISCRIMINATIVE ABILITY\n",
            "(Cross-Validation on Train Set & Final Evaluation on Test Set)\n",
            "======================================================================\n",
            "\n",
            "--- Evaluating with LogisticRegression ---\n",
            "  INFUSE (Fitted Full):\n",
            "    CV Acc: 0.8385 (+/- 0.0050)\n",
            "    CV AUC: 0.6098 (+/- 0.0663)\n",
            "    Test Acc: 0.8313\n",
            "    Test AUC: 0.6611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  INFUSE (Train Only):\n",
            "    CV Acc: 0.8374 (+/- 0.0052)\n",
            "    CV AUC: 0.6165 (+/- 0.0763)\n",
            "    Test Acc: 0.8354\n",
            "    Test AUC: 0.6235\n",
            "  TopK_Fscore:\n",
            "    CV Acc: 0.8364 (+/- 0.0039)\n",
            "    CV AUC: 0.6400 (+/- 0.0935)\n",
            "    Test Acc: 0.8354\n",
            "    Test AUC: 0.6203\n",
            "  TopK_MI:\n",
            "    CV Acc: 0.8364 (+/- 0.0039)\n",
            "    CV AUC: 0.4750 (+/- 0.0281)\n",
            "    Test Acc: 0.8354\n",
            "    Test AUC: 0.5787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PCA:\n",
            "    CV Acc: 0.8364 (+/- 0.0039)\n",
            "    CV AUC: 0.5782 (+/- 0.0593)\n",
            "    Test Acc: 0.8354\n",
            "    Test AUC: 0.5824\n",
            "\n",
            "--- Evaluating with RandomForest ---\n",
            "  INFUSE (Fitted Full):\n",
            "    CV Acc: 0.8385 (+/- 0.0086)\n",
            "    CV AUC: 0.5976 (+/- 0.1706)\n",
            "    Test Acc: 0.8025\n",
            "    Test AUC: 0.5873\n",
            "  INFUSE (Train Only):\n",
            "    CV Acc: 0.8323 (+/- 0.0115)\n",
            "    CV AUC: 0.6039 (+/- 0.0896)\n",
            "    Test Acc: 0.8189\n",
            "    Test AUC: 0.5366\n",
            "  TopK_Fscore:\n",
            "    CV Acc: 0.7397 (+/- 0.0825)\n",
            "    CV AUC: 0.5280 (+/- 0.0846)\n",
            "    Test Acc: 0.7284\n",
            "    Test AUC: 0.6036\n",
            "  TopK_MI:\n",
            "    CV Acc: 0.8158 (+/- 0.0410)\n",
            "    CV AUC: 0.6107 (+/- 0.1309)\n",
            "    Test Acc: 0.8189\n",
            "    Test AUC: 0.5727\n",
            "  PCA:\n",
            "    CV Acc: 0.8251 (+/- 0.0239)\n",
            "    CV AUC: 0.5448 (+/- 0.1014)\n",
            "    Test Acc: 0.8477\n",
            "    Test AUC: 0.6369\n",
            "\n",
            "======================================================================\n",
            "SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\n",
            "======================================================================\n",
            "\n",
            "--- Performance Summary for LogisticRegression ---\n",
            "  Cross-Validation Performance (Train Set):\n",
            "  Technique                 CV Acc (mean +/- std)          CV AUC (mean +/- std)         \n",
            "  -------------------------------------------------------------------------------------\n",
            "  INFUSE (Fitted Full)      0.8385 (+/- 0.0050) 0.6098 (+/- 0.0663)\n",
            "  INFUSE (Train Only)       0.8374 (+/- 0.0052) 0.6165 (+/- 0.0763)\n",
            "  TopK_Fscore               0.8364 (+/- 0.0039) 0.6400 (+/- 0.0935)\n",
            "  TopK_MI                   0.8364 (+/- 0.0039) 0.4750 (+/- 0.0281)\n",
            "  PCA                       0.8364 (+/- 0.0039) 0.5782 (+/- 0.0593)\n",
            "  -------------------------------------------------------------------------------------\n",
            "  Final Test Set Performance:\n",
            "  Technique                 Test Acc     Test AUC    \n",
            "  --------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid format specifier '.4f:<12' for object of type 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-369746981.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid format specifier '.4f:<12' for object of type 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C22el5fyf1g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4xWLbP6_Kc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aui0GkQI_KgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34obLB6U_KjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mbp4Y16O_Kl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQPXVvB3_Ko0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Latest INFUSE Class\n",
        "\n",
        "\n",
        "\n",
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.0 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "\n",
        "    INFUSE operates on the principle that meaningful signals in biological\n",
        "    systems are often distributed across groups of features (cohorts) rather\n",
        "    than isolated within single features. It sequentially:\n",
        "    1. Pre-filters features based on univariate F-scores.\n",
        "    2. Selects diverse seed features using F-scores and JSD (on Softmax profiles).\n",
        "    3. Calculates hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "    4. Constructs a k-NN graph on feature profiles to define local neighborhoods.\n",
        "    5. Fuses features within neighborhoods using hybrid weights to create cohorts.\n",
        "    6. Evaluates cohort stability via bootstrapping and filters based on performance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    k_seeds : int, default=20\n",
        "        Number of initial seed candidates based on F-scores.\n",
        "    n_neighbors : int, deprecated\n",
        "        Placeholder from earlier versions. Not used in final graph construction.\n",
        "    alpha : float, default=0.6\n",
        "        Weight for the cosine similarity component in hybrid weighting.\n",
        "    beta : float, default=0.2\n",
        "        Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "    jsd_threshold : float, default=0.35\n",
        "        Minimum JSD dissimilarity required between seed candidates during filtering.\n",
        "    k_graph : int, deprecated\n",
        "        Placeholder from earlier versions. Final version uses automatic k determination.\n",
        "    n_bootstrap : int, default=100\n",
        "        Number of bootstrap iterations for stability evaluation.\n",
        "    stability_thresh : float, default=0.5\n",
        "        Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "    final_k : int, default=2\n",
        "        Number of top cohorts to keep if none meet stability_thresh.\n",
        "    verbose : bool, default=True\n",
        "        Whether to print progress messages.\n",
        "    max_features : int, default=1000\n",
        "        Initial pre-filtering to this many top F-score features.\n",
        "    random_state : int or RandomState instance, default=42\n",
        "        Controls the randomness of the estimator.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    feature_names_in_ : list of str\n",
        "        Names of features seen during `fit`.\n",
        "    fscores_ : dict\n",
        "        Dictionary mapping seed feature names to their F-scores.\n",
        "    seeds_ : list of str\n",
        "        Final list of diverse seed feature names after filtering.\n",
        "    cohort_weights_ : ndarray of shape (n_features_prefiltered, n_seeds_filtered)\n",
        "        Matrix of hybrid weights for all features wrt each filtered seed.\n",
        "    cohort_members_ : list of dict\n",
        "        Details of cohorts formed before final filtering.\n",
        "    kept_indices_ : list of int\n",
        "        Indices of cohorts kept after stability-based filtering.\n",
        "    stabilities_ : list of float\n",
        "        Stability scores for all initial cohorts.\n",
        "    scaler_ : StandardScaler instance\n",
        "        The scaler used to standardize features.\n",
        "    is_fitted_ : bool\n",
        "        Indicates if the transformer has been fitted.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import make_classification\n",
        "    >>> from infuse import INFUSE\n",
        "    >>> X, y = make_classification(n_samples=100, n_features=50, n_informative=10,\n",
        "    ...                            n_redundant=5, n_clusters_per_class=1, random_state=42)\n",
        "    >>> feature_names = [f\"Gene_{i}\" for i in range(X.shape[1])]\n",
        "    >>> infuse = INFUSE(k_seeds=5, max_features=20, verbose=True, random_state=42)\n",
        "    >>> Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "    >>> print(f\"Final cohort matrix shape: {Z_final.shape}\")\n",
        "    >>> summary_df = infuse.get_cohort_summary()\n",
        "    >>> print(summary_df)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- 1. Data Loading & Preprocessing ---\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # Scaling\n",
        "        self.scaler_ = StandardScaler()\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Data preprocessed: {X.shape}\")\n",
        "\n",
        "        # --- 2. Seed Selection ---\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # --- 3. Hybrid Weighting ---\n",
        "        similarities = cosine_similarity(X.T, X[:, [self.feature_names_in_.index(name) for name in seed_names_filtered]].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- 4. Graph Regularization - FIXED to build graph on X ---\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # --- 5. Cohort Fusion ---\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # --- 6. Final Filtering ---\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # --- 7. Save Attributes ---\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep:\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        # --- Use PRE-COMPUTED F-scores from self.fscores_ dictionary ---\n",
        "        # Retrieve F-scores for ALL pre-filtered features using their names\n",
        "        # This avoids needing self.y_ inside this method\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "\n",
        "        # Normalize F-scores to [0, 1] range for fair contribution in weighted sum\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "            fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        # Tile the normalized F-score vector to create a matrix for all seed comparisons\n",
        "        # Shape: (n_features_prefiltered, n_seeds_filtered)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # --- Compute JSD dissimilarity component ---\n",
        "        # Apply Softmax normalization for JSD calculation on feature profiles\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        # Initialize matrix to store JSD values for all feature-seed pairs\n",
        "        # Shape: (n_features_prefiltered, n_seeds_filtered)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "\n",
        "        # Iterate through each seed to compute its JSD with all features\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            # Get the index of the current seed within the pre-filtered feature set\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            # Extract the Softmax-normalized expression profile of the seed\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx]\n",
        "\n",
        "            # Compute JSD between the seed's profile and EVERY feature's profile\n",
        "            for j in range(X.shape[1]): # Iterate through all pre-filtered features\n",
        "                # Extract the Softmax-normalized expression profile of the current gene\n",
        "                gene_profile_softmax = X_softmax[:, j]\n",
        "                # Calculate JSD using scipy.spatial.distance.jensenshannon\n",
        "                # This correctly measures dissimilarity between probability distributions\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # --- Combine components into final hybrid weights ---\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        # The weights matrix W has shape (n_features_prefiltered, n_seeds_filtered)\n",
        "        weights = (self.alpha * similarities +               # Weighted similarity component\n",
        "                  (1 - self.alpha) * fs_matrix -           # Weighted F-score component\n",
        "                  self.beta * jsd_div)                     # Weighted JSD dissimilarity penalty\n",
        "\n",
        "        # Ensure non-negative weights by clipping values below zero\n",
        "        weights = np.clip(weights, 0, None)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # <-- Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Don't connect feature to itself in neighbor list\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Start with 1 for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception:\n",
        "                        # Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 5. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.4f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "qYZl0PSJ_Ktp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "# Import resampling techniques to handle class imbalance\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE # Optional: Uncomment if you want to try SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler # Optional: Uncomment if you want to try undersampling\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Address Class Imbalance ---\n",
        "# Check initial label distribution\n",
        "initial_counts = pd.Series(y).value_counts()\n",
        "print(f\" Initial label distribution: {initial_counts.to_dict()}\")\n",
        "\n",
        "# --- Strategy 1: Undersampling the Majority Class (Alive) ---\n",
        "# This reduces the number of 'Alive' samples to match the 'Dead' count.\n",
        "# It's simple and preserves the original distribution of the minority class.\n",
        "# Note: This will reduce the overall dataset size.\n",
        "print(\"\\n--- Addressing Class Imbalance: Undersampling Majority Class ---\")\n",
        "# Create a temporary DataFrame for resampling\n",
        "df_temp = pd.concat([X_df, pd.Series(y, name='target')], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df_temp[df_temp.target == 'Alive']\n",
        "df_minority = df_temp[df_temp.target == 'Dead']\n",
        "\n",
        "print(f\"  Before Resampling:\")\n",
        "print(f\"    Majority class (Alive) samples: {len(df_majority)}\")\n",
        "print(f\"    Minority class (Dead) samples: {len(df_minority)}\")\n",
        "\n",
        "# Downsample majority class to match minority class size\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,    # Sample without replacement\n",
        "                                   n_samples=len(df_minority), # Match minority class\n",
        "                                   random_state=42) # Reproducible results\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract balanced X and y\n",
        "X_df_balanced = df_balanced.drop('target', axis=1)\n",
        "y_balanced = df_balanced['target'].values\n",
        "\n",
        "print(f\"  After Undersampling:\")\n",
        "print(f\"    Balanced dataset size: {X_df_balanced.shape[0]}\")\n",
        "final_counts = pd.Series(y_balanced).value_counts()\n",
        "print(f\"    Final label distribution: {final_counts.to_dict()}\")\n",
        "\n",
        "# --- Continue with standard preprocessing on the BALANCED data ---\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_balanced) # Use y_balanced\n",
        "print(f\" Final encoded label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "# Note: Scaling is done on the balanced X_df_balanced\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_df_balanced.values) # Use X_df_balanced\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df_balanced.columns.tolist() # Use X_df_balanced\n",
        "print(f\" First 10 genes (balanced data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Undersampling) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X): {X.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Alternative Strategies (Commented Out) ---\n",
        "# You can experiment with these if desired.\n",
        "\n",
        "# --- Strategy 2: Oversampling the Minority Class (Dead) ---\n",
        "# This increases the number of 'Dead' samples by duplicating them.\n",
        "# It preserves all original data but can lead to overfitting.\n",
        "\"\"\"\n",
        "print(\"\\n--- Addressing Class Imbalance: Oversampling Minority Class ---\")\n",
        "# Separate majority and minority classes\n",
        "df_majority_os = df_temp[df_temp.target == 'Alive']\n",
        "df_minority_os = df_temp[df_temp.target == 'Dead']\n",
        "\n",
        "print(f\"  Before Resampling (Oversampling):\")\n",
        "print(f\"    Majority class (Alive) samples: {len(df_majority_os)}\")\n",
        "print(f\"    Minority class (Dead) samples: {len(df_minority_os)}\")\n",
        "\n",
        "# Upsample minority class to match majority class size\n",
        "df_minority_upsampled = resample(df_minority_os,\n",
        "                                 replace=True,     # Sample with replacement\n",
        "                                 n_samples=len(df_majority_os), # Match majority class\n",
        "                                 random_state=42) # Reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_balanced_os = pd.concat([df_majority_os, df_minority_upsampled])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced_os = df_balanced_os.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract balanced X and y for oversampling\n",
        "X_df_balanced_os = df_balanced_os.drop('target', axis=1)\n",
        "y_balanced_os = df_balanced_os['target'].values\n",
        "\n",
        "print(f\"  After Oversampling:\")\n",
        "print(f\"    Balanced dataset size (Oversampled): {X_df_balanced_os.shape[0]}\")\n",
        "final_counts_os = pd.Series(y_balanced_os).value_counts()\n",
        "print(f\"    Final label distribution (Oversampled): {final_counts_os.to_dict()}\")\n",
        "\n",
        "# Preprocess X_df_balanced_os and y_balanced_os similarly...\n",
        "\"\"\"\n",
        "\n",
        "# --- Strategy 3: Using SMOTE (Synthetic Minority Oversampling Technique) ---\n",
        "# This generates synthetic samples for the minority class.\n",
        "# More sophisticated than simple oversampling but requires careful application.\n",
        "# Note: SMOTE typically requires features to be numerical and may not work directly with all data types.\n",
        "# It's also sensitive to outliers and may not be ideal for all biological data.\n",
        "\"\"\"\n",
        "print(\"\\n--- Addressing Class Imbalance: Using SMOTE ---\")\n",
        "# Ensure X_df is numerical (it should be after loading HiSeqV2)\n",
        "X_smote = X_df.values # Use original X_df for SMOTE\n",
        "y_smote = y # Use original y for SMOTE\n",
        "\n",
        "# Encode labels for SMOTE\n",
        "le_smote = LabelEncoder()\n",
        "y_encoded_smote = le_smote.fit_transform(y_smote)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_smote, y_encoded_smote)\n",
        "\n",
        "# Convert back to DataFrame if needed (optional)\n",
        "# X_df_resampled_smote = pd.DataFrame(X_resampled_smote, columns=feature_names)\n",
        "\n",
        "print(f\"  After SMOTE:\")\n",
        "print(f\"    Resampled dataset size: {X_resampled_smote.shape[0]}\")\n",
        "final_counts_smote = pd.Series(le_smote.inverse_transform(y_resampled_smote)).value_counts()\n",
        "print(f\"    Final label distribution (SMOTE): {final_counts_smote.to_dict()}\")\n",
        "\n",
        "# Preprocess X_resampled_smote and y_resampled_smote similarly...\n",
        "# scaler_smote = StandardScaler()\n",
        "# X_smote_scaled = scaler_smote.fit_transform(X_resampled_smote)\n",
        "# feature_names_smote = feature_names # Same features\n",
        "\"\"\"\n",
        "\n",
        "# --- Strategy 4: Combining Oversampling and Undersampling ---\n",
        "# This can provide a middle ground.\n",
        "# For example, upsample the minority class to half the majority class size,\n",
        "# then downsample the majority class to match the new minority size.\n",
        "\"\"\"\n",
        "print(\"\\n--- Addressing Class Imbalance: Combined Sampling ---\")\n",
        "# Separate classes\n",
        "df_majority_cs = df_temp[df_temp.target == 'Alive']\n",
        "df_minority_cs = df_temp[df_temp.target == 'Dead']\n",
        "\n",
        "# Define target sizes (e.g., aim for a 60:40 or 70:30 split)\n",
        "target_minority_size = int(len(df_majority_cs) * 0.4) # Aim for 40% minority\n",
        "target_majority_size = target_minority_size # Match them\n",
        "\n",
        "# Upsample minority\n",
        "df_minority_upsampled_cs = resample(df_minority_cs,\n",
        "                                    replace=True,\n",
        "                                    n_samples=target_minority_size,\n",
        "                                    random_state=42)\n",
        "\n",
        "# Downsample majority\n",
        "df_majority_downsampled_cs = resample(df_majority_cs,\n",
        "                                      replace=False,\n",
        "                                      n_samples=target_majority_size,\n",
        "                                      random_state=42)\n",
        "\n",
        "# Combine\n",
        "df_balanced_cs = pd.concat([df_minority_upsampled_cs, df_majority_downsampled_cs])\n",
        "df_balanced_cs = df_balanced_cs.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "X_df_balanced_cs = df_balanced_cs.drop('target', axis=1)\n",
        "y_balanced_cs = df_balanced_cs['target'].values\n",
        "\n",
        "print(f\"  After Combined Sampling:\")\n",
        "print(f\"    Balanced dataset size: {X_df_balanced_cs.shape[0]}\")\n",
        "final_counts_cs = pd.Series(y_balanced_cs).value_counts()\n",
        "print(f\"    Final label distribution (Combined): {final_counts_cs.to_dict()}\")\n",
        "\n",
        "# Preprocess X_df_balanced_cs and y_balanced_cs similarly...\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "75nP-OLFf1mE",
        "outputId": "47d7dfb5-557f-4c81-cb97-01f0fc02b24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            " Initial label distribution: {'Alive': 1016, 'Dead': 199}\n",
            "\n",
            "--- Addressing Class Imbalance: Undersampling Majority Class ---\n",
            "  Before Resampling:\n",
            "    Majority class (Alive) samples: 1016\n",
            "    Minority class (Dead) samples: 199\n",
            "  After Undersampling:\n",
            "    Balanced dataset size: 398\n",
            "    Final label distribution: {'Alive': 199, 'Dead': 199}\n",
            " Final encoded label distribution: {'Alive': np.int64(199), 'Dead': np.int64(199)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " First 10 genes (balanced data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Undersampling) Completed:\n",
            "   - Final Data Matrix Shape (X): (398, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (398,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [199 199]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"\\n--- Addressing Class Imbalance: Combined Sampling ---\")\\n# Separate classes\\ndf_majority_cs = df_temp[df_temp.target == \\'Alive\\']\\ndf_minority_cs = df_temp[df_temp.target == \\'Dead\\']\\n\\n# Define target sizes (e.g., aim for a 60:40 or 70:30 split)\\ntarget_minority_size = int(len(df_majority_cs) * 0.4) # Aim for 40% minority\\ntarget_majority_size = target_minority_size # Match them\\n\\n# Upsample minority\\ndf_minority_upsampled_cs = resample(df_minority_cs,\\n                                    replace=True,\\n                                    n_samples=target_minority_size,\\n                                    random_state=42)\\n\\n# Downsample majority\\ndf_majority_downsampled_cs = resample(df_majority_cs,\\n                                      replace=False,\\n                                      n_samples=target_majority_size,\\n                                      random_state=42)\\n\\n# Combine\\ndf_balanced_cs = pd.concat([df_minority_upsampled_cs, df_majority_downsampled_cs])\\ndf_balanced_cs = df_balanced_cs.sample(frac=1, random_state=42).reset_index(drop=True)\\n\\nX_df_balanced_cs = df_balanced_cs.drop(\\'target\\', axis=1)\\ny_balanced_cs = df_balanced_cs[\\'target\\'].values\\n\\nprint(f\"  After Combined Sampling:\")\\nprint(f\"    Balanced dataset size: {X_df_balanced_cs.shape[0]}\")\\nfinal_counts_cs = pd.Series(y_balanced_cs).value_counts()\\nprint(f\"    Final label distribution (Combined): {final_counts_cs.to_dict()}\")\\n\\n# Preprocess X_df_balanced_cs and y_balanced_cs similarly...\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# --- Address Class Imbalance ---\n",
        "print(\"\\n--- Addressing Class Imbalance: Undersampling Majority Class ---\")\n",
        "# Check initial label distribution\n",
        "y_series = pd.Series(y)\n",
        "initial_label_counts = y_series.value_counts()\n",
        "print(f\"  Initial label distribution: {initial_label_counts.to_dict()}\")\n",
        "\n",
        "# Create a temporary DataFrame for resampling\n",
        "df_temp = pd.concat([X_df, y_series.rename('target')], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "majority_class = initial_label_counts.idxmax()\n",
        "minority_class = initial_label_counts.idxmin()\n",
        "df_majority = df_temp[df_temp.target == majority_class]\n",
        "df_minority = df_temp[df_temp.target == minority_class]\n",
        "\n",
        "print(f\"  Before Resampling:\")\n",
        "print(f\"    Majority class ({majority_class}) samples: {len(df_majority)}\")\n",
        "print(f\"    Minority class ({minority_class}) samples: {len(df_minority)}\")\n",
        "\n",
        "# Downsample majority class to match minority class size\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority),\n",
        "                                   random_state=42)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract balanced X and y\n",
        "X_df_balanced = df_balanced.drop('target', axis=1)\n",
        "y_balanced = df_balanced['target'].values\n",
        "\n",
        "print(f\"  After Undersampling:\")\n",
        "print(f\"    Balanced dataset size: {X_df_balanced.shape[0]}\")\n",
        "final_label_counts = pd.Series(y_balanced).value_counts()\n",
        "print(f\"    Final label distribution: {final_label_counts.to_dict()}\")\n",
        "\n",
        "# --- Continue with standard preprocessing on the BALANCED data ---\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_balanced)\n",
        "print(f\" Final encoded label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# --- Scale expression data ROBUSTLY ---\n",
        "print(\"\\n--- Scaling Expression Data ---\")\n",
        "scaler = StandardScaler()\n",
        "try:\n",
        "    # Fit and transform the balanced, imputed data\n",
        "    X_scaled_balanced = scaler.fit_transform(X_df_balanced.values)\n",
        "    print(f\"âœ… Data successfully scaled. Final scaled data shape: {X_scaled_balanced.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âŒ Error during scaling: {e}\")\n",
        "    # Handle potential edge cases (should be rare after imputation)\n",
        "    X_scaled_balanced = np.empty((X_df_balanced.shape[0], 0))\n",
        "    print(f\"   Returned empty scaled data matrix.\")\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df_balanced.columns.tolist()\n",
        "print(f\" First 10 genes (balanced data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X): {X_scaled_balanced.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Assign final outputs for use in subsequent sections ---\n",
        "X = X_scaled_balanced  # Use the scaled, balanced, CLEANED data\n",
        "y = y_encoded          # Use the encoded, balanced labels\n",
        "# feature_names now refers to the features in the balanced, scaled data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnxNdGn5Diyr",
        "outputId": "9d472924-1d60-4dff-d202-830052b0effa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            "\n",
            "--- Addressing Class Imbalance: Undersampling Majority Class ---\n",
            "  Initial label distribution: {'Alive': 1016, 'Dead': 199}\n",
            "  Before Resampling:\n",
            "    Majority class (Alive) samples: 1016\n",
            "    Minority class (Dead) samples: 199\n",
            "  After Undersampling:\n",
            "    Balanced dataset size: 398\n",
            "    Final label distribution: {'Alive': 199, 'Dead': 199}\n",
            " Final encoded label distribution: {'Alive': np.int64(199), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Scaling Expression Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data successfully scaled. Final scaled data shape: (398, 20530)\n",
            " First 10 genes (balanced data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\n",
            "   - Final Data Matrix Shape (X): (398, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (398,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [199 199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFUSE Execution\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lFLrs_tO-tjc",
        "outputId": "db5b460e-67da-42ed-b942-d9ddb0d60730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Handling NaNs in input data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-549535185.py:196: RuntimeWarning: All-NaN slice encountered\n",
            "  col_medians = np.nanmedian(X, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n",
            "âœ… Data preprocessed: (398, 1000)\n",
            " Seeds (raw): ['ARHGEF10L', 'RTP1', 'RTP3', 'RTP2', 'RTP4', 'PSMD2', 'PSMD3', 'KIAA1731', 'ZNF704', 'LOC339240']\n",
            " Seeds (filtered): ['ARHGEF10L']\n",
            "âœ… Similarity matrix computed: (1000, 1)\n",
            "âš™ï¸ Weight matrix shape: (1000, 1)\n",
            "ðŸ“Œ Max weight: 0.0000 | Min weight: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [    0     1     2 ... 20527 20528 20529] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
            " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
            " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
            " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
            " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
            " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
            " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
            " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
            " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
            " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
            " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
            " 990 991 992 993 994 995 996 997 998 999] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "âŒ Weight matrix collapsed â€” check input similarity/JSD structure.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-919104391.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# feature_names = X_df.columns.tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mZ_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass raw X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ“‹ INFUSE Cohort Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-549535185.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hybrid_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_names_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Weight matrix computed: {weights.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: âŒ Weight matrix collapsed â€” check input similarity/JSD structure."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features)\n",
        "# y_encoded: Encoded target labels (n_samples,)\n",
        "# feature_names: Names of the m pre-filtered features\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- Define Original Feature Names ---\n",
        "# Assuming X_df is the original DataFrame loaded in Section 1\n",
        "feature_names_full = X_df.columns.tolist() # List of all original feature names (length 20530)\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"\\n--- Transforming Test Data with Pre-fitted INFUSE Model ---\")\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the pre-fitted 'infuse' model ---\n",
        "    # Assuming the fitted 'infuse' object stores the names of the features it retained\n",
        "    # after internal pre-filtering. This is typically stored in an attribute like feature_names_in_\n",
        "    # Let's assume it's feature_names_in_\n",
        "    infuse_selected_feature_names = infuse.feature_names_in_ # List of 1000 feature names\n",
        "    # If feature_names_full corresponds to the columns of X_train_full/X_test_full (20530 names)\n",
        "    # Find the indices of the 1000 features selected by 'infuse' within the full 20530\n",
        "    infuse_selected_indices = [feature_names_full.index(name) for name in infuse_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full and X_train_full to the 1000 features used by 'infuse' ---\n",
        "    X_test_full_for_infuse = X_test_full[:, infuse_selected_indices] # Shape (243, 1000)\n",
        "    X_train_full_for_infuse = X_train_full[:, infuse_selected_indices] # Shape (972, 1000)\n",
        "\n",
        "    # --- NOW: Transform using the correctly sized data ---\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full_for_infuse)\n",
        "    # Optionally, re-transform train data if needed for consistency in techniques dict\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full_for_infuse)\n",
        "\n",
        "    if Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "        # Update k_compare based on actual number of features produced\n",
        "        k_compare = max(2, Z_test_infuse_full.shape[1])\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "\n",
        "    # --- FIX: Fit infuse_train on the full-dimensional X_train_full ---\n",
        "    # INFUSE will handle its own pre-filtering internally.\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=10,\n",
        "        jsd_threshold=0.4,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        max_features=1000,\n",
        "        stability_thresh=0.5,\n",
        "        final_k=2,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Fit ONLY on the full-dimensional training data (972, 20530) and corresponding labels (972,)\n",
        "    # Pass the full feature names list corresponding to X_train_full's 20530 columns\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_full)\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the newly fitted 'infuse_train' model ---\n",
        "    # After fitting, infuse_train.feature_names_in_ should contain the 1000 names it retained\n",
        "    infuse_train_selected_feature_names = infuse_train.feature_names_in_\n",
        "    infuse_train_selected_indices = [feature_names_full.index(name) for name in infuse_train_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full to the 1000 features used by 'infuse_train' ---\n",
        "    X_test_full_for_infuse_train = X_test_full[:, infuse_train_selected_indices] # Shape (243, 1000)\n",
        "\n",
        "    # --- NOW: Transform the correctly sized test data ---\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full_for_infuse_train)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        if n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "# Apply SelectKBest to the pre-filtered training data\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "# Apply to the pre-filtered training data\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "#X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "#X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "#estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "#rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "#X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "#X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "#techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "#print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                # Corrected formatting without colons outside braces\n",
        "                print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "0wGm7ms_-tmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCWyL7Ri-tpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1VlQovQ-trx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmGmjzFi-tuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nko4VG4G-t1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_debug.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Debugging Enhancement)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with enhanced debugging capabilities.\n",
        "# INFUSE is a transformer designed for high-dimensional biological data\n",
        "# (e.g., gene expression) to construct new, stable, and potentially interpretable\n",
        "# cohort features. It integrates concepts of seed selection, multi-criteria\n",
        "# hybrid weighting, graph-based regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse_debug import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- DEBUGGED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"  _hybrid_weights input X shape: {X.shape}\")\n",
        "            print(f\"  _hybrid_weights input seed_names: {seed_names[:3]}{'...' if len(seed_names) > 3 else ''}\")\n",
        "            print(f\"  _hybrid_weights input similarities shape: {similarities.shape}\")\n",
        "\n",
        "        # --- DEBUG: Inspect similarities matrix ---\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG similarities matrix - Min: {similarities.min():.6f}, Max: {similarities.max():.6f}, Mean: {similarities.mean():.6f}\")\n",
        "            print(f\"  DEBUG similarities matrix - First few rows/columns:\\n{similarities[:3, :min(3, similarities.shape[1])] if similarities.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- Component 1: Individual Feature Importance (F-score) ---\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG fscores_arr - Shape: {fscores_arr.shape}, Min: {fscores_arr.min():.6f}, Max: {fscores_arr.max():.6f}, Mean: {fscores_arr.mean():.6f}\")\n",
        "            print(f\"  DEBUG fscores_arr - First few values: {fscores_arr[:5]}\")\n",
        "\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG F-score normalization - fs_min: {fs_min:.6f}, fs_max: {fs_max:.6f}, denom: {denom:.6f}\")\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "             if self.verbose:\n",
        "                 print(\"  DEBUG F-score normalization - All F-scores identical. Using zero vector.\")\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "            if self.verbose:\n",
        "                print(f\"  DEBUG fs_norm - Shape: {fs_norm.shape}, Min: {fs_norm.min():.6f}, Max: {fs_norm.max():.6f}, Mean: {fs_norm.mean():.6f}\")\n",
        "                print(f\"  DEBUG fs_norm - First few values: {fs_norm[:5]}\")\n",
        "\n",
        "        # Tile to create F_matrix for all seed comparisons\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG fs_matrix - Shape: {fs_matrix.shape}\")\n",
        "            print(f\"  DEBUG fs_matrix - Sample values (first 3 features, first 2 seeds):\\n{fs_matrix[:3, :min(2, fs_matrix.shape[1])] if fs_matrix.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- Component 2: Apply Softmax normalization for JSD calculation ---\n",
        "        if self.verbose:\n",
        "            print(\"  DEBUG Applying Softmax normalization for JSD...\")\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG X_softmax - Shape: {X_softmax.shape}\")\n",
        "            print(f\"  DEBUG X_softmax - Sample values (first 3 samples, first 3 features):\\n{X_softmax[:3, :min(3, X_softmax.shape[1])] if X_softmax.size > 0 else 'Empty'}\")\n",
        "            # Check if softmax worked correctly\n",
        "            row_sums = np.sum(X_softmax, axis=0)\n",
        "            print(f\"  DEBUG X_softmax row sums (should be ~1.0 for each feature): Min: {row_sums.min():.6f}, Max: {row_sums.max():.6f}\")\n",
        "\n",
        "        # --- Component 3: Compute JSD dissimilarity matrix ---\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG Initializing JSD matrix - Shape: {jsd_div.shape}\")\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            if self.verbose and i == 0: # Print details for first seed only\n",
        "                print(f\"  DEBUG Computing JSD for seed {i+1}/{len(seed_names)}: {seed_name}\")\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            if self.verbose and i == 0:\n",
        "                print(f\"  DEBUG Seed profile (Softmax) - Shape: {seed_profile_softmax.shape}, Min: {seed_profile_softmax.min():.6f}, Max: {seed_profile_softmax.max():.6f}\")\n",
        "\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_val = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "                 jsd_div[j, i] = jsd_val\n",
        "                 if self.verbose and i == 0 and j < 3: # Print first few JSD values for first seed\n",
        "                     print(f\"  DEBUG JSD[{j}, {i}] (feature {j} vs seed {seed_name}): {jsd_val:.6f}\")\n",
        "                 # Optional: Add check for invalid JSD values\n",
        "                 if not np.isfinite(jsd_val):\n",
        "                     if self.verbose:\n",
        "                         print(f\"  WARNING: Invalid JSD value encountered for feature {j} vs seed {seed_name}: {jsd_val}. Setting to 1.0 (max dissimilarity).\")\n",
        "                     jsd_div[j, i] = 1.0 # Default to max dissimilarity\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG jsd_div matrix - Shape: {jsd_div.shape}\")\n",
        "            print(f\"  DEBUG jsd_div matrix - Min: {jsd_div.min():.6f}, Max: {jsd_div.max():.6f}, Mean: {jsd_div.mean():.6f}\")\n",
        "            print(f\"  DEBUG jsd_div matrix - Sample values (first 3 features, first 2 seeds):\\n{jsd_div[:3, :min(2, jsd_div.shape[1])] if jsd_div.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- Combine components into final hybrid weights ---\n",
        "        if self.verbose:\n",
        "            print(\"  DEBUG Combining components into hybrid weights...\")\n",
        "            print(f\"  DEBUG alpha: {self.alpha}, beta: {self.beta}\")\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"  DEBUG Combined weights before clipping - Shape: {weights.shape}\")\n",
        "            print(f\"  DEBUG Combined weights before clipping - Min: {weights.min():.6f}, Max: {weights.max():.6f}, Mean: {weights.mean():.6f}\")\n",
        "            print(f\"  DEBUG Combined weights before clipping - Sample values (first 3 features, first 2 seeds):\\n{weights[:3, :min(2, weights.shape[1])] if weights.size > 0 else 'Empty'}\")\n",
        "            # Check for NaNs or all identical values before clipping\n",
        "            if np.isnan(weights).any():\n",
        "                print(\"  WARNING: NaN values detected in combined weights before clipping.\")\n",
        "            if np.all(weights == weights[0, 0]):\n",
        "                print(\"  WARNING: All weights are identical before clipping.\")\n",
        "\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "            print(f\"  DEBUG Final weights after clipping - Sample values (first 3 features, first 2 seeds):\\n{weights[:3, :min(2, weights.shape[1])] if weights.size > 0 else 'Empty'}\")\n",
        "            # Final check for collapse\n",
        "            if np.isnan(weights).any():\n",
        "                print(\"  ERROR: NaN values detected in final weight matrix.\")\n",
        "            if np.all(weights == weights[0, 0]):\n",
        "                print(\"  ERROR: Final weight matrix collapsed - all values are identical.\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "8b-kKN1Kf1pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# --- Address Class Imbalance ---\n",
        "print(\"\\n--- Addressing Class Imbalance: Undersampling Majority Class ---\")\n",
        "# Check initial label distribution\n",
        "y_series = pd.Series(y)\n",
        "initial_label_counts = y_series.value_counts()\n",
        "print(f\"  Initial label distribution: {initial_label_counts.to_dict()}\")\n",
        "\n",
        "# Create a temporary DataFrame for resampling\n",
        "df_temp = pd.concat([X_df, y_series.rename('target')], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "majority_class = initial_label_counts.idxmax()\n",
        "minority_class = initial_label_counts.idxmin()\n",
        "df_majority = df_temp[df_temp.target == majority_class]\n",
        "df_minority = df_temp[df_temp.target == minority_class]\n",
        "\n",
        "print(f\"  Before Resampling:\")\n",
        "print(f\"    Majority class ({majority_class}) samples: {len(df_majority)}\")\n",
        "print(f\"    Minority class ({minority_class}) samples: {len(df_minority)}\")\n",
        "\n",
        "# Downsample majority class to match minority class size\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority),\n",
        "                                   random_state=42)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract balanced X and y\n",
        "X_df_balanced = df_balanced.drop('target', axis=1)\n",
        "y_balanced = df_balanced['target'].values\n",
        "\n",
        "print(f\"  After Undersampling:\")\n",
        "print(f\"    Balanced dataset size: {X_df_balanced.shape[0]}\")\n",
        "final_label_counts = pd.Series(y_balanced).value_counts()\n",
        "print(f\"    Final label distribution: {final_label_counts.to_dict()}\")\n",
        "\n",
        "# --- Continue with standard preprocessing on the BALANCED data ---\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_balanced)\n",
        "print(f\" Final encoded label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# --- Scale expression data ROBUSTLY ---\n",
        "print(\"\\n--- Scaling Expression Data ---\")\n",
        "scaler = StandardScaler()\n",
        "try:\n",
        "    # Fit and transform the balanced, imputed data\n",
        "    X_scaled_balanced = scaler.fit_transform(X_df_balanced.values)\n",
        "    print(f\"âœ… Data successfully scaled. Final scaled data shape: {X_scaled_balanced.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âŒ Error during scaling: {e}\")\n",
        "    # Handle potential edge cases (should be rare after imputation)\n",
        "    X_scaled_balanced = np.empty((X_df_balanced.shape[0], 0))\n",
        "    print(f\"   Returned empty scaled data matrix.\")\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df_balanced.columns.tolist()\n",
        "print(f\" First 10 genes (balanced data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X): {X_scaled_balanced.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Assign final outputs for use in subsequent sections ---\n",
        "X = X_scaled_balanced  # Use the scaled, balanced, CLEANED data\n",
        "y = y_encoded          # Use the encoded, balanced labels\n",
        "# feature_names now refers to the features in the balanced, scaled data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaPWz8rpyFqD",
        "outputId": "c091e101-9790-46b7-9bc6-5d088483b81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            "\n",
            "--- Addressing Class Imbalance: Undersampling Majority Class ---\n",
            "  Initial label distribution: {'Alive': 1016, 'Dead': 199}\n",
            "  Before Resampling:\n",
            "    Majority class (Alive) samples: 1016\n",
            "    Minority class (Dead) samples: 199\n",
            "  After Undersampling:\n",
            "    Balanced dataset size: 398\n",
            "    Final label distribution: {'Alive': 199, 'Dead': 199}\n",
            " Final encoded label distribution: {'Alive': np.int64(199), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Scaling Expression Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data successfully scaled. Final scaled data shape: (398, 20530)\n",
            " First 10 genes (balanced data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\n",
            "   - Final Data Matrix Shape (X): (398, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (398,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [199 199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3t3XEevf1re",
        "outputId": "4e427af5-1187-4b45-bb50-9e096dd53b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            "\n",
            "--- Addressing Class Imbalance: Undersampling Majority Class ---\n",
            "  Initial label distribution: {'Alive': 1016, 'Dead': 199}\n",
            "  Before Resampling:\n",
            "    Majority class (Alive) samples: 1016\n",
            "    Minority class (Dead) samples: 199\n",
            "  After Undersampling:\n",
            "    Balanced dataset size: 398\n",
            "    Final label distribution: {'Alive': 199, 'Dead': 199}\n",
            " Final encoded label distribution: {'Alive': np.int64(199), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Scaling Expression Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data successfully scaled. Final scaled data shape: (398, 20530)\n",
            " First 10 genes (balanced data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\n",
            "   - Final Data Matrix Shape (X): (398, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (398,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [199 199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFUSE Execution\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EyCtI7BVrYFF",
        "outputId": "cf708d25-5197-4f88-e605-95e7ba7aec68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Handling NaNs in input data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2056642463.py:153: RuntimeWarning: All-NaN slice encountered\n",
            "  col_medians = np.nanmedian(X, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [    0     1     2 ... 20527 20528 20529] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
            " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
            " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
            " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
            " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
            " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
            " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
            " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
            " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
            " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
            " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
            " 990 991 992 993 994 995 996 997 998 999] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['ARHGEF10L', 'RTP1', 'RTP3', 'RTP2', 'RTP4', 'PSMD2', 'PSMD3', 'KIAA1731', 'ZNF704', 'LOC339240']\n",
            " Seeds (filtered): ['ARHGEF10L']\n",
            "âœ… Similarity matrix computed: (1000, 1)\n",
            "  _hybrid_weights input X shape: (398, 1000)\n",
            "  _hybrid_weights input seed_names: ['ARHGEF10L']\n",
            "  _hybrid_weights input similarities shape: (1000, 1)\n",
            "  DEBUG similarities matrix - Min: 0.000000, Max: 0.000000, Mean: 0.000000\n",
            "  DEBUG similarities matrix - First few rows/columns:\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "  DEBUG fscores_arr - Shape: (1000,), Min: 0.000000, Max: 0.000000, Mean: 0.000000\n",
            "  DEBUG fscores_arr - First few values: [0. 0. 0. 0. 0.]\n",
            "  DEBUG F-score normalization - fs_min: 0.000000, fs_max: 0.000000, denom: 0.000000\n",
            "  DEBUG fs_norm - Shape: (1000,), Min: 0.000000, Max: 0.000000, Mean: 0.000000\n",
            "  DEBUG fs_norm - First few values: [0. 0. 0. 0. 0.]\n",
            "  DEBUG fs_matrix - Shape: (1000, 1)\n",
            "  DEBUG fs_matrix - Sample values (first 3 features, first 2 seeds):\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "  DEBUG Applying Softmax normalization for JSD...\n",
            "  DEBUG X_softmax - Shape: (398, 1000)\n",
            "  DEBUG X_softmax - Sample values (first 3 samples, first 3 features):\n",
            "[[0.00251256 0.00251256 0.00251256]\n",
            " [0.00251256 0.00251256 0.00251256]\n",
            " [0.00251256 0.00251256 0.00251256]]\n",
            "  DEBUG X_softmax row sums (should be ~1.0 for each feature): Min: 1.000000, Max: 1.000000\n",
            "  DEBUG Initializing JSD matrix - Shape: (1000, 1)\n",
            "  DEBUG Computing JSD for seed 1/1: ARHGEF10L\n",
            "  DEBUG Seed profile (Softmax) - Shape: (398,), Min: 0.002513, Max: 0.002513\n",
            "  DEBUG JSD[0, 0] (feature 0 vs seed ARHGEF10L): 0.000000\n",
            "  DEBUG JSD[1, 0] (feature 1 vs seed ARHGEF10L): 0.000000\n",
            "  DEBUG JSD[2, 0] (feature 2 vs seed ARHGEF10L): 0.000000\n",
            "  DEBUG jsd_div matrix - Shape: (1000, 1)\n",
            "  DEBUG jsd_div matrix - Min: 0.000000, Max: 0.000000, Mean: 0.000000\n",
            "  DEBUG jsd_div matrix - Sample values (first 3 features, first 2 seeds):\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "  DEBUG Combining components into hybrid weights...\n",
            "  DEBUG alpha: 0.6, beta: 0.2\n",
            "  DEBUG Combined weights before clipping - Shape: (1000, 1)\n",
            "  DEBUG Combined weights before clipping - Min: 0.000000, Max: 0.000000, Mean: 0.000000\n",
            "  DEBUG Combined weights before clipping - Sample values (first 3 features, first 2 seeds):\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "  WARNING: All weights are identical before clipping.\n",
            "âš™ï¸ Weight matrix shape: (1000, 1)\n",
            "ðŸ“Œ Max weight: 0.0000 | Min weight: 0.0000\n",
            "  DEBUG Final weights after clipping - Sample values (first 3 features, first 2 seeds):\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "  ERROR: Final weight matrix collapsed - all values are identical.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "âŒ Weight matrix collapsed â€” check input similarity/JSD structure.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-919104391.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# feature_names = X_df.columns.tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mZ_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass raw X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ“‹ INFUSE Cohort Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2056642463.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hybrid_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_names_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Weight matrix computed: {weights.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: âŒ Weight matrix collapsed â€” check input similarity/JSD structure."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features)\n",
        "# y_encoded: Encoded target labels (n_samples,)\n",
        "# feature_names: Names of the m pre-filtered features\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- Define Original Feature Names ---\n",
        "# Assuming X_df is the original DataFrame loaded in Section 1\n",
        "feature_names_full = X_df.columns.tolist() # List of all original feature names (length 20530)\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"\\n--- Transforming Test Data with Pre-fitted INFUSE Model ---\")\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the pre-fitted 'infuse' model ---\n",
        "    # Assuming the fitted 'infuse' object stores the names of the features it retained\n",
        "    # after internal pre-filtering. This is typically stored in an attribute like feature_names_in_\n",
        "    # Let's assume it's feature_names_in_\n",
        "    infuse_selected_feature_names = infuse.feature_names_in_ # List of 1000 feature names\n",
        "    # If feature_names_full corresponds to the columns of X_train_full/X_test_full (20530 names)\n",
        "    # Find the indices of the 1000 features selected by 'infuse' within the full 20530\n",
        "    infuse_selected_indices = [feature_names_full.index(name) for name in infuse_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full and X_train_full to the 1000 features used by 'infuse' ---\n",
        "    X_test_full_for_infuse = X_test_full[:, infuse_selected_indices] # Shape (243, 1000)\n",
        "    X_train_full_for_infuse = X_train_full[:, infuse_selected_indices] # Shape (972, 1000)\n",
        "\n",
        "    # --- NOW: Transform using the correctly sized data ---\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full_for_infuse)\n",
        "    # Optionally, re-transform train data if needed for consistency in techniques dict\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full_for_infuse)\n",
        "\n",
        "    if Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "        # Update k_compare based on actual number of features produced\n",
        "        k_compare = max(2, Z_test_infuse_full.shape[1])\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "\n",
        "    # --- FIX: Fit infuse_train on the full-dimensional X_train_full ---\n",
        "    # INFUSE will handle its own pre-filtering internally.\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=10,\n",
        "        jsd_threshold=0.4,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        max_features=1000,\n",
        "        stability_thresh=0.5,\n",
        "        final_k=2,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Fit ONLY on the full-dimensional training data (972, 20530) and corresponding labels (972,)\n",
        "    # Pass the full feature names list corresponding to X_train_full's 20530 columns\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_full)\n",
        "\n",
        "    # --- FIX: Get the feature names/index used by the newly fitted 'infuse_train' model ---\n",
        "    # After fitting, infuse_train.feature_names_in_ should contain the 1000 names it retained\n",
        "    infuse_train_selected_feature_names = infuse_train.feature_names_in_\n",
        "    infuse_train_selected_indices = [feature_names_full.index(name) for name in infuse_train_selected_feature_names if name in feature_names_full]\n",
        "\n",
        "    # --- FIX: Subset X_test_full to the 1000 features used by 'infuse_train' ---\n",
        "    X_test_full_for_infuse_train = X_test_full[:, infuse_train_selected_indices] # Shape (243, 1000)\n",
        "\n",
        "    # --- NOW: Transform the correctly sized test data ---\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full_for_infuse_train)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        if n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "# Apply SelectKBest to the pre-filtered training data\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "# Apply to the pre-filtered training data\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "#X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "#X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "#estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "#rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "#X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "#X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "#techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "#print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                # Corrected formatting without colons outside braces\n",
        "                print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "aiQamdqsrYIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ZoQ73HRrYLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYO4eJyirYOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIcwuPSVrYRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7j_ZiMJrYUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgUlbgP4yL1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkjrqAbvyL4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LATEST FILES 07082025"
      ],
      "metadata": {
        "id": "68N7gMVzY_Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary connections (1 if neighbor, 0 otherwise)\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph = graph.toarray() # Convert to dense for easier handling\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph) / (graph.shape[0] * graph.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.4f}\")\n",
        "\n",
        "            return graph # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity and to reflect the final, robust implementation logic.\n"
      ],
      "metadata": {
        "id": "DURlSAtpyL8M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED _graph_regularization to build graph on X ---\n",
        "    # FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary connections (1 if neighbor, 0 otherwise)\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph = graph.toarray() # Convert to dense for easier handling\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph) / (graph.shape[0] * graph.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.4f}\")\n",
        "\n",
        "            return graph # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity and to reflect the final, robust implementation logic.\n",
        "\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity and to reflect the final, robust implementation logic.\n"
      ],
      "metadata": {
        "id": "e3ha9JkRe2qq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULsTukAddL1A",
        "outputId": "79f45fee-f7d6-45d9-b0a9-719a1afd78f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the final class definition\n",
        "# CRITICAL: Pass the FULL, RAW, IMPUTED data (X_raw_imputed) and full feature names (feature_names_full)\n",
        "# INFUSE handles its own scaling and pre-filtering (max_features=1000)\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,          # Number of initial seed candidates\n",
        "    jsd_threshold=0.35,  # JSD threshold for seed diversity\n",
        "    alpha=0.6,           # Weight for similarity in hybrid score\n",
        "    beta=0.2,            # Weight for JSD dissimilarity penalty\n",
        "    max_features=1000,   # INFUSE's internal pre-filtering parameter\n",
        "    stability_thresh=0.5, # Minimum stability score for a cohort to be kept\n",
        "    final_k=2,           # Number of cohorts to keep if none meet stability_thresh\n",
        "    n_bootstrap=100,     # Number of bootstrap iterations for stability\n",
        "    verbose=True,        # Print progress\n",
        "    random_state=42      # For reproducibility\n",
        ")\n",
        "\n",
        "# --- CRITICAL: Pass RAW, IMPUTED data to fit_transform ---\n",
        "# X_raw_imputed has shape (n_samples, p_original_features)\n",
        "# y_encoded has shape (n_samples,)\n",
        "# feature_names_full has length p_original_features\n",
        "try:\n",
        "    Z_final = infuse.fit_transform(X_raw_imputed, y_encoded, feature_names=feature_names_full)\n",
        "    print(f\"\\nâœ… INFUSE pipeline completed successfully.\")\n",
        "    print(f\"ðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    # Detailed analysis\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed before filtering: {len(infuse.cohort_members_) if hasattr(infuse, 'cohort_members_') else 'N/A'}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "    print(f\"Stability scores: {[f'{s:.4f}' for s in infuse.stabilities_] if hasattr(infuse, 'stabilities_') else 'N/A'}\")\n",
        "\n",
        "    # Use the describe_cohorts method for a detailed view\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ INFUSE pipeline failed: {type(e).__name__} - {e}\")\n",
        "    Z_final = np.empty((X_raw_imputed.shape[0], 0)) # Return empty matrix on failure\n",
        "    # Optionally, print more details about the fitted infuse object for debugging\n",
        "    # if hasattr(infuse, 'is_fitted_') and infuse.is_fitted_:\n",
        "    #     print(\"  INFUSE object attributes after failure:\")\n",
        "    #     print(f\"    is_fitted_: {infuse.is_fitted_}\")\n",
        "    #     print(f\"    seeds_: {getattr(infuse, 'seeds_', 'N/A')}\")\n",
        "    #     print(f\"    kept_indices_: {getattr(infuse, 'kept_indices_', 'N/A')}\")\n",
        "    #     print(f\"    stabilities_: {getattr(infuse, 'stabilities_', 'N/A')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqC_spGddL4P",
        "outputId": "d37a27ae-ce10-4517-92bb-d64fff8bd469"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âš™ï¸ Weight matrix shape: (1000, 8)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "âš ï¸ Graph construction failed: Negative values in data passed to X.. Using fully connected graph.\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 1000\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            " No stable features met threshold. Keeping top 2.\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "\n",
            "âœ… INFUSE pipeline completed successfully.\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 2)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id seed_gene  num_members  \\\n",
            "0          0     KLF10         1000   \n",
            "1          1    CLEC4M         1000   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...   0.046160  \n",
            "1  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...   0.044257  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed before filtering: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 2\n",
            "Stability scores: ['0.0462', '0.0416', '0.0414', '0.0391', '0.0391', '0.0416', '0.0443', '0.0415']\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.05\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 1 | Seed: CLEC4M | Stability: 0.04\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "revJxGtpdMeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0_X_HZah6sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FW4RaRqXh6wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6kHWZakh6za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression data: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical data: {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# --- Address Class Imbalance ---\n",
        "print(\"\\n--- Addressing Class Imbalance: Undersampling Majority Class ---\")\n",
        "# Check initial label distribution\n",
        "y_series = pd.Series(y)\n",
        "initial_label_counts = y_series.value_counts()\n",
        "print(f\"  Initial label distribution: {initial_label_counts.to_dict()}\")\n",
        "\n",
        "# Create a temporary DataFrame for resampling\n",
        "df_temp = pd.concat([X_df, y_series.rename('target')], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "majority_class = initial_label_counts.idxmax()\n",
        "minority_class = initial_label_counts.idxmin()\n",
        "df_majority = df_temp[df_temp.target == majority_class]\n",
        "df_minority = df_temp[df_temp.target == minority_class]\n",
        "\n",
        "print(f\"  Before Resampling:\")\n",
        "print(f\"    Majority class ({majority_class}) samples: {len(df_majority)}\")\n",
        "print(f\"    Minority class ({minority_class}) samples: {len(df_minority)}\")\n",
        "\n",
        "# Downsample majority class to match minority class size\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority),\n",
        "                                   random_state=42)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract balanced X and y\n",
        "X_df_balanced = df_balanced.drop('target', axis=1)\n",
        "y_balanced = df_balanced['target'].values\n",
        "\n",
        "print(f\"  After Undersampling:\")\n",
        "print(f\"    Balanced dataset size: {X_df_balanced.shape[0]}\")\n",
        "final_label_counts = pd.Series(y_balanced).value_counts()\n",
        "print(f\"    Final label distribution: {final_label_counts.to_dict()}\")\n",
        "\n",
        "# --- Continue with standard preprocessing on the BALANCED data ---\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_balanced)\n",
        "print(f\" Final encoded label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# --- Scale expression data ROBUSTLY ---\n",
        "print(\"\\n--- Scaling Expression Data ---\")\n",
        "scaler = StandardScaler()\n",
        "try:\n",
        "    # Fit and transform the balanced, imputed data\n",
        "    X_scaled_balanced = scaler.fit_transform(X_df_balanced.values)\n",
        "    print(f\"âœ… Data successfully scaled. Final scaled data shape: {X_scaled_balanced.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âŒ Error during scaling: {e}\")\n",
        "    # Handle potential edge cases (should be rare after imputation)\n",
        "    X_scaled_balanced = np.empty((X_df_balanced.shape[0], 0))\n",
        "    print(f\"   Returned empty scaled data matrix.\")\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df_balanced.columns.tolist()\n",
        "print(f\" First 10 genes (balanced data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X): {X_scaled_balanced.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Assign final outputs for use in subsequent sections ---\n",
        "X = X_scaled_balanced  # Use the scaled, balanced, CLEANED data\n",
        "y = y_encoded          # Use the encoded, balanced labels\n",
        "# feature_names now refers to the features in the balanced, scaled data\n"
      ],
      "metadata": {
        "id": "gB0O8Y2RyL_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfa3658-8f5d-464c-fe85-3ad0de4fdce5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression data: (1218, 20530)\n",
            " Loaded clinical data: (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            "\n",
            "--- Addressing Class Imbalance: Undersampling Majority Class ---\n",
            "  Initial label distribution: {'Alive': 1016, 'Dead': 199}\n",
            "  Before Resampling:\n",
            "    Majority class (Alive) samples: 1016\n",
            "    Minority class (Dead) samples: 199\n",
            "  After Undersampling:\n",
            "    Balanced dataset size: 398\n",
            "    Final label distribution: {'Alive': 199, 'Dead': 199}\n",
            " Final encoded label distribution: {'Alive': np.int64(199), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Scaling Expression Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data successfully scaled. Final scaled data shape: (398, 20530)\n",
            " First 10 genes (balanced data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation & Undersampling) Completed:\n",
            "   - Final Data Matrix Shape (X): (398, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (398,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [199 199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFUSE Execution\n",
        "\n",
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=10,\n",
        "    jsd_threshold=0.4,  # Increased threshold (as discussed)\n",
        "    # min_cohort_size=3,  # <-- Remove this line\n",
        "    # max_cohort_size=30, # <-- Remove this line\n",
        "    # Consider adjusting other parameters if needed, e.g., alpha, beta, final_k\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NGsg0vvJc6AB",
        "outputId": "a1632f49-98f0-4db9-84cf-cc647ed1e615"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Handling NaNs in input data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-1472139356.py:153: RuntimeWarning: All-NaN slice encountered\n",
            "  col_medians = np.nanmedian(X, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [    0     1     2 ... 20527 20528 20529] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
            " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
            " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
            " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
            " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
            " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
            " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
            " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
            " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
            " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
            " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
            " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
            " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
            " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
            " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
            " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
            " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
            " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
            " 990 991 992 993 994 995 996 997 998 999] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['ARHGEF10L', 'RTP1', 'RTP3', 'RTP2', 'RTP4', 'PSMD2', 'PSMD3', 'KIAA1731', 'ZNF704', 'LOC339240']\n",
            " Seeds (filtered): ['ARHGEF10L']\n",
            "âœ… Similarity matrix computed: (1000, 1)\n",
            "âš™ï¸ Weight matrix shape: (1000, 1)\n",
            "ðŸ“Œ Max weight: 0.0000 | Min weight: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "âŒ Weight matrix collapsed â€” check input similarity/JSD structure.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-919104391.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# feature_names = X_df.columns.tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mZ_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass raw X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ“‹ INFUSE Cohort Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1472139356.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hybrid_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_names_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Weight matrix computed: {weights.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: âŒ Weight matrix collapsed â€” check input similarity/JSD structure."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4cJPzOGc6DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_BIzDCxc6GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbmZ28rRc6Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNnucLXMifCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latest 070825 B"
      ],
      "metadata": {
        "id": "KumOkdVKigdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        # --- CRITICAL: Ensure ALL hyperparameters are assigned to self ---\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features  # <-- THIS LINE WAS MISSING OR INCORRECT\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        # --- Initialize internal attributes ---\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "        # --- Initialize other attributes that will be set during fit_transform ---\n",
        "        self.feature_names_in_ = None\n",
        "        self.fscores_ = None\n",
        "        self.seeds_ = None\n",
        "        self.cohort_weights_ = None\n",
        "        self.cohort_members_ = None\n",
        "        self.kept_indices_ = None\n",
        "        self.stabilities_ = None\n",
        "        # --- END OF __init__ ---\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "        Executes the full INFUSE pipeline.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # --- Handle feature names ---\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # --- Handle NaNs ---\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # --- CRITICAL: Pre-filtering using self.max_features ---\n",
        "        # This is where the AttributeError likely occurred if self.max_features was not set\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features] # <-- Uses self.max_features\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X_scaled, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "\n",
        "        # Dissimilarity filtering\n",
        "        seed_names_filtered = self._dissimilarity_filter(X_scaled, seed_names_raw)\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X_scaled, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "\n",
        "        # Hybrid weighting\n",
        "        weights = self._hybrid_weights(X_scaled, seed_names_filtered, similarities)\n",
        "\n",
        "        # Graph regularization\n",
        "        graph = self._graph_regularization(X_scaled, seed_names_filtered)\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X_scaled, weights, graph, seed_names_filtered)\n",
        "\n",
        "        # Final filtering\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Apply Softmax normalization to ensure non-negative values\n",
        "            X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X_softmax.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,               # Use the automatically determined k\n",
        "                mode='connectivity',              # Binary adjacency matrix\n",
        "                include_self=False,               # Important: Seed should be explicitly added later\n",
        "                metric='cosine',                  # Use cosine distance between feature profiles\n",
        "                n_jobs=-1                         # Use all cores for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "w-fZzQULifF1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.1 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, # <-- Updated default threshold\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # --- CRITICAL: Assign scaled data to X_scaled ---\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Data scaled: {X_scaled.shape}\")\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X_scaled, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X_scaled, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X_scaled to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X_scaled, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X_scaled, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X_scaled for feature graph\n",
        "        # --- PASS X_scaled, NOT weights ---\n",
        "        graph = self._graph_regularization(X_scaled, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X_scaled, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use r_pb^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X_scaled ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Assign scaled data to X_scaled_for_graph ---\n",
        "            # This ensures X_scaled_for_graph is defined in the local scope\n",
        "            X_scaled_for_graph = X # X is already scaled from fit_transform/transform\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X_scaled_for_graph.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # --- PASS X_scaled_for_graph.T, NOT weights ---\n",
        "            graph = kneighbors_graph(\n",
        "                X_scaled_for_graph.T,         # Transpose so features are rows\n",
        "                n_neighbors=auto_k,           # Use the automatically determined k\n",
        "                mode='connectivity',          # Binary adjacency matrix\n",
        "                include_self=False,           # Important: Seed should be explicitly added later\n",
        "                metric='cosine',              # Use cosine distance between feature profiles\n",
        "                n_jobs=1                      # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        # --- CRITICAL: Scale the input data using the fitted scaler ---\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X_scaled\n",
        "        # --- PASS X_scaled, NOT weights ---\n",
        "        graph = self._graph_regularization(X_scaled, self.seeds_) # Pass X_scaled\n",
        "        Z_fused, _ = self._cohort_fusion(X_scaled, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity but can be included if needed elsewhere.\n",
        "\n"
      ],
      "metadata": {
        "id": "aVtHLUuKvnrc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rlSQKWFifJT",
        "outputId": "7b0420ac-2103-4cde-8265-36b9035e9901"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the final class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    jsd_threshold=0.35,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,\n",
        "    final_k=2,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- CRITICAL: Pass RAW, IMPUTED data to fit_transform ---\n",
        "# X_raw_imputed has shape (n_samples, p_original_features)\n",
        "# y_encoded has shape (n_samples,)\n",
        "# feature_names_full has length p_original_features\n",
        "try:\n",
        "    Z_final = infuse.fit_transform(X_raw_imputed, y_encoded, feature_names=feature_names_full)\n",
        "    print(f\"\\nâœ… INFUSE pipeline completed successfully.\")\n",
        "    print(f\"ðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    # Detailed analysis\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed before filtering: {len(infuse.cohort_members_) if hasattr(infuse, 'cohort_members_') else 'N/A'}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "    print(f\"Stability scores: {[f'{s:.4f}' for s in infuse.stabilities_] if hasattr(infuse, 'stabilities_') else 'N/A'}\")\n",
        "\n",
        "    # Use the describe_cohorts method for a detailed view\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ INFUSE pipeline failed: {type(e).__name__} - {e}\")\n",
        "    Z_final = np.empty((X_raw_imputed.shape[0], 0)) # Return empty matrix on failure\n",
        "    # Optionally, print more details about the fitted infuse object for debugging\n",
        "    # if hasattr(infuse, 'is_fitted_') and infuse.is_fitted_:\n",
        "    #     print(\"  INFUSE object attributes after failure:\")\n",
        "    #     print(f\"    is_fitted_: {infuse.is_fitted_}\")\n",
        "    #     print(f\"    seeds_: {getattr(infuse, 'seeds_', 'N/A')}\")\n",
        "    #     print(f\"    kept_indices_: {getattr(infuse, 'kept_indices_', 'N/A')}\")\n",
        "    #     print(f\"    stabilities_: {getattr(infuse, 'stabilities_', 'N/A')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OantlRsKifM-",
        "outputId": "31072f6a-3993-4e3e-d35d-a506dc51c502"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data scaled: (1215, 1000)\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âš™ï¸ Weight matrix shape: (1000, 8)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            " No stable features met threshold. Keeping top 2.\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "\n",
            "âœ… INFUSE pipeline completed successfully.\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 2)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id seed_gene  num_members  \\\n",
            "0          0    CLEC4M            6   \n",
            "1          1     KLF10            6   \n",
            "\n",
            "                                       member_genes  stability  \n",
            "0  [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.044870  \n",
            "1     [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.043768  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed before filtering: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 2\n",
            "Stability scores: ['0.0438', '0.0304', '0.0346', '0.0332', '0.0342', '0.0378', '0.0449', '0.0329']\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: CLEC4M | Stability: 0.04\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            " Cohort 1 | Seed: KLF10 | Stability: 0.04\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-t1e_9AlifQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OqZXv-Jw4P1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 3.2 (Robust Implementation with Constant Feature Handling and Updated Parameters)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        # --- UPDATE: Use 'ensure_all_finite' instead of 'force_all_finite' ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # --- FIX: Handle Constant Features Before Pre-filtering ---\n",
        "        # Check for constant features and remove them to prevent numerical instability\n",
        "        constant_feature_mask = np.all(X == X[0, :], axis=0)\n",
        "        n_constant_features = np.sum(constant_feature_mask)\n",
        "        if n_constant_features > 0:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Found {n_constant_features} constant features. Removing them before pre-filtering.\")\n",
        "            X = X[:, ~constant_feature_mask]\n",
        "            self.feature_names_in_ = [name for name, is_const in zip(self.feature_names_in_, constant_feature_mask) if not is_const]\n",
        "            if self.verbose:\n",
        "                print(f\"   Data shape after removing constant features: {X.shape}\")\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            # --- FIX: Handle Constant Features Before F-score Calculation ---\n",
        "            # Check for constant features within the pre-filtering step\n",
        "            constant_feature_mask_prefilter = np.all(X == X[0, :], axis=0)\n",
        "            n_constant_features_prefilter = np.sum(constant_feature_mask_prefilter)\n",
        "            if n_constant_features_prefilter > 0:\n",
        "                if self.verbose:\n",
        "                    print(f\"âš ï¸ Found {n_constant_features_prefilter} constant features during pre-filtering. Removing them.\")\n",
        "                X_temp = X[:, ~constant_feature_mask_prefilter]\n",
        "                self.feature_names_in_temp = [name for name, is_const in zip(self.feature_names_in_, constant_feature_mask_prefilter) if not is_const]\n",
        "            else:\n",
        "                X_temp = X\n",
        "                self.feature_names_in_temp = self.feature_names_in_\n",
        "\n",
        "            scores, _ = f_classif(X_temp, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X_temp[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_temp[i] for i in top_idx]\n",
        "            if self.verbose:\n",
        "                print(f\"   Data shape after pre-filtering: {X.shape}\")\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # --- FIX: Handle Constant Features After Scaling ---\n",
        "        # Check for constant features after scaling and remove them\n",
        "        constant_feature_mask_scaled = np.all(np.isclose(X, X[0, :], atol=1e-8), axis=0)\n",
        "        n_constant_features_scaled = np.sum(constant_feature_mask_scaled)\n",
        "        if n_constant_features_scaled > 0:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Found {n_constant_features_scaled} constant features after scaling. Removing them.\")\n",
        "            X = X[:, ~constant_feature_mask_scaled]\n",
        "            self.feature_names_in_ = [name for name, is_const in zip(self.feature_names_in_, constant_feature_mask_scaled) if not is_const]\n",
        "            if self.verbose:\n",
        "                print(f\"   Data shape after removing constant features: {X.shape}\")\n",
        "\n",
        "        # Seed selection\n",
        "        # --- FIX: Handle Constant Features Before Seed Selection ---\n",
        "        # Check for constant features within the seed selection step\n",
        "        constant_feature_mask_seeds = np.all(np.isclose(X, X[0, :], atol=1e-8), axis=0)\n",
        "        n_constant_features_seeds = np.sum(constant_feature_mask_seeds)\n",
        "        if n_constant_features_seeds > 0:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Found {n_constant_features_seeds} constant features during seed selection. Removing them.\")\n",
        "            X_temp_seeds = X[:, ~constant_feature_mask_seeds]\n",
        "            self.feature_names_in_temp_seeds = [name for name, is_const in zip(self.feature_names_in_, constant_feature_mask_seeds) if not is_const]\n",
        "        else:\n",
        "            X_temp_seeds = X\n",
        "            self.feature_names_in_temp_seeds = self.feature_names_in_\n",
        "\n",
        "        scores, _ = f_classif(X_temp_seeds, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_temp_seeds[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_temp_seeds.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X_temp_seeds, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X_temp_seeds, columns=self.feature_names_in_temp_seeds)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X_temp_seeds, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X_temp_seeds, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X_temp_seeds, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use r_pb^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_temp_seeds.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_temp_seeds[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_temp_seeds])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_temp_seeds.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        This method correctly builds the graph on the feature data X using cosine distance.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Build graph directly on X.T using cosine distance ---\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_temp_seeds.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_temp_seeds[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "ZEsoWQxG4P42"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nL7zSmoX765A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtSc5x4Y77sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_debug_v4.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.0 (Debugging Focus Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with extensive debugging capabilities.\n",
        "# INFUSE is a transformer designed for high-dimensional biological data\n",
        "# (e.g., gene expression) to construct new, stable, and potentially interpretable\n",
        "# cohort features. It integrates concepts of seed selection, multi-criteria\n",
        "# hybrid weighting, graph-based regularization, and empirical stability evaluation.\n",
        "# This version prioritizes exposing internal states for debugging.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Re-enable for debugging\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation (Debugging Version).\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    This version includes extensive debugging prints.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"INFUSE DEBUG VERSION 4.0 - STARTING FIT_TRANSFORM\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Initial Data Shape: {X.shape}\")\n",
        "            print(f\"âœ… Initial Target Shape: {y.shape}\")\n",
        "            print(f\"âœ… Unique target values: {np.unique(y)}\")\n",
        "            print(f\"âœ… Target distribution: {dict(zip(np.unique(y), np.bincount(y)))}\")\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Data shape after pre-filtering: {X.shape}\")\n",
        "\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Data scaled: {X_scaled.shape}\")\n",
        "            print(f\"   X_scaled range: [{X_scaled.min():.4f}, {X_scaled.max():.4f}]\")\n",
        "            print(f\"   X_scaled mean: {X_scaled.mean():.4f}, std: {X_scaled.std():.4f}\")\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X_scaled, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw[:5]}...\") # Show first 5\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X_scaled, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X_scaled, columns=self.feature_names_in_)\n",
        "\n",
        "        # --- DEBUGGING: Inspect Similarity Matrix ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Similarity Matrix...\")\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "            print(f\"   Similarity matrix range: [{similarities.min():.4f}, {similarities.max():.4f}]\")\n",
        "            print(f\"   Similarity matrix sample (first 3 features vs first 2 seeds):\\n{similarities[:3, :min(2, similarities.shape[1])] if similarities.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Hybrid Weights ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Hybrid Weights...\")\n",
        "        weights = self._hybrid_weights(X_scaled, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "            print(f\"   Weight matrix range: [{weights.min():.4f}, {weights.max():.4f}]\")\n",
        "            print(f\"   Weight matrix sample (first 3 features vs first 2 seeds):\\n{weights[:3, :min(2, weights.shape[1])] if weights.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Graph Regularization ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Graph Regularization...\")\n",
        "        graph = self._graph_regularization(X_scaled, seed_names_filtered) # Pass X_scaled\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "            print(f\"   Graph density: {np.count_nonzero(graph) / (graph.shape[0] * graph.shape[1]):.6f}\")\n",
        "            # Show sparsity pattern for first 50 features\n",
        "            if graph.shape[0] > 50:\n",
        "                print(f\"   Graph sparsity pattern (first 50x50):\")\n",
        "                subset_graph = graph[:50, :50]\n",
        "                for i in range(min(10, subset_graph.shape[0])): # Print first 10 rows\n",
        "                    row_str = \"\".join([\"1\" if val > 0 else \"0\" for val in subset_graph[i, :min(50, subset_graph.shape[1])]])\n",
        "                    print(f\"     Row {i:2d}: {row_str}\")\n",
        "            else:\n",
        "                print(f\"   Graph sparsity pattern (full {graph.shape[0]}x{graph.shape[1]}):\")\n",
        "                for i in range(graph.shape[0]):\n",
        "                    row_str = \"\".join([\"1\" if val > 0 else \"0\" for val in graph[i, :]])\n",
        "                    print(f\"     Row {i:2d}: {row_str}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Cohort Fusion ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Performing Cohort Fusion...\")\n",
        "        Z, cohorts = self._cohort_fusion(X_scaled, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "            # Analyze cohort sizes\n",
        "            if hasattr(self, 'cohort_members_'):\n",
        "                cohort_sizes = [len(c['members']) for c in self.cohort_members_]\n",
        "                print(f\"   Cohort sizes: {cohort_sizes}\")\n",
        "                print(f\"   Min cohort size: {min(cohort_sizes) if cohort_sizes else 'N/A'}\")\n",
        "                print(f\"   Max cohort size: {max(cohort_sizes) if cohort_sizes else 'N/A'}\")\n",
        "                print(f\"   Avg cohort size: {np.mean(cohort_sizes):.2f}\" if cohort_sizes else \"N/A\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Final Filtering ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Performing Final Filtering...\")\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "            print(f\"   Kept indices: {kept}\")\n",
        "            print(f\"   Stability scores: {[f'{s:.4f}' for s in stabilities]}\")\n",
        "            if len(stabilities) > 0:\n",
        "                print(f\"   Max stability: {max(stabilities):.4f}\")\n",
        "                print(f\"   Min stability: {min(stabilities):.4f}\")\n",
        "                print(f\"   Avg stability: {np.mean(stabilities):.4f}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts # Save cohort details\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"INFUSE DEBUG VERSION 4.0 - FIT_TRANSFORM COMPLETED\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _dissimilarity_filter input X shape: {X.shape}\")\n",
        "            print(f\"   _dissimilarity_filter input seed_names: {seed_names[:3]}...\") # Show first 3\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if self.verbose and i < 3 and j < 3: # Debug first few comparisons\n",
        "                    print(f\"     JSD({seed_indices[i]}, {j}) = {jsd:.4f}\")\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    if self.verbose and i < 3:\n",
        "                        print(f\"     Seed {seed_indices[i]} is REDUNDANT with {j} (JSD < {self.jsd_threshold})\")\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "                if self.verbose and i < 3:\n",
        "                    print(f\"     Seed {seed_indices[i]} is UNIQUE. Added to filtered list.\")\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        if self.verbose:\n",
        "            print(f\"   _dissimilarity_filter output filtered_names: {filtered_names}\")\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        if self.verbose:\n",
        "            print(f\"   _hybrid_weights input X shape: {X.shape}\")\n",
        "            print(f\"   _hybrid_weights input seed_names: {seed_names[:3]}...\") # Show first 3\n",
        "            print(f\"   _hybrid_weights input similarities shape: {similarities.shape}\")\n",
        "\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "                 if self.verbose and i == 0 and j < 3: # Debug first seed, first 3 features\n",
        "                     print(f\"     JSD({j}, Seed:{seed_idx}) = {jsd_div[j, i]:.4f}\")\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"   _hybrid_weights output weights shape: {weights.shape}\")\n",
        "            print(f\"   _hybrid_weights output weights range: [{weights.min():.4f}, {weights.max():.4f}]\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X_scaled ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Build graph directly on X.T using cosine distance ---\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        if self.verbose:\n",
        "            print(f\"   _cohort_fusion input X shape: {X.shape}\")\n",
        "            print(f\"   _cohort_fusion input weights shape: {weights.shape}\")\n",
        "            print(f\"   _cohort_fusion input graph shape: {graph.shape}\")\n",
        "            print(f\"   _cohort_fusion input seed_names: {seed_names}\")\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Initial neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "                if self.verbose and i < 3:\n",
        "                     print(f\"     Cohort {i} (Seed: {seed_name}) - Seed added. Final neighbors: {len(neighbors)}\")\n",
        "            else:\n",
        "                if self.verbose and i < 3:\n",
        "                     print(f\"     Cohort {i} (Seed: {seed_name}) - Seed already included. Final neighbors: {len(neighbors)}\")\n",
        "\n",
        "            # --- CRITICAL DEBUG: Check if neighbors include ALL features ---\n",
        "            if len(neighbors) == X.shape[1]:\n",
        "                if self.verbose:\n",
        "                    print(f\"     âš ï¸ CRITICAL DEBUG: Cohort {i} has ALL {X.shape[1]} features as neighbors!\")\n",
        "                    print(f\"     âš ï¸ This indicates a potential issue with the graph structure.\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weights retrieved: {w.shape}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weight sum: {w.sum():.4f}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - First 5 weights: {w[:min(5, len(w))] if len(w) > 0 else '[]'}\")\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weights normalized: {w.shape}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Normalized weight sum: {w.sum():.4f}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - First 5 normalized weights: {w[:min(5, len(w))] if len(w) > 0 else '[]'}\")\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Fused vector shape: {fused_vec.shape}\")\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _cohort_fusion output Z shape: {Z.shape}\")\n",
        "            print(f\"   _cohort_fusion output members length: {len(members)}\")\n",
        "\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        if self.verbose:\n",
        "            print(f\"   _final_filter input Z shape: {Z.shape}\")\n",
        "            print(f\"   _final_filter input y shape: {y.shape}\")\n",
        "            print(f\"   _final_filter stability_thresh: {self.stability_thresh}\")\n",
        "            print(f\"   _final_filter final_k: {self.final_k}\")\n",
        "            print(f\"   _final_filter n_bootstrap: {self.n_bootstrap}\")\n",
        "\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for b in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                             if self.verbose and i < 3 and b < 5: # Debug first 3 cohorts, first 5 bootstraps\n",
        "                                 print(f\"     Bootstrap {b} for Cohort {i}: r_pb={r_pb:.4f}, r_pb^2={r_pb_squared:.4f}\")\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "                             if self.verbose and i < 3 and b < 5:\n",
        "                                 print(f\"     Bootstrap {b} for Cohort {i}: Invalid r_pb^2 (NaN/Inf), set to 0.0\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                        if self.verbose and i < 3 and b < 5:\n",
        "                            print(f\"     Bootstrap {b} for Cohort {i}: Calculation failed, set to 0.0\")\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "                    if self.verbose and i < 3 and b < 5:\n",
        "                        print(f\"     Bootstrap {b} for Cohort {i}: Only one class, set to 0.0\")\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "            if self.verbose and i < 3:\n",
        "                print(f\"   Cohort {i} stability score S_j: {S_j:.4f}\")\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "                print(f\"   Kept indices from top: {kept}\")\n",
        "                print(f\"   Corresponding stability scores: {[f'{stabilities[i]:.4f}' for i in kept]}\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "                if self.verbose:\n",
        "                    print(f\" Ultimate fallback: Keeping cohort 0.\")\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            if self.verbose:\n",
        "                print(f\" Final fallback: No cohorts kept, returning empty matrix.\")\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _final_filter output kept indices: {kept}\")\n",
        "            print(f\"   _final_filter output stabilities: {[f'{s:.4f}' for s in stabilities]}\")\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X_scaled\n",
        "        graph = self._graph_regularization(X_scaled, self.seeds_) # Pass X_scaled\n",
        "        Z_fused, _ = self._cohort_fusion(X_scaled, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "pPyiXcU377wY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yJZQeve4P8Z",
        "outputId": "848be236-b12b-4339-8e3c-2bb4356d9d28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the final class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    jsd_threshold=0.35,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,\n",
        "    final_k=2,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- CRITICAL: Pass RAW, IMPUTED data to fit_transform ---\n",
        "# X_raw_imputed has shape (n_samples, p_original_features)\n",
        "# y_encoded has shape (n_samples,)\n",
        "# feature_names_full has length p_original_features\n",
        "try:\n",
        "    Z_final = infuse.fit_transform(X_raw_imputed, y_encoded, feature_names=feature_names_full)\n",
        "    print(f\"\\nâœ… INFUSE pipeline completed successfully.\")\n",
        "    print(f\"ðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    # Detailed analysis\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed before filtering: {len(infuse.cohort_members_) if hasattr(infuse, 'cohort_members_') else 'N/A'}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "    print(f\"Stability scores: {[f'{s:.4f}' for s in infuse.stabilities_] if hasattr(infuse, 'stabilities_') else 'N/A'}\")\n",
        "\n",
        "    # Use the describe_cohorts method for a detailed view\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ INFUSE pipeline failed: {type(e).__name__} - {e}\")\n",
        "    Z_final = np.empty((X_raw_imputed.shape[0], 0)) # Return empty matrix on failure\n",
        "    # Optionally, print more details about the fitted infuse object for debugging\n",
        "    # if hasattr(infuse, 'is_fitted_') and infuse.is_fitted_:\n",
        "    #     print(\"  INFUSE object attributes after failure:\")\n",
        "    #     print(f\"    is_fitted_: {infuse.is_fitted_}\")\n",
        "    #     print(f\"    seeds_: {getattr(infuse, 'seeds_', 'N/A')}\")\n",
        "    #     print(f\"    kept_indices_: {getattr(infuse, 'kept_indices_', 'N/A')}\")\n",
        "    #     print(f\"    stabilities_: {getattr(infuse, 'stabilities_', 'N/A')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgDOBwSE4QAL",
        "outputId": "b768af31-cea8-448e-eaeb-0a17f276ffea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "INFUSE DEBUG VERSION 4.0 - STARTING FIT_TRANSFORM\n",
            "============================================================\n",
            "âœ… Initial Data Shape: (1215, 20530)\n",
            "âœ… Initial Target Shape: (1215,)\n",
            "âœ… Unique target values: [0 1]\n",
            "âœ… Target distribution: {np.int64(0): np.int64(1016), np.int64(1): np.int64(199)}\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data shape after pre-filtering: (1215, 1000)\n",
            "âœ… Data scaled: (1215, 1000)\n",
            "   X_scaled range: [-7.7837, 20.1326]\n",
            "   X_scaled mean: 0.0000, std: 1.0000\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4']...\n",
            "   _dissimilarity_filter input X shape: (1215, 1000)\n",
            "   _dissimilarity_filter input seed_names: ['KLF10', 'APOB', 'LEPR']...\n",
            "     Seed 0 is UNIQUE. Added to filtered list.\n",
            "     JSD(1, 0) = 0.4158\n",
            "     Seed 1 is UNIQUE. Added to filtered list.\n",
            "     JSD(2, 0) = 0.3310\n",
            "     Seed 2 is REDUNDANT with 0 (JSD < 0.35)\n",
            "   _dissimilarity_filter output filtered_names: ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "\n",
            "ðŸ” DEBUG: Computing Similarity Matrix...\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "   Similarity matrix range: [-0.5896, 1.0000]\n",
            "   Similarity matrix sample (first 3 features vs first 2 seeds):\n",
            "[[1.         0.43951553]\n",
            " [0.43951553 1.        ]\n",
            " [0.5334556  0.65287029]]\n",
            "\n",
            "ðŸ” DEBUG: Computing Hybrid Weights...\n",
            "   _hybrid_weights input X shape: (1215, 1000)\n",
            "   _hybrid_weights input seed_names: ['KLF10', 'APOB', 'ADH4']...\n",
            "   _hybrid_weights input similarities shape: (1000, 8)\n",
            "     JSD(0, Seed:0) = 0.0000\n",
            "     JSD(1, Seed:0) = 0.4158\n",
            "     JSD(2, Seed:0) = 0.3310\n",
            "   _hybrid_weights output weights shape: (1000, 8)\n",
            "   _hybrid_weights output weights range: [0.0000, 1.0000]\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Weight matrix range: [0.0000, 1.0000]\n",
            "   Weight matrix sample (first 3 features vs first 2 seeds):\n",
            "[[1.         0.58055382]\n",
            " [0.53797263 0.95741881]\n",
            " [0.60587257 0.67979358]]\n",
            "\n",
            "ðŸ” DEBUG: Computing Graph Regularization...\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Graph density: 0.005000\n",
            "   Graph sparsity pattern (first 50x50):\n",
            "     Row  0: 00000000000000000010000000010000000000000000000000\n",
            "     Row  1: 00000000000000000000000000000000000000000000000000\n",
            "     Row  2: 00000000000000000000000000000000000000000000000000\n",
            "     Row  3: 00000000000000000000000000000000000000000000000000\n",
            "     Row  4: 00000000000100000000000000000000000000000000000000\n",
            "     Row  5: 00000000000000000000000000000000000000000000000000\n",
            "     Row  6: 00000000000000000000000000000000000000000000000000\n",
            "     Row  7: 00000000000000000000000000010000000000000000000000\n",
            "     Row  8: 00000000000010100000000000000000010000000000000000\n",
            "     Row  9: 00000000000100000000000000000000001000000000000000\n",
            "\n",
            "ðŸ” DEBUG: Performing Cohort Fusion...\n",
            "   _cohort_fusion input X shape: (1215, 1000)\n",
            "   _cohort_fusion input weights shape: (1000, 8)\n",
            "   _cohort_fusion input graph shape: (1000, 1000)\n",
            "   _cohort_fusion input seed_names: ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "     Cohort 0 (Seed: KLF10) - Initial neighbors found: 5\n",
            "     Cohort 0 (Seed: KLF10) - Seed added. Final neighbors: 6\n",
            "     Cohort 0 (Seed: KLF10) - Weights retrieved: (6,)\n",
            "     Cohort 0 (Seed: KLF10) - Weight sum: 2.6373\n",
            "     Cohort 0 (Seed: KLF10) - First 5 weights: [0.5703409  0.27453336 0.27358504 0.25369961 0.26514381]\n",
            "     Cohort 0 (Seed: KLF10) - Weights normalized: (6,)\n",
            "     Cohort 0 (Seed: KLF10) - Normalized weight sum: 1.0000\n",
            "     Cohort 0 (Seed: KLF10) - First 5 normalized weights: [0.21625917 0.10409627 0.10373668 0.09619662 0.10053598]\n",
            "     Cohort 0 (Seed: KLF10) - Fused vector shape: (1215,)\n",
            "     Cohort 1 (Seed: APOB) - Initial neighbors found: 5\n",
            "     Cohort 1 (Seed: APOB) - Seed added. Final neighbors: 6\n",
            "     Cohort 1 (Seed: APOB) - Weights retrieved: (6,)\n",
            "     Cohort 1 (Seed: APOB) - Weight sum: 3.1215\n",
            "     Cohort 1 (Seed: APOB) - First 5 weights: [0.42415243 0.42857108 0.43367932 0.43762826 0.44000924]\n",
            "     Cohort 1 (Seed: APOB) - Weights normalized: (6,)\n",
            "     Cohort 1 (Seed: APOB) - Normalized weight sum: 1.0000\n",
            "     Cohort 1 (Seed: APOB) - First 5 normalized weights: [0.13588274 0.13729831 0.13893481 0.1401999  0.14096268]\n",
            "     Cohort 1 (Seed: APOB) - Fused vector shape: (1215,)\n",
            "     Cohort 2 (Seed: ADH4) - Initial neighbors found: 5\n",
            "     Cohort 2 (Seed: ADH4) - Seed added. Final neighbors: 6\n",
            "     Cohort 2 (Seed: ADH4) - Weights retrieved: (6,)\n",
            "     Cohort 2 (Seed: ADH4) - Weight sum: 2.9657\n",
            "     Cohort 2 (Seed: ADH4) - First 5 weights: [0.67124207 0.36142156 0.33238297 0.33972991 0.32572659]\n",
            "     Cohort 2 (Seed: ADH4) - Weights normalized: (6,)\n",
            "     Cohort 2 (Seed: ADH4) - Normalized weight sum: 1.0000\n",
            "     Cohort 2 (Seed: ADH4) - First 5 normalized weights: [0.22633378 0.12186648 0.11207506 0.11455235 0.10983062]\n",
            "     Cohort 2 (Seed: ADH4) - Fused vector shape: (1215,)\n",
            "   _cohort_fusion output Z shape: (1215, 8)\n",
            "   _cohort_fusion output members length: 8\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "\n",
            "ðŸ” DEBUG: Performing Final Filtering...\n",
            "   _final_filter input Z shape: (1215, 8)\n",
            "   _final_filter input y shape: (1215,)\n",
            "   _final_filter stability_thresh: 0.5\n",
            "   _final_filter final_k: 2\n",
            "   _final_filter n_bootstrap: 100\n",
            "     Bootstrap 0 for Cohort 0: r_pb=0.2320, r_pb^2=0.0538\n",
            "     Bootstrap 1 for Cohort 0: r_pb=0.2001, r_pb^2=0.0401\n",
            "     Bootstrap 2 for Cohort 0: r_pb=0.2029, r_pb^2=0.0412\n",
            "     Bootstrap 3 for Cohort 0: r_pb=0.1979, r_pb^2=0.0392\n",
            "     Bootstrap 4 for Cohort 0: r_pb=0.1536, r_pb^2=0.0236\n",
            "   Cohort 0 stability score S_j: 0.0438\n",
            "     Bootstrap 0 for Cohort 1: r_pb=0.2506, r_pb^2=0.0628\n",
            "     Bootstrap 1 for Cohort 1: r_pb=0.1133, r_pb^2=0.0128\n",
            "     Bootstrap 2 for Cohort 1: r_pb=0.1853, r_pb^2=0.0343\n",
            "     Bootstrap 3 for Cohort 1: r_pb=0.1102, r_pb^2=0.0122\n",
            "     Bootstrap 4 for Cohort 1: r_pb=0.1895, r_pb^2=0.0359\n",
            "   Cohort 1 stability score S_j: 0.0304\n",
            "     Bootstrap 0 for Cohort 2: r_pb=0.1605, r_pb^2=0.0257\n",
            "     Bootstrap 1 for Cohort 2: r_pb=0.1998, r_pb^2=0.0399\n",
            "     Bootstrap 2 for Cohort 2: r_pb=0.2153, r_pb^2=0.0463\n",
            "     Bootstrap 3 for Cohort 2: r_pb=0.2241, r_pb^2=0.0502\n",
            "     Bootstrap 4 for Cohort 2: r_pb=0.1668, r_pb^2=0.0278\n",
            "   Cohort 2 stability score S_j: 0.0346\n",
            " No stable features met threshold. Keeping top 2.\n",
            "   Kept indices from top: [6, 0]\n",
            "   Corresponding stability scores: ['0.0449', '0.0438']\n",
            "   _final_filter output kept indices: [6, 0]\n",
            "   _final_filter output stabilities: ['0.0438', '0.0304', '0.0346', '0.0332', '0.0342', '0.0378', '0.0449', '0.0329']\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "   Kept indices: [6, 0]\n",
            "   Stability scores: ['0.0438', '0.0304', '0.0346', '0.0332', '0.0342', '0.0378', '0.0449', '0.0329']\n",
            "   Max stability: 0.0449\n",
            "   Min stability: 0.0304\n",
            "   Avg stability: 0.0365\n",
            "\n",
            "============================================================\n",
            "INFUSE DEBUG VERSION 4.0 - FIT_TRANSFORM COMPLETED\n",
            "============================================================\n",
            "\n",
            "âœ… INFUSE pipeline completed successfully.\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 2)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id seed_gene  num_members  \\\n",
            "0          0    CLEC4M            6   \n",
            "1          1     KLF10            6   \n",
            "\n",
            "                                       member_genes  stability  \n",
            "0  [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.044870  \n",
            "1     [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.043768  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed before filtering: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 2\n",
            "Stability scores: ['0.0438', '0.0304', '0.0346', '0.0332', '0.0342', '0.0378', '0.0449', '0.0329']\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: CLEC4M | Stability: 0.04\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            " Cohort 1 | Seed: KLF10 | Stability: 0.04\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_mjir1Y4QD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version that uses AUCROC in Final filtering"
      ],
      "metadata": {
        "id": "a4H3ylk-I6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_debug_v4.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.0 (Debugging Focus Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with extensive debugging capabilities.\n",
        "# INFUSE is a transformer designed for high-dimensional biological data\n",
        "# (e.g., gene expression) to construct new, stable, and potentially interpretable\n",
        "# cohort features. It integrates concepts of seed selection, multi-criteria\n",
        "# hybrid weighting, graph-based regularization, and empirical stability evaluation.\n",
        "# This version prioritizes exposing internal states for debugging.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Re-enable for debugging\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation (Debugging Version).\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    This version includes extensive debugging prints.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"INFUSE DEBUG VERSION 4.0 - STARTING FIT_TRANSFORM\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Initial Data Shape: {X.shape}\")\n",
        "            print(f\"âœ… Initial Target Shape: {y.shape}\")\n",
        "            print(f\"âœ… Unique target values: {np.unique(y)}\")\n",
        "            print(f\"âœ… Target distribution: {dict(zip(np.unique(y), np.bincount(y)))}\")\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Data shape after pre-filtering: {X.shape}\")\n",
        "\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Data scaled: {X_scaled.shape}\")\n",
        "            print(f\"   X_scaled range: [{X_scaled.min():.4f}, {X_scaled.max():.4f}]\")\n",
        "            print(f\"   X_scaled mean: {X_scaled.mean():.4f}, std: {X_scaled.std():.4f}\")\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X_scaled, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw[:5]}...\") # Show first 5\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X_scaled, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X_scaled, columns=self.feature_names_in_)\n",
        "\n",
        "        # --- DEBUGGING: Inspect Similarity Matrix ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Similarity Matrix...\")\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "            print(f\"   Similarity matrix range: [{similarities.min():.4f}, {similarities.max():.4f}]\")\n",
        "            print(f\"   Similarity matrix sample (first 3 features vs first 2 seeds):\\n{similarities[:3, :min(2, similarities.shape[1])] if similarities.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Hybrid Weights ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Hybrid Weights...\")\n",
        "        weights = self._hybrid_weights(X_scaled, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "            print(f\"   Weight matrix range: [{weights.min():.4f}, {weights.max():.4f}]\")\n",
        "            print(f\"   Weight matrix sample (first 3 features vs first 2 seeds):\\n{weights[:3, :min(2, weights.shape[1])] if weights.size > 0 else 'Empty'}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Graph Regularization ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Computing Graph Regularization...\")\n",
        "        graph = self._graph_regularization(X_scaled, seed_names_filtered) # Pass X_scaled\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "            print(f\"   Graph density: {np.count_nonzero(graph) / (graph.shape[0] * graph.shape[1]):.6f}\")\n",
        "            # Show sparsity pattern for first 50 features\n",
        "            if graph.shape[0] > 50:\n",
        "                print(f\"   Graph sparsity pattern (first 50x50):\")\n",
        "                subset_graph = graph[:50, :50]\n",
        "                for i in range(min(10, subset_graph.shape[0])): # Print first 10 rows\n",
        "                    row_str = \"\".join([\"1\" if val > 0 else \"0\" for val in subset_graph[i, :min(50, subset_graph.shape[1])]])\n",
        "                    print(f\"     Row {i:2d}: {row_str}\")\n",
        "            else:\n",
        "                print(f\"   Graph sparsity pattern (full {graph.shape[0]}x{graph.shape[1]}):\")\n",
        "                for i in range(graph.shape[0]):\n",
        "                    row_str = \"\".join([\"1\" if val > 0 else \"0\" for val in graph[i, :]])\n",
        "                    print(f\"     Row {i:2d}: {row_str}\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Cohort Fusion ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Performing Cohort Fusion...\")\n",
        "        Z, cohorts = self._cohort_fusion(X_scaled, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "            # Analyze cohort sizes\n",
        "            if hasattr(self, 'cohort_members_'):\n",
        "                cohort_sizes = [len(c['members']) for c in self.cohort_members_]\n",
        "                print(f\"   Cohort sizes: {cohort_sizes}\")\n",
        "                print(f\"   Min cohort size: {min(cohort_sizes) if cohort_sizes else 'N/A'}\")\n",
        "                print(f\"   Max cohort size: {max(cohort_sizes) if cohort_sizes else 'N/A'}\")\n",
        "                print(f\"   Avg cohort size: {np.mean(cohort_sizes):.2f}\" if cohort_sizes else \"N/A\")\n",
        "\n",
        "        # --- DEBUGGING: Inspect Final Filtering ---\n",
        "        if self.verbose:\n",
        "            print(f\"\\nðŸ” DEBUG: Performing Final Filtering...\")\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "            print(f\"   Kept indices: {kept}\")\n",
        "            print(f\"   Stability scores: {[f'{s:.4f}' for s in stabilities]}\")\n",
        "            if len(stabilities) > 0:\n",
        "                print(f\"   Max stability: {max(stabilities):.4f}\")\n",
        "                print(f\"   Min stability: {min(stabilities):.4f}\")\n",
        "                print(f\"   Avg stability: {np.mean(stabilities):.4f}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts # Save cohort details\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"INFUSE DEBUG VERSION 4.0 - FIT_TRANSFORM COMPLETED\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _dissimilarity_filter input X shape: {X.shape}\")\n",
        "            print(f\"   _dissimilarity_filter input seed_names: {seed_names[:3]}...\") # Show first 3\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if self.verbose and i < 3 and j < 3: # Debug first few comparisons\n",
        "                    print(f\"     JSD({seed_indices[i]}, {j}) = {jsd:.4f}\")\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    if self.verbose and i < 3:\n",
        "                        print(f\"     Seed {seed_indices[i]} is REDUNDANT with {j} (JSD < {self.jsd_threshold})\")\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "                if self.verbose and i < 3:\n",
        "                    print(f\"     Seed {seed_indices[i]} is UNIQUE. Added to filtered list.\")\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        if self.verbose:\n",
        "            print(f\"   _dissimilarity_filter output filtered_names: {filtered_names}\")\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        if self.verbose:\n",
        "            print(f\"   _hybrid_weights input X shape: {X.shape}\")\n",
        "            print(f\"   _hybrid_weights input seed_names: {seed_names[:3]}...\") # Show first 3\n",
        "            print(f\"   _hybrid_weights input similarities shape: {similarities.shape}\")\n",
        "\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "                 if self.verbose and i == 0 and j < 3: # Debug first seed, first 3 features\n",
        "                     print(f\"     JSD({j}, Seed:{seed_idx}) = {jsd_div[j, i]:.4f}\")\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"   _hybrid_weights output weights shape: {weights.shape}\")\n",
        "            print(f\"   _hybrid_weights output weights range: [{weights.min():.4f}, {weights.max():.4f}]\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X_scaled ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Build graph directly on X.T using cosine distance ---\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        if self.verbose:\n",
        "            print(f\"   _cohort_fusion input X shape: {X.shape}\")\n",
        "            print(f\"   _cohort_fusion input weights shape: {weights.shape}\")\n",
        "            print(f\"   _cohort_fusion input graph shape: {graph.shape}\")\n",
        "            print(f\"   _cohort_fusion input seed_names: {seed_names}\")\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Initial neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "                if self.verbose and i < 3:\n",
        "                     print(f\"     Cohort {i} (Seed: {seed_name}) - Seed added. Final neighbors: {len(neighbors)}\")\n",
        "            else:\n",
        "                if self.verbose and i < 3:\n",
        "                     print(f\"     Cohort {i} (Seed: {seed_name}) - Seed already included. Final neighbors: {len(neighbors)}\")\n",
        "\n",
        "            # --- CRITICAL DEBUG: Check if neighbors include ALL features ---\n",
        "            if len(neighbors) == X.shape[1]:\n",
        "                if self.verbose:\n",
        "                    print(f\"     âš ï¸ CRITICAL DEBUG: Cohort {i} has ALL {X.shape[1]} features as neighbors!\")\n",
        "                    print(f\"     âš ï¸ This indicates a potential issue with the graph structure.\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weights retrieved: {w.shape}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weight sum: {w.sum():.4f}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - First 5 weights: {w[:min(5, len(w))] if len(w) > 0 else '[]'}\")\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Weights normalized: {w.shape}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Normalized weight sum: {w.sum():.4f}\")\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - First 5 normalized weights: {w[:min(5, len(w))] if len(w) > 0 else '[]'}\")\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            if self.verbose and i < 3: # Debug first 3 cohorts\n",
        "                 print(f\"     Cohort {i} (Seed: {seed_name}) - Fused vector shape: {fused_vec.shape}\")\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _cohort_fusion output Z shape: {Z.shape}\")\n",
        "            print(f\"   _cohort_fusion output members length: {len(members)}\")\n",
        "\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using AUC-ROC ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using AUC-ROC.\n",
        "        \"\"\"\n",
        "        from sklearn.metrics import roc_auc_score\n",
        "        from sklearn.tree import DecisionTreeClassifier # Use simple model for single feature\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            auc_roc_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for AUC\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Train a simple model (e.g., Decision Tree with max_depth=1)\n",
        "                        #    to predict yb using *only* the single cohort feature Zb[:, i]\n",
        "                        #    This is more direct than RF and less prone to overfitting on 1 feature\n",
        "                        clf = DecisionTreeClassifier(max_depth=1, random_state=self.random_state.randint(0, 10000))\n",
        "                        clf.fit(Zb[:, [i]], yb) # Fit on single feature\n",
        "\n",
        "                        # 3. Predict probabilities for AUC calculation\n",
        "                        y_proba = clf.predict_proba(Zb[:, [i]])[:, 1] # Prob of positive class\n",
        "\n",
        "                        # 4. Calculate AUC-ROC score\n",
        "                        #    This measures the model's ability to discriminate between classes\n",
        "                        #    It's bounded [0, 1], with 0.5 indicating random guessing.\n",
        "                        auc_roc = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                        # 5. Append the calculated AUC-ROC value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(auc_roc):\n",
        "                            auc_roc_vals.append(auc_roc)\n",
        "                        else:\n",
        "                            auc_roc_vals.append(0.5) # Default score for invalid AUC (random guessing)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 6. Fallback: Assign default score if calculation fails\n",
        "                        auc_roc_vals.append(0.5)\n",
        "                else:\n",
        "                    # 7. Fallback: Assign default score if only one class in bootstrap\n",
        "                    auc_roc_vals.append(0.5) # Cannot compute AUC with one class, default to random\n",
        "\n",
        "            # 8. Calculate the cohort's stability score S_j as the mean AUC-ROC\n",
        "            #    A higher mean AUC-ROC indicates better stability and discriminative ability\n",
        "            if auc_roc_vals:\n",
        "                S_j = np.mean(auc_roc_vals)\n",
        "            else:\n",
        "                # Edge case: No valid AUC-ROC calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.5 # Default to random guessing\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "                print(f\"   Kept indices from top: {kept}\")\n",
        "                print(f\"   Corresponding stability scores: {[f'{stabilities[i]:.4f}' for i in kept]}\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "                if self.verbose:\n",
        "                    print(f\" Ultimate fallback: Keeping cohort 0.\")\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            if self.verbose:\n",
        "                print(f\" Final fallback: No cohorts kept, returning empty matrix.\")\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"   _final_filter output kept indices: {kept}\")\n",
        "            print(f\"   _final_filter output stabilities: {[f'{s:.4f}' for s in stabilities]}\")\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X_scaled\n",
        "        graph = self._graph_regularization(X_scaled, self.seeds_) # Pass X_scaled\n",
        "        Z_fused, _ = self._cohort_fusion(X_scaled, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "0NtQjsPuI49V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J6cP3nEI5BN",
        "outputId": "d4a4db6a-a699-46ea-b741-f8a0ce2a694c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the final class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    jsd_threshold=0.35,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,\n",
        "    final_k=2,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- CRITICAL: Pass RAW, IMPUTED data to fit_transform ---\n",
        "# X_raw_imputed has shape (n_samples, p_original_features)\n",
        "# y_encoded has shape (n_samples,)\n",
        "# feature_names_full has length p_original_features\n",
        "try:\n",
        "    Z_final = infuse.fit_transform(X_raw_imputed, y_encoded, feature_names=feature_names_full)\n",
        "    print(f\"\\nâœ… INFUSE pipeline completed successfully.\")\n",
        "    print(f\"ðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    # Detailed analysis\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed before filtering: {len(infuse.cohort_members_) if hasattr(infuse, 'cohort_members_') else 'N/A'}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "    print(f\"Stability scores: {[f'{s:.4f}' for s in infuse.stabilities_] if hasattr(infuse, 'stabilities_') else 'N/A'}\")\n",
        "\n",
        "    # Use the describe_cohorts method for a detailed view\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ INFUSE pipeline failed: {type(e).__name__} - {e}\")\n",
        "    Z_final = np.empty((X_raw_imputed.shape[0], 0)) # Return empty matrix on failure\n",
        "    # Optionally, print more details about the fitted infuse object for debugging\n",
        "    # if hasattr(infuse, 'is_fitted_') and infuse.is_fitted_:\n",
        "    #     print(\"  INFUSE object attributes after failure:\")\n",
        "    #     print(f\"    is_fitted_: {infuse.is_fitted_}\")\n",
        "    #     print(f\"    seeds_: {getattr(infuse, 'seeds_', 'N/A')}\")\n",
        "    #     print(f\"    kept_indices_: {getattr(infuse, 'kept_indices_', 'N/A')}\")\n",
        "    #     print(f\"    stabilities_: {getattr(infuse, 'stabilities_', 'N/A')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-luJT4DI5Hh",
        "outputId": "20facab2-39c8-49b1-c725-79c6cdf6ef23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "INFUSE DEBUG VERSION 4.0 - STARTING FIT_TRANSFORM\n",
            "============================================================\n",
            "âœ… Initial Data Shape: (1215, 20530)\n",
            "âœ… Initial Target Shape: (1215,)\n",
            "âœ… Unique target values: [0 1]\n",
            "âœ… Target distribution: {np.int64(0): np.int64(1016), np.int64(1): np.int64(199)}\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data shape after pre-filtering: (1215, 1000)\n",
            "âœ… Data scaled: (1215, 1000)\n",
            "   X_scaled range: [-7.7837, 20.1326]\n",
            "   X_scaled mean: 0.0000, std: 1.0000\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4']...\n",
            "   _dissimilarity_filter input X shape: (1215, 1000)\n",
            "   _dissimilarity_filter input seed_names: ['KLF10', 'APOB', 'LEPR']...\n",
            "     Seed 0 is UNIQUE. Added to filtered list.\n",
            "     JSD(1, 0) = 0.4158\n",
            "     Seed 1 is UNIQUE. Added to filtered list.\n",
            "     JSD(2, 0) = 0.3310\n",
            "     Seed 2 is REDUNDANT with 0 (JSD < 0.35)\n",
            "   _dissimilarity_filter output filtered_names: ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "\n",
            "ðŸ” DEBUG: Computing Similarity Matrix...\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "   Similarity matrix range: [-0.5896, 1.0000]\n",
            "   Similarity matrix sample (first 3 features vs first 2 seeds):\n",
            "[[1.         0.43951553]\n",
            " [0.43951553 1.        ]\n",
            " [0.5334556  0.65287029]]\n",
            "\n",
            "ðŸ” DEBUG: Computing Hybrid Weights...\n",
            "   _hybrid_weights input X shape: (1215, 1000)\n",
            "   _hybrid_weights input seed_names: ['KLF10', 'APOB', 'ADH4']...\n",
            "   _hybrid_weights input similarities shape: (1000, 8)\n",
            "     JSD(0, Seed:0) = 0.0000\n",
            "     JSD(1, Seed:0) = 0.4158\n",
            "     JSD(2, Seed:0) = 0.3310\n",
            "   _hybrid_weights output weights shape: (1000, 8)\n",
            "   _hybrid_weights output weights range: [0.0000, 1.0000]\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Weight matrix range: [0.0000, 1.0000]\n",
            "   Weight matrix sample (first 3 features vs first 2 seeds):\n",
            "[[1.         0.58055382]\n",
            " [0.53797263 0.95741881]\n",
            " [0.60587257 0.67979358]]\n",
            "\n",
            "ðŸ” DEBUG: Computing Graph Regularization...\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Graph density: 0.005000\n",
            "   Graph sparsity pattern (first 50x50):\n",
            "     Row  0: 00000000000000000010000000010000000000000000000000\n",
            "     Row  1: 00000000000000000000000000000000000000000000000000\n",
            "     Row  2: 00000000000000000000000000000000000000000000000000\n",
            "     Row  3: 00000000000000000000000000000000000000000000000000\n",
            "     Row  4: 00000000000100000000000000000000000000000000000000\n",
            "     Row  5: 00000000000000000000000000000000000000000000000000\n",
            "     Row  6: 00000000000000000000000000000000000000000000000000\n",
            "     Row  7: 00000000000000000000000000010000000000000000000000\n",
            "     Row  8: 00000000000010100000000000000000010000000000000000\n",
            "     Row  9: 00000000000100000000000000000000001000000000000000\n",
            "\n",
            "ðŸ” DEBUG: Performing Cohort Fusion...\n",
            "   _cohort_fusion input X shape: (1215, 1000)\n",
            "   _cohort_fusion input weights shape: (1000, 8)\n",
            "   _cohort_fusion input graph shape: (1000, 1000)\n",
            "   _cohort_fusion input seed_names: ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "     Cohort 0 (Seed: KLF10) - Initial neighbors found: 5\n",
            "     Cohort 0 (Seed: KLF10) - Seed added. Final neighbors: 6\n",
            "     Cohort 0 (Seed: KLF10) - Weights retrieved: (6,)\n",
            "     Cohort 0 (Seed: KLF10) - Weight sum: 2.6373\n",
            "     Cohort 0 (Seed: KLF10) - First 5 weights: [0.5703409  0.27453336 0.27358504 0.25369961 0.26514381]\n",
            "     Cohort 0 (Seed: KLF10) - Weights normalized: (6,)\n",
            "     Cohort 0 (Seed: KLF10) - Normalized weight sum: 1.0000\n",
            "     Cohort 0 (Seed: KLF10) - First 5 normalized weights: [0.21625917 0.10409627 0.10373668 0.09619662 0.10053598]\n",
            "     Cohort 0 (Seed: KLF10) - Fused vector shape: (1215,)\n",
            "     Cohort 1 (Seed: APOB) - Initial neighbors found: 5\n",
            "     Cohort 1 (Seed: APOB) - Seed added. Final neighbors: 6\n",
            "     Cohort 1 (Seed: APOB) - Weights retrieved: (6,)\n",
            "     Cohort 1 (Seed: APOB) - Weight sum: 3.1215\n",
            "     Cohort 1 (Seed: APOB) - First 5 weights: [0.42415243 0.42857108 0.43367932 0.43762826 0.44000924]\n",
            "     Cohort 1 (Seed: APOB) - Weights normalized: (6,)\n",
            "     Cohort 1 (Seed: APOB) - Normalized weight sum: 1.0000\n",
            "     Cohort 1 (Seed: APOB) - First 5 normalized weights: [0.13588274 0.13729831 0.13893481 0.1401999  0.14096268]\n",
            "     Cohort 1 (Seed: APOB) - Fused vector shape: (1215,)\n",
            "     Cohort 2 (Seed: ADH4) - Initial neighbors found: 5\n",
            "     Cohort 2 (Seed: ADH4) - Seed added. Final neighbors: 6\n",
            "     Cohort 2 (Seed: ADH4) - Weights retrieved: (6,)\n",
            "     Cohort 2 (Seed: ADH4) - Weight sum: 2.9657\n",
            "     Cohort 2 (Seed: ADH4) - First 5 weights: [0.67124207 0.36142156 0.33238297 0.33972991 0.32572659]\n",
            "     Cohort 2 (Seed: ADH4) - Weights normalized: (6,)\n",
            "     Cohort 2 (Seed: ADH4) - Normalized weight sum: 1.0000\n",
            "     Cohort 2 (Seed: ADH4) - First 5 normalized weights: [0.22633378 0.12186648 0.11207506 0.11455235 0.10983062]\n",
            "     Cohort 2 (Seed: ADH4) - Fused vector shape: (1215,)\n",
            "   _cohort_fusion output Z shape: (1215, 8)\n",
            "   _cohort_fusion output members length: 8\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "\n",
            "ðŸ” DEBUG: Performing Final Filtering...\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "   Kept indices: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "   Stability scores: ['0.5913', '0.5842', '0.5893', '0.5892', '0.5871', '0.5978', '0.5954', '0.5911']\n",
            "   Max stability: 0.5978\n",
            "   Min stability: 0.5842\n",
            "   Avg stability: 0.5907\n",
            "\n",
            "============================================================\n",
            "INFUSE DEBUG VERSION 4.0 - FIT_TRANSFORM COMPLETED\n",
            "============================================================\n",
            "\n",
            "âœ… INFUSE pipeline completed successfully.\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 8)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1       APOB            6   \n",
            "2          2       ADH4            6   \n",
            "3          3       UBTF            6   \n",
            "4          4      CRHR2            6   \n",
            "5          5  LOC729467            6   \n",
            "6          6     CLEC4M            6   \n",
            "7          7      SAMD1            6   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.591338  \n",
            "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.584221  \n",
            "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.589293  \n",
            "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.589212  \n",
            "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.587141  \n",
            "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.597779  \n",
            "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.595426  \n",
            "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.591131  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed before filtering: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 8\n",
            "Stability scores: ['0.5913', '0.5842', '0.5893', '0.5892', '0.5871', '0.5978', '0.5954', '0.5911']\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.59\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 0.58\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            " Cohort 2 | Seed: ADH4 | Stability: 0.59\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            " Cohort 3 | Seed: UBTF | Stability: 0.59\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            " Cohort 4 | Seed: CRHR2 | Stability: 0.59\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 5 | Seed: LOC729467 | Stability: 0.60\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            " Cohort 6 | Seed: CLEC4M | Stability: 0.60\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            " Cohort 7 | Seed: SAMD1 | Stability: 0.59\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_aHmn9sFI5OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R_GN3CCpI5pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmgkuHm8I51l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbOFMS6sOq79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xVIp_auOrAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.1 (Final Academic Implementation with Robust Corrections)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse_final import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import roc_auc_score for stability evaluation\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Import DecisionTreeClassifier for single-feature evaluation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35, #final_k=2,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap AUC-ROC for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        #self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- UPDATE: Use 'ensure_all_finite' to fix FutureWarning ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use AUC-ROC\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=-1                 # Use all cores\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using AUC-ROC ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using AUC-ROC.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            auc_roc_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for AUC\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Train a simple model (e.g., Decision Tree with max_depth=1)\n",
        "                        #    to predict yb using *only* the single cohort feature Zb[:, i]\n",
        "                        #    This is more direct than RF and less prone to overfitting on 1 feature\n",
        "                        clf = DecisionTreeClassifier(max_depth=1, random_state=self.random_state.randint(0, 10000))\n",
        "                        clf.fit(Zb[:, [i]], yb) # Fit on single feature\n",
        "\n",
        "                        # 3. Predict probabilities for AUC calculation\n",
        "                        y_proba = clf.predict_proba(Zb[:, [i]])[:, 1] # Prob of positive class\n",
        "\n",
        "                        # 4. Calculate AUC-ROC score\n",
        "                        #    This measures the model's ability to discriminate between classes\n",
        "                        #    It's bounded [0, 1], with 0.5 indicating random guessing.\n",
        "                        auc_roc = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                        # 5. Append the calculated AUC-ROC value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(auc_roc):\n",
        "                             auc_roc_vals.append(auc_roc)\n",
        "                        else:\n",
        "                             auc_roc_vals.append(0.5) # Default score for invalid AUC (random guessing)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 6. Fallback: Assign default score if calculation fails\n",
        "                        auc_roc_vals.append(0.5)\n",
        "                else:\n",
        "                    # 7. Fallback: Assign default score if only one class in bootstrap\n",
        "                    auc_roc_vals.append(0.5) # Cannot compute AUC with one class, default to random guessing\n",
        "\n",
        "            # 8. Calculate the cohort's stability score S_j as the mean AUC-ROC\n",
        "            #    A higher mean AUC-ROC indicates better stability and discriminative ability\n",
        "            if auc_roc_vals:\n",
        "                S_j = np.mean(auc_roc_vals)\n",
        "            else:\n",
        "                # Edge case: No valid AUC-ROC calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.5 # Default to random guessing\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "IG0suuS4OrE8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ovR8lMBOrJl",
        "outputId": "94e3fd0a-1c13-43f3-c4df-3f0cf38c66bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. INFUSE Execution ---\n",
        "#print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "#print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the final class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    jsd_threshold=0.35,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,\n",
        "    #final_k=2,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- CRITICAL: Pass RAW, IMPUTED data to fit_transform ---\n",
        "# X_raw_imputed has shape (n_samples, p_original_features)\n",
        "# y_encoded has shape (n_samples,)\n",
        "# feature_names_full has length p_original_features\n",
        "try:\n",
        "    Z_final = infuse.fit_transform(X_raw_imputed, y_encoded, feature_names=feature_names_full)\n",
        "    print(f\"\\nâœ… INFUSE pipeline completed successfully.\")\n",
        "    print(f\"ðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    # Detailed analysis\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed before filtering: {len(infuse.cohort_members_) if hasattr(infuse, 'cohort_members_') else 'N/A'}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "    print(f\"Stability scores: {[f'{s:.4f}' for s in infuse.stabilities_] if hasattr(infuse, 'stabilities_') else 'N/A'}\")\n",
        "\n",
        "    # Use the describe_cohorts method for a detailed view\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ INFUSE pipeline failed: {type(e).__name__} - {e}\")\n",
        "    Z_final = np.empty((X_raw_imputed.shape[0], 0)) # Return empty matrix on failure\n",
        "    # Optionally, print more details about the fitted infuse object for debugging\n",
        "    # if hasattr(infuse, 'is_fitted_') and infuse.is_fitted_:\n",
        "    #     print(\"  INFUSE object attributes after failure:\")\n",
        "    #     print(f\"    is_fitted_: {infuse.is_fitted_}\")\n",
        "    #     print(f\"    seeds_: {getattr(infuse, 'seeds_', 'N/A')}\")\n",
        "    #     print(f\"    kept_indices_: {getattr(infuse, 'kept_indices_', 'N/A')}\")\n",
        "    #     print(f\"    stabilities_: {getattr(infuse, 'stabilities_', 'N/A')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUwqkj6xO4TB",
        "outputId": "8eb40667-b85f-42d5-8ce2-6195da592bb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âš™ï¸ Weight matrix shape: (1000, 8)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "\n",
            "âœ… INFUSE pipeline completed successfully.\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 8)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1       APOB            6   \n",
            "2          2       ADH4            6   \n",
            "3          3       UBTF            6   \n",
            "4          4      CRHR2            6   \n",
            "5          5  LOC729467            6   \n",
            "6          6     CLEC4M            6   \n",
            "7          7      SAMD1            6   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.591338  \n",
            "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.584221  \n",
            "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.589293  \n",
            "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.589212  \n",
            "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.587141  \n",
            "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.597779  \n",
            "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.595426  \n",
            "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.591131  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed before filtering: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 8\n",
            "Stability scores: ['0.5913', '0.5842', '0.5893', '0.5892', '0.5871', '0.5978', '0.5954', '0.5911']\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.59\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 0.58\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            " Cohort 2 | Seed: ADH4 | Stability: 0.59\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            " Cohort 3 | Seed: UBTF | Stability: 0.59\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            " Cohort 4 | Seed: CRHR2 | Stability: 0.59\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 5 | Seed: LOC729467 | Stability: 0.60\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            " Cohort 6 | Seed: CLEC4M | Stability: 0.60\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            " Cohort 7 | Seed: SAMD1 | Stability: 0.59\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Benchmarking INFUSE Against Other Techniques ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, m_features) e.g., (1215, 1000)\n",
        "# y_encoded: Encoded target labels (n_samples,) e.g., (1215,)\n",
        "# feature_names: Names of the m pre-filtered features e.g., (1000,)\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"- Transforming Test Data with Pre-fitted INFUSE Model -\")\n",
        "    # Transform the pre-filtered train and test sets using the already fitted infuse model\n",
        "    # This uses the scaler_, seeds_, graph, etc., learned from the full X, y_encoded (1215, 1000)\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full)\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full)\n",
        "\n",
        "    # Check if transformation produced features\n",
        "    if Z_train_infuse_full.size > 0 and Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "    # Re-instantiate INFUSE with the same parameters as used in Section 2\n",
        "    # CRITICAL: Pass the ORIGINAL feature names corresponding to the pre-filtered X_train_full\n",
        "    # We need the feature names for the 1000 features in X_train_full\n",
        "    # Assuming feature_names corresponds to the 1000 features in the original X from Section 1\n",
        "    feature_names_for_train = feature_names # From Section 1, should be length 1000\n",
        "\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=20,               # Match Section 2\n",
        "        jsd_threshold=0.35,       # Match Section 2\n",
        "        alpha=0.6,                # Match Section 2\n",
        "        beta=0.2,                 # Match Section 2\n",
        "        max_features=1000,        # Match Section 2 (This should be <= X_train_full.shape[1])\n",
        "        stability_thresh=0.5,     # Match Section 2\n",
        "        final_k=2,                # Match Section 2\n",
        "        verbose=False,            # Turn off verbose for cleaner benchmarking output\n",
        "        random_state=42           # Match Section 2\n",
        "    )\n",
        "    # Fit ONLY on the pre-filtered training data (972, 1000) and corresponding labels (972,)\n",
        "    # Pass the feature names for these 1000 features\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_for_train)\n",
        "    # Transform the pre-filtered test data (243, 1000) using the model fitted on training data\n",
        "    # CRITICAL: X_test_full must have the SAME 1000 features in the SAME ORDER\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        # Update k_compare if this rigorous fit produced a different number of features\n",
        "        if n_infuse_features_rigorous > 0 and n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "# Apply SelectKBest to the pre-filtered training data\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "# Note: mutual_info_classif can be slower than f_classif\n",
        "# Apply to the pre-filtered training data\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "\n",
        "# --- D. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- E. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                #print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}):<30} {auc_mean:.4f} (+/- {auc_std*2:.4f}):<30}\")\n",
        "                # Corrected version of line 255\n",
        "                print(f\"  {tech_name:<25} {f'{acc_mean:.4f} (+/- {acc_std*2:.4f})':<30} {f'{auc_mean:.4f} (+/- {auc_std*2:.4f})':<30}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vSmWIcpVPznO",
        "outputId": "bf5411fa-223d-4374-8916-d9fd2d3bba39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3729388282.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Split data for final evaluation (using the same split for fairness)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Ensure this split uses the same random_state as your main analysis if needed for consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Benchmarking INFUSE Against Other Techniques ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- CRITICAL: Ensure all necessary imports are available ---\n",
        "# Add missing imports for functions used in this section\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "# Assuming 'infuse' is your fitted INFUSE instance from the previous section\n",
        "# from infuse import INFUSE # Import your INFUSE class (ensure it's the latest version)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, n_features_prefiltered) e.g., (1215, 1000)\n",
        "# y_encoded: Encoded target labels (n_samples,) e.g., (1215,)\n",
        "# feature_names: Names of the n_features_prefiltered features e.g., (1000,)\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"\\n--- Transforming Test Data with Pre-fitted INFUSE Model ---\")\n",
        "    # Transform the pre-filtered train and test sets using the already fitted infuse model\n",
        "    # This uses the scaler_, seeds_, graph, etc., learned from the full X, y_encoded (1215, 1000)\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full)\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full)\n",
        "\n",
        "    # Check if transformation produced features\n",
        "    if Z_train_infuse_full.size > 0 and Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "    # Re-instantiate INFUSE with the same parameters as used in Section 2\n",
        "    # CRITICAL: Pass the ORIGINAL feature names corresponding to the pre-filtered X_train_full\n",
        "    # We need the feature names for the 1000 features in X_train_full\n",
        "    # Assuming feature_names corresponds to the 1000 features in the original X from Section 1\n",
        "    feature_names_for_train = feature_names # From Section 1, should be length 1000\n",
        "\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=20,               # Match Section 2\n",
        "        jsd_threshold=0.35,       # Match Section 2\n",
        "        alpha=0.6,                # Match Section 2\n",
        "        beta=0.2,                 # Match Section 2\n",
        "        max_features=1000,        # Match Section 2 (This should be <= X_train_full.shape[1])\n",
        "        stability_thresh=0.5,     # Match Section 2\n",
        "        final_k=2,                # Match Section 2\n",
        "        verbose=False,            # Turn off verbose for cleaner benchmarking output\n",
        "        random_state=42           # Match Section 2\n",
        "    )\n",
        "    # Fit ONLY on the pre-filtered training data (972, 1000) and corresponding labels (972,)\n",
        "    # Pass the feature names for these 1000 features\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_for_train)\n",
        "    # Transform the pre-filtered test data (243, 1000) using the model fitted on training data\n",
        "    # CRITICAL: X_test_full must have the SAME 1000 features in the SAME ORDER\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        # Update k_compare if this rigorous fit produced a different number of features\n",
        "        if n_infuse_features_rigorous > 0 and n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "# --- D. Other Techniques (using pre-filtered, standardized data) ---\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "# --- E. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- F. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                # Corrected formatting without colons outside braces\n",
        "                print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "9iK3N8TePzr8",
        "outputId": "046e08aa-89a5-48c8-99bf-b8533a805053"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2215734788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Ensure this split uses the same random_state as your main analysis if needed for consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" Train Set Shape: {X_train_full.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KKJTsCNPzxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7oxFYZ1vPz2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UpgjrrXPz66",
        "outputId": "ae037304-a00c-44a4-c6a5-b2fdbba2ab31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.0 (Final Robust Implementation with Comprehensive Fixes)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- UPDATE: Use 'ensure_all_finite' to fix FutureWarning ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary adjacency matrix\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        from scipy.stats import pointbiserialr\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "8_XVDdpYPz_P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Preserve gene names for INFUSE\n",
        "feature_names_full = X_df_imputed.columns.tolist()\n",
        "print(f\" First 10 genes (full data): {feature_names_full[:10]}\")\n",
        "\n",
        "# --- Encode labels ---\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_df): {X_df_imputed.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- CRITICAL: Pass the FULL, RAW, IMPUTED data (X_df_imputed.values) to INFUSE ---\n",
        "# INFUSE will handle its own scaling and pre-filtering internally.\n",
        "# Do NOT apply StandardScaler or pre-filtering (max_features) here.\n",
        "X_raw_imputed = X_df_imputed.values # Shape: (n_samples, p_original_features)\n",
        "# y_encoded is already 1D\n",
        "# feature_names_full contains ALL original feature names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJmamLuRZi7b",
        "outputId": "65703ab6-027e-4c42-ac20-f5dd22cd1545"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes (full data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_df): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Benchmarking INFUSE Against Other Techniques ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- CRITICAL: Ensure all necessary imports are available ---\n",
        "# Add missing imports for functions used in this section\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "# Assuming 'infuse' is your fitted INFUSE instance from the previous section\n",
        "# from infuse import INFUSE # Import your INFUSE class (ensure it's the latest version)\n",
        "\n",
        "# --- A. Prepare Data for Benchmarking ---\n",
        "# Use the preprocessed data from Section 1\n",
        "# X: Standardized, pre-filtered data (n_samples, n_features_prefiltered) e.g., (1215, 1000)\n",
        "# y_encoded: Encoded target labels (n_samples,) e.g., (1215,)\n",
        "# feature_names: Names of the n_features_prefiltered features e.g., (1000,)\n",
        "\n",
        "# Split data for final evaluation (using the same split for fairness)\n",
        "# Ensure this split uses the same random_state as your main analysis if needed for consistency\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(f\" Train Set Shape: {X_train_full.shape}\")\n",
        "print(f\" Test Set Shape: {X_test_full.shape}\")\n",
        "\n",
        "# --- B. Define Models for Evaluation ---\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# --- C. Define Feature Selection/Dimensionality Reduction Techniques ---\n",
        "# Number of features/components for fair comparison.\n",
        "# Use the number of final cohorts produced by the pre-fitted INFUSE model.\n",
        "# Access the number of cohorts kept by the pre-fitted 'infuse' model\n",
        "try:\n",
        "    # Ensure 'infuse' is fitted\n",
        "    from sklearn.utils.validation import check_is_fitted\n",
        "    check_is_fitted(infuse, 'is_fitted_')\n",
        "    # Get the number of final cohorts from the fitted model\n",
        "    n_infuse_features_full = len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') and infuse.kept_indices_ is not None else 0\n",
        "    # Fallback if kept_indices_ is empty or unavailable, use the number of seeds selected\n",
        "    if n_infuse_features_full == 0:\n",
        "        n_infuse_features_full = len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 6\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not determine n_infuse_features_full from pre-fitted model: {e}. Using default k=2.\")\n",
        "    n_infuse_features_full = 2\n",
        "\n",
        "k_compare = max(2, n_infuse_features_full) # Ensure at least 2 features for comparison\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "techniques = {}\n",
        "\n",
        "# 1. INFUSE Features (Using the pre-fitted model on the full dataset)\n",
        "# INFUSE handles its own scaling internally on the raw data.\n",
        "# We use the ALREADY FITTED 'infuse' object to transform the pre-filtered train/test sets.\n",
        "# CRITICAL: Pass the PRE-FILTERED data (972, 1000) and (243, 1000) to infuse.transform()\n",
        "try:\n",
        "    print(\"\\n--- Transforming Test Data with Pre-fitted INFUSE Model ---\")\n",
        "    # Transform the pre-filtered train and test sets using the already fitted infuse model\n",
        "    # This uses the scaler_, seeds_, graph, etc., learned from the full X, y_encoded (1215, 1000)\n",
        "    Z_train_infuse_full = infuse.transform(X_train_full)\n",
        "    Z_test_infuse_full = infuse.transform(X_test_full)\n",
        "\n",
        "    # Check if transformation produced features\n",
        "    if Z_train_infuse_full.size > 0 and Z_test_infuse_full.size > 0:\n",
        "        techniques['INFUSE (Fitted Full)'] = (Z_train_infuse_full, Z_test_infuse_full)\n",
        "        print(f\"âœ… INFUSE Features (using fitted model on full data): Train {Z_train_infuse_full.shape}, Test {Z_test_infuse_full.shape}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ INFUSE transformation (full model) resulted in empty matrices. Skipping this variant.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to transform with pre-fitted INFUSE model: {e}\")\n",
        "\n",
        "# --- For a more rigorous comparison, fit INFUSE only on training data ---\n",
        "try:\n",
        "    print(\"\\n--- Fitting INFUSE on Training Data Only (Rigorous Comparison) ---\")\n",
        "    # Re-instantiate INFUSE with the same parameters as used in Section 2\n",
        "    # CRITICAL: Pass the ORIGINAL feature names corresponding to the pre-filtered X_train_full\n",
        "    # We need the feature names for the 1000 features in X_train_full\n",
        "    # Assuming feature_names corresponds to the 1000 features in the original X from Section 1\n",
        "    feature_names_for_train = feature_names # From Section 1, should be length 1000\n",
        "\n",
        "    infuse_train = INFUSE(\n",
        "        k_seeds=20,               # Match Section 2\n",
        "        jsd_threshold=0.35,       # Match Section 2\n",
        "        alpha=0.6,                # Match Section 2\n",
        "        beta=0.2,                 # Match Section 2\n",
        "        max_features=1000,        # Match Section 2 (This should be <= X_train_full.shape[1])\n",
        "        stability_thresh=0.5,     # Match Section 2\n",
        "        final_k=2,                # Match Section 2\n",
        "        verbose=False,            # Turn off verbose for cleaner benchmarking output\n",
        "        random_state=42           # Match Section 2\n",
        "    )\n",
        "    # Fit ONLY on the pre-filtered training data (972, 1000) and corresponding labels (972,)\n",
        "    # Pass the feature names for these 1000 features\n",
        "    Z_train_infuse_rigorous = infuse_train.fit_transform(X_train_full, y_train_full, feature_names=feature_names_for_train)\n",
        "    # Transform the pre-filtered test data (243, 1000) using the model fitted on training data\n",
        "    # CRITICAL: X_test_full must have the SAME 1000 features in the SAME ORDER\n",
        "    Z_test_infuse_rigorous = infuse_train.transform(X_test_full)\n",
        "\n",
        "    if Z_train_infuse_rigorous.size > 0 and Z_test_infuse_rigorous.size > 0:\n",
        "        techniques['INFUSE (Train Only)'] = (Z_train_infuse_rigorous, Z_test_infuse_rigorous)\n",
        "        print(f\"âœ… INFUSE Features (fitted on train only): Train {Z_train_infuse_rigorous.shape}, Test {Z_test_infuse_rigorous.shape}\")\n",
        "        n_infuse_features_rigorous = Z_train_infuse_rigorous.shape[1]\n",
        "        # Update k_compare if this rigorous fit produced a different number of features\n",
        "        if n_infuse_features_rigorous > 0 and n_infuse_features_rigorous != k_compare:\n",
        "             print(f\"âš ï¸ Rigorous INFUSE produced {n_infuse_features_rigorous} features. Updating comparison k.\")\n",
        "             k_compare = max(2, n_infuse_features_rigorous)\n",
        "    else:\n",
        "        print(\"âš ï¸ Rigorous INFUSE fit/transform resulted in empty matrices.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to fit/transform INFUSE on training  {e}\")\n",
        "\n",
        "# --- D. Other Techniques (using pre-filtered, standardized data) ---\n",
        "print(f\"\\n Comparing techniques using k={k_compare} features/components.\")\n",
        "\n",
        "# 2. Top K Univariate Features (F-score)\n",
        "selector_fscore = SelectKBest(score_func=f_classif, k=k_compare)\n",
        "X_train_fscore = selector_fscore.fit_transform(X_train_full, y_train_full)\n",
        "X_test_fscore = selector_fscore.transform(X_test_full)\n",
        "techniques['TopK_Fscore'] = (X_train_fscore, X_test_fscore)\n",
        "print(f\"âœ… Top {k_compare} F-score Features Selected: Train {X_train_fscore.shape}, Test {X_test_fscore.shape}\")\n",
        "\n",
        "# 3. Top K Univariate Features (Mutual Information)\n",
        "selector_mi = SelectKBest(score_func=mutual_info_classif, k=k_compare)\n",
        "# Mutual info can benefit from scaling, though it's not strictly required.\n",
        "# X_train_full and X_test_full are already scaled from Section 1.\n",
        "# Using them directly is acceptable, but re-scaling on train only is safer practice.\n",
        "scaler_mi = StandardScaler()\n",
        "X_train_scaled_mi = scaler_mi.fit_transform(X_train_full)\n",
        "X_test_scaled_mi = scaler_mi.transform(X_test_full)\n",
        "\n",
        "X_train_mi = selector_mi.fit_transform(X_train_scaled_mi, y_train_full)\n",
        "X_test_mi = selector_mi.transform(X_test_scaled_mi)\n",
        "techniques['TopK_MI'] = (X_train_mi, X_test_mi)\n",
        "print(f\"âœ… Top {k_compare} MI Features Selected: Train {X_train_mi.shape}, Test {X_test_mi.shape}\")\n",
        "\n",
        "# 4. Principal Component Analysis (PCA)\n",
        "# PCA requires the data to be scaled. X_train_full/X_test_full are already scaled from Section 1.\n",
        "# But let's re-scale to be absolutely sure, as PCA is sensitive to scale.\n",
        "# Fit scaler on training data only\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_full)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_full)\n",
        "\n",
        "pca = PCA(n_components=k_compare)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)\n",
        "techniques['PCA'] = (X_train_pca, X_test_pca)\n",
        "print(f\"âœ… Top {k_compare} PCA Components Derived: Train {X_train_pca.shape}, Test {X_test_pca.shape}\")\n",
        "\n",
        "# 5. Recursive Feature Elimination (RFE) with Logistic Regression\n",
        "# RFE is a wrapper method and can be computationally expensive.\n",
        "# We'll apply it to the pre-filtered features (1000).\n",
        "# Fit RFE on the scaled training data (X_train_full is already scaled from Section 1)\n",
        "# But for consistency with MI, let's use the scaler fitted on X_train_full\n",
        "X_train_scaled_rfe = scaler_mi.transform(X_train_full) # Re-use scaler from MI step\n",
        "X_test_scaled_rfe = scaler_mi.transform(X_test_full)\n",
        "\n",
        "estimator_rfe = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rfe = RFE(estimator=estimator_rfe, n_features_to_select=k_compare)\n",
        "# Fit RFE on the scaled training data\n",
        "X_train_rfe = rfe.fit_transform(X_train_scaled_rfe, y_train_full)\n",
        "X_test_rfe = rfe.transform(X_test_scaled_rfe)\n",
        "techniques['RFE_LR'] = (X_train_rfe, X_test_rfe)\n",
        "print(f\"âœ… Top {k_compare} Features Selected by RFE (LR): Train {X_train_rfe.shape}, Test {X_test_rfe.shape}\")\n",
        "\n",
        "# --- E. Evaluate Discriminative Ability ---\n",
        "cv_scores = {} # To store cross-validation results\n",
        "test_scores = {} # To store final test set results\n",
        "\n",
        "# Use StratifiedKFold for robust CV, especially with imbalanced data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DISCRIMINATIVE ABILITY\")\n",
        "print(\"(Cross-Validation on Train Set & Final Evaluation on Test Set)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating with {model_name} ---\")\n",
        "    cv_scores[model_name] = {}\n",
        "    test_scores[model_name] = {}\n",
        "\n",
        "    for tech_name, (X_tr, X_te) in techniques.items():\n",
        "        # Check if technique produced valid data\n",
        "        if X_tr.size == 0 or X_te.size == 0 or X_tr.shape[1] == 0 or X_te.shape[1] == 0:\n",
        "            print(f\"  Skipping {tech_name} (empty or zero-feature matrix)\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': 'N/A'}\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # --- Cross-Validation on Training Set ---\n",
        "            cv_acc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='accuracy')\n",
        "\n",
        "            # For AUC, we need predict_proba. Check if the model supports it.\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                cv_auc_scores = cross_val_score(model, X_tr, y_train_full, cv=cv, scoring='roc_auc')\n",
        "            else:\n",
        "                cv_auc_scores = [np.nan] * len(cv_acc_scores)\n",
        "\n",
        "            cv_scores[model_name][tech_name] = {\n",
        "                'accuracy': (np.mean(cv_acc_scores), np.std(cv_acc_scores)),\n",
        "                'auc': (np.nanmean(cv_auc_scores), np.nanstd(cv_auc_scores))\n",
        "            }\n",
        "\n",
        "            # --- Final Evaluation on Test Set ---\n",
        "            model.fit(X_tr, y_train_full)\n",
        "            y_pred = model.predict(X_te)\n",
        "            test_acc = accuracy_score(y_test_full, y_pred)\n",
        "\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_proba = model.predict_proba(X_te)[:, 1] # Probability of positive class\n",
        "                test_auc = roc_auc_score(y_test_full, y_proba)\n",
        "            else:\n",
        "                test_auc = np.nan\n",
        "\n",
        "            test_scores[model_name][tech_name] = {\n",
        "                'accuracy': test_acc,\n",
        "                'auc': test_auc,\n",
        "                # Store the full report string\n",
        "                'report': classification_report(y_test_full, y_pred, output_dict=False)\n",
        "            }\n",
        "\n",
        "            print(f\"  {tech_name}:\")\n",
        "            print(f\"    CV Acc: {cv_scores[model_name][tech_name]['accuracy'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['accuracy'][1]*2:.4f})\")\n",
        "            print(f\"    CV AUC: {cv_scores[model_name][tech_name]['auc'][0]:.4f} \"\n",
        "                  f\"(+/- {cv_scores[model_name][tech_name]['auc'][1]*2:.4f})\")\n",
        "            print(f\"    Test Acc: {test_scores[model_name][tech_name]['accuracy']:.4f}\")\n",
        "            print(f\"    Test AUC: {test_scores[model_name][tech_name]['auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error evaluating {tech_name} with {model_name}: {e}\")\n",
        "            cv_scores[model_name][tech_name] = {'accuracy': (np.nan, np.nan), 'auc': (np.nan, np.nan)}\n",
        "            test_scores[model_name][tech_name] = {'accuracy': np.nan, 'auc': np.nan, 'report': f'Error: {e}'}\n",
        "\n",
        "\n",
        "# --- F. Summarize and Report Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY OF DISCRIMINATIVE ABILITY COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n--- Performance Summary for {model_name} ---\")\n",
        "\n",
        "    # 1. Cross-Validation Performance Table\n",
        "    print(f\"  Cross-Validation Performance (Train Set):\")\n",
        "    print(f\"  {'Technique':<25} {'CV Acc (mean +/- std)':<30} {'CV AUC (mean +/- std)':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    if model_name in cv_scores:\n",
        "        sorted_techs_cv = sorted(cv_scores[model_name].items(), key=lambda item: item[1]['accuracy'][0], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_cv:\n",
        "            if not (np.isnan(scores['accuracy'][0]) and np.isnan(scores['auc'][0])):\n",
        "                acc_mean, acc_std = scores['accuracy']\n",
        "                auc_mean, auc_std = scores['auc']\n",
        "                # Corrected formatting without colons outside braces\n",
        "                print(f\"  {tech_name:<25} {acc_mean:.4f} (+/- {acc_std*2:.4f}) {auc_mean:.4f} (+/- {auc_std*2:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<30} {'N/A':<30}\")\n",
        "    print(\"  \" + \"-\" * 85)\n",
        "\n",
        "    # 2. Final Test Set Performance Table\n",
        "    print(f\"  Final Test Set Performance:\")\n",
        "    print(f\"  {'Technique':<25} {'Test Acc':<12} {'Test AUC':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    if model_name in test_scores:\n",
        "        sorted_techs_test = sorted(test_scores[model_name].items(), key=lambda item: item[1]['accuracy'], reverse=True)\n",
        "        for tech_name, scores in sorted_techs_test:\n",
        "            test_acc = scores['accuracy']\n",
        "            test_auc = scores['auc']\n",
        "            if not (np.isnan(test_acc) and np.isnan(test_auc)):\n",
        "                print(f\"  {tech_name:<25} {test_acc:.4f:<12} {test_auc:.4f:<12}\")\n",
        "            else:\n",
        "                 print(f\"  {tech_name:<25} {'N/A':<12} {'N/A':<12}\")\n",
        "    print(\"  \" + \"-\" * 50)\n",
        "\n",
        "    # 3. (Optional) Detailed Test Set Classification Reports\n",
        "    # Uncomment the lines below if you want to print detailed reports\n",
        "    # print(f\"  Detailed Classification Reports (Test Set):\")\n",
        "    # for tech_name, scores in sorted_techs_test:\n",
        "    #     if 'report' in scores and isinstance(scores['report'], str) and scores['report'] != 'N/A':\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report:\")\n",
        "    #         print(scores['report'])\n",
        "    #     else:\n",
        "    #         print(f\"\\n  {tech_name.upper()} Report: N/A or Error\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BENCHMARKING COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Oka0_jnSP0Dr",
        "outputId": "6d867305-86c8-4a04-8a98-d2c5633a7da9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BENCHMARKING INFUSE AGAINST OTHER TECHNIQUES\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2215734788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Ensure this split uses the same random_state as your main analysis if needed for consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" Train Set Shape: {X_train_full.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYlZ0mA7P0IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJuiGaVUeFl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.0 (Final Robust Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology. INFUSE is a transformer designed\n",
        "# for high-dimensional biological data (e.g., gene expression) to construct\n",
        "# new, stable, and potentially interpretable cohort features. It integrates\n",
        "# concepts of seed selection, multi-criteria hybrid weighting, graph-based\n",
        "# regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "from scipy.special import softmax\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # Use 'ensure_all_finite' to fix FutureWarning\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary adjacency matrix\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Point-Biserial r^2.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "TYvcgGl7eFrV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmMJ8qpNhV7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final_robust_graph.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: Final Robust Graph Implementation (Addressing Core Failure Mode)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with a focus on robust graph construction.\n",
        "# The core issue of fully connected graphs and 1000-member cohorts is addressed\n",
        "# by ensuring the _graph_regularization method builds a proper k-NN graph on X.T.\n",
        "# All other components remain as per the final academic implementation.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Import kneighbors_graph for graph construction\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- CRITICAL FIX: Graph regularization - Build graph on X.T using cosine distance ---\n",
        "        graph = self._graph_regularization(X) # Pass ONLY the scaled data matrix X\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- CRITICAL FIX: ROBUST _graph_regularization to build graph on X.T ---\n",
        "    def _graph_regularization(self, X): # Takes ONLY the scaled data matrix X\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        This method correctly builds the graph on the feature data X using cosine distance.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Build graph directly on X.T using cosine distance ---\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # --- CRITICAL FIX: Recompute graph if needed - FIXED to use X ---\n",
        "        graph = self._graph_regularization(X) # Pass ONLY the scaled data matrix X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "as-OBJ8BhWJi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZuvgrxNj_vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final_robust_graph.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: Final Robust Graph Implementation (Addressing Core Failure Mode)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with a focus on robust graph construction.\n",
        "# The core issue of fully connected graphs and 1000-member cohorts is addressed\n",
        "# by ensuring the _graph_regularization method builds a proper k-NN graph on X.T.\n",
        "# All other components remain as per the final academic implementation.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Import kneighbors_graph for graph construction\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import pointbiserialr for stability evaluation\n",
        "from scipy.stats import pointbiserialr\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- CRITICAL FIX: Graph regularization - Build graph on X.T using cosine distance ---\n",
        "        graph = self._graph_regularization(X) # Pass ONLY the scaled data matrix X\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use Point-Biserial r^2\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- CRITICAL FIX: ROBUST _graph_regularization to build graph on X.T ---\n",
        "    def _graph_regularization(self, X): # Takes ONLY the scaled data matrix X\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        This method correctly builds the graph on the feature data X using cosine distance.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # --- CRITICAL: Build graph directly on X.T using cosine distance ---\n",
        "            # Determine k automatically based on the number of features\n",
        "            n_features = X.shape[1]\n",
        "            # Heuristic: k is 0.5% of the number of features, bounded between 3 and 20.\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                 print(f\"   Automatically determined k: {auto_k} (based on {n_features} features)\")\n",
        "\n",
        "            # Use cosine distance between feature profiles for gene expression\n",
        "            # kneighbors_graph(X.T, ...) finds neighbors for each ROW of X.T (i.e., each feature)\n",
        "            graph = kneighbors_graph(\n",
        "                X.T,                      # Transpose so features are rows\n",
        "                n_neighbors=auto_k,       # Use the automatically determined k\n",
        "                mode='connectivity',      # Binary adjacency matrix\n",
        "                include_self=False,       # Important: Seed should be explicitly added later\n",
        "                metric='cosine',          # Use cosine distance between feature profiles\n",
        "                n_jobs=1                  # Use 1 core for clarity/debugging\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Point-Biserial r^2 ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            r_pb_squared_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for r_pb\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate Point-Biserial correlation coefficient 'r_pb'\n",
        "                        r_pb_result = pointbiserialr(Zb[:, i], yb)\n",
        "                        r_pb = r_pb_result.correlation\n",
        "\n",
        "                        # 3. Calculate r_pb^2 (Point-Biserial r-squared)\n",
        "                        #    This represents the proportion of variance in Zb[:, i]\n",
        "                        #    explained by yb. It's bounded [0, 1].\n",
        "                        r_pb_squared = r_pb ** 2\n",
        "\n",
        "                        # 4. Append the calculated r_pb^2 value\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(r_pb_squared):\n",
        "                             r_pb_squared_vals.append(r_pb_squared)\n",
        "                        else:\n",
        "                             r_pb_squared_vals.append(0.0) # Default score for invalid r_pb^2\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 5. Fallback: Assign default score if calculation fails\n",
        "                        r_pb_squared_vals.append(0.0)\n",
        "                else:\n",
        "                    # 6. Fallback: Assign default score if only one class in bootstrap\n",
        "                    r_pb_squared_vals.append(0.0)\n",
        "\n",
        "            # 7. Calculate the cohort's stability score S_j as the mean r_pb^2\n",
        "            if r_pb_squared_vals:\n",
        "                S_j = np.mean(r_pb_squared_vals)\n",
        "            else:\n",
        "                # Edge case: No valid r_pb^2 calculated (e.g., all bootstraps failed)\n",
        "                S_j = 0.0\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # --- CRITICAL FIX: Recompute graph if needed - FIXED to use X ---\n",
        "        graph = self._graph_regularization(X) # Pass ONLY the scaled data matrix X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n"
      ],
      "metadata": {
        "id": "MkhySrbakAnV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "# Note: Scaling is done on the imputed X_df\n",
        "scaler = StandardScaler()\n",
        "try:\n",
        "    # Fit and transform the imputed data\n",
        "    X_scaled = scaler.fit_transform(X_df.values)\n",
        "    print(f\"âœ… Data successfully scaled. Final scaled data shape: {X_scaled.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âŒ Error during scaling: {e}\")\n",
        "    # Handle potential edge cases (should be rare after imputation)\n",
        "    X_scaled = np.empty((X_df.shape[0], 0))\n",
        "    print(f\"   Returned empty scaled data matrix.\")\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes (scaled data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_scaled): {X_scaled.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Assign final outputs for use in subsequent sections ---\n",
        "X = X_scaled  # Use the scaled, imputed data\n",
        "y = y_encoded # Use the encoded labels\n",
        "# feature_names now refers to the features in the scaled data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IuxlDQ2eFxD",
        "outputId": "105dfcac-a371-4a00-a63f-98a4a0cac0de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "âœ… Data successfully scaled. Final scaled data shape: (1215, 20530)\n",
            " First 10 genes (scaled data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_scaled): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "# CRITICAL FIX: Lowered stability_thresh to address class imbalance sensitivity\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,          # Number of initial seed candidates based on F-scores\n",
        "    jsd_threshold=0.25,  # Minimum JSD dissimilarity required between seed candidates\n",
        "    alpha=0.6,           # Weight for the cosine similarity component in hybrid weighting\n",
        "    beta=0.2,            # Weight for the JSD dissimilarity penalty in hybrid weighting\n",
        "    # --- CRITICAL FIX: Lowered stability threshold for imbalanced data ---\n",
        "    stability_thresh=0.015, # <-- LOWERED from 0.5 to 0.1 to address low stability scores\n",
        "    # --- END OF CRITICAL FIX ---\n",
        "    #final_k=4,           # Number of top cohorts to keep if none meet stability_thresh\n",
        "    n_bootstrap=100,     # Number of bootstrap iterations for stability evaluation\n",
        "    max_features=1000,   # Initial pre-filtering to this many top F-score features\n",
        "    verbose=True,        # Print progress messages\n",
        "    random_state=42      # Controls the randomness of the estimator\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35PM7KhkeF2S",
        "outputId": "fa5342d6-feeb-4b17-f513-1405ab4f1938"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'FAM128A', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            "âœ… Similarity matrix computed: (1000, 17)\n",
            "âš™ï¸ Weight matrix shape: (1000, 17)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 17)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "   Automatically determined k: 5 (based on 1000 features)\n",
            "âœ… Graph built with k=5, density=0.005000, metric='cosine'\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 6\n",
            "âœ… Cohort fusion completed: (1215, 17)\n",
            "âœ… Final filtering completed: (1215, 17)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "    cohort_id  seed_gene  num_members  \\\n",
            "0           0      KLF10            6   \n",
            "1           1       APOB            6   \n",
            "2           2       LEPR            6   \n",
            "3           3      KLF11            6   \n",
            "4           4       ADH4            6   \n",
            "5           5       UBTF            6   \n",
            "6           6      CRHR2            6   \n",
            "7           7     ZNF295            6   \n",
            "8           8     LRRC45            6   \n",
            "9           9  LOC729467            6   \n",
            "10         10     CLEC4M            6   \n",
            "11         11    FAM128A            6   \n",
            "12         12      SAMD1            6   \n",
            "13         13      CCDC9            6   \n",
            "14         14     TMEM22            6   \n",
            "15         15     DNAJB4            6   \n",
            "16         16       EMP1            6   \n",
            "\n",
            "                                         member_genes  stability  \n",
            "0       [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.043768  \n",
            "1       [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.030426  \n",
            "2            [CAV1, EBF1, SVEP1, TGFBR2, ABCA9, LEPR]   0.027315  \n",
            "3             [EHBP1, NMT2, SOS1, SPTBN1, QKI, KLF11]   0.032405  \n",
            "4             [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.033537  \n",
            "5       [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.035371  \n",
            "6           [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.032093  \n",
            "7          [DDX3X, GABPA, JMJD1C, MLL, MORC3, ZNF295]   0.032186  \n",
            "8     [AZI1, ASPSCR1, SIRT7, CCDC137, STRA13, LRRC45]   0.030393  \n",
            "9     [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.036834  \n",
            "10   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.044387  \n",
            "11  [MRPS34, FAM128B, C14orf80, HMG20B, NUBP2, FAM...   0.030449  \n",
            "12  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.032524  \n",
            "13        [ZGPAT, BBC3, SCAF1, LENG1, HDGFRP2, CCDC9]   0.030092  \n",
            "14          [LDB2, CAV1, AOC3, EBF1, CXorf36, TMEM22]   0.023923  \n",
            "15       [CAV2, PPAP2B, SLC16A7, TGFBR2, QKI, DNAJB4]   0.024972  \n",
            "16            [FHL1, CAV1, CAV2, ADAMTS5, SRPX, EMP1]   0.026068  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 17\n",
            "Final output cohorts (kept): 17\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 0.04\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 0.03\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            " Cohort 2 | Seed: LEPR | Stability: 0.03\n",
            "  Top members: CAV1, EBF1, SVEP1, TGFBR2, ABCA9, LEPR \n",
            "\n",
            " Cohort 3 | Seed: KLF11 | Stability: 0.03\n",
            "  Top members: EHBP1, NMT2, SOS1, SPTBN1, QKI, KLF11 \n",
            "\n",
            " Cohort 4 | Seed: ADH4 | Stability: 0.03\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            " Cohort 5 | Seed: UBTF | Stability: 0.04\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            " Cohort 6 | Seed: CRHR2 | Stability: 0.03\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            " Cohort 7 | Seed: ZNF295 | Stability: 0.03\n",
            "  Top members: DDX3X, GABPA, JMJD1C, MLL, MORC3, ZNF295 \n",
            "\n",
            " Cohort 8 | Seed: LRRC45 | Stability: 0.03\n",
            "  Top members: AZI1, ASPSCR1, SIRT7, CCDC137, STRA13, LRRC45 \n",
            "\n",
            " Cohort 9 | Seed: LOC729467 | Stability: 0.04\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            " Cohort 10 | Seed: CLEC4M | Stability: 0.04\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            " Cohort 11 | Seed: FAM128A | Stability: 0.03\n",
            "  Top members: MRPS34, FAM128B, C14orf80, HMG20B, NUBP2, FAM128A \n",
            "\n",
            " Cohort 12 | Seed: SAMD1 | Stability: 0.03\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1 \n",
            "\n",
            " Cohort 13 | Seed: CCDC9 | Stability: 0.03\n",
            "  Top members: ZGPAT, BBC3, SCAF1, LENG1, HDGFRP2, CCDC9 \n",
            "\n",
            " Cohort 14 | Seed: TMEM22 | Stability: 0.02\n",
            "  Top members: LDB2, CAV1, AOC3, EBF1, CXorf36, TMEM22 \n",
            "\n",
            " Cohort 15 | Seed: DNAJB4 | Stability: 0.02\n",
            "  Top members: CAV2, PPAP2B, SLC16A7, TGFBR2, QKI, DNAJB4 \n",
            "\n",
            " Cohort 16 | Seed: EMP1 | Stability: 0.03\n",
            "  Top members: FHL1, CAV1, CAV2, ADAMTS5, SRPX, EMP1 \n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCI7GlHCeF7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ohs_Z6DGeGGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBRUDmYxuKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FILE: infuse_permutation_test.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.0 (Permutation Test Implementation)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# This file implements the INFUSE (Integrative Neighborhood Feature Selection\n",
        "# Using Stability Evaluation) methodology with permutation testing for stability.\n",
        "# INFUSE is a transformer designed for high-dimensional biological data\n",
        "# (e.g., gene expression) to construct new, stable, and potentially interpretable\n",
        "# cohort features. It integrates concepts of seed selection, multi-criteria\n",
        "# hybrid weighting, graph-based regularization, and empirical stability evaluation.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "#\n",
        "# USAGE:\n",
        "# from infuse_permutation_test import INFUSE\n",
        "# infuse_model = INFUSE(...)\n",
        "# Z_final = infuse_model.fit_transform(X, y, feature_names=feature_names_list)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.utils import check_array\n",
        "# Import Softmax for normalization\n",
        "from scipy.special import softmax\n",
        "# Import ttest_ind for permutation test\n",
        "from scipy.stats import ttest_ind\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\") # Optional: Re-enable for debugging if needed\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, n_neighbors=50, alpha=0.6, beta=0.2,\n",
        "                 jsd_threshold=0.35,\n",
        "                 k_graph=5, n_bootstrap=100,\n",
        "                 stability_thresh=0.5, final_k=2, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        n_neighbors : int, default=50\n",
        "            (Deprecated/Unused in final graph) Placeholder from earlier versions.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        k_graph : int, default=5\n",
        "            (Deprecated/Unused) Placeholder from earlier versions.\n",
        "            Final version uses automatic k determination.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap accuracy/r^2 for a cohort to be kept.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Initial pre-filtering to this many top F-score features.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls the randomness of the estimator.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.k_graph = k_graph\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.final_k = final_k\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        This calls fit_transform and sets the fitted flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        return self.fit_transform(X, y, feature_names)\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer and return the transformed data.\n",
        "\n",
        "        Executes the full INFUSE pipeline.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- UPDATE: Use 'ensure_all_finite' to fix FutureWarning ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle NaNs\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filtering\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        # Fix: Correctly assign fscores_ dictionary using feature names as keys\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Dissimilarity filtering - FIXED with Softmax\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Convert X to a DataFrame with named columns for easier handling\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "\n",
        "        # Compute similarities between ALL features and the FILTERED seed features\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Hybrid weighting - FIXED with Softmax\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.all(weights == weights[0, 0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input similarity/JSD structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph regularization - FIXED to use X for feature graph\n",
        "        graph = self._graph_regularization(X, seed_names_filtered) # Pass X, not weights\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Final filtering - Updated to use permutation testing with empirical p-values\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "        return Z_final\n",
        "\n",
        "    # --- FIXED _dissimilarity_filter using Softmax ---\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"\n",
        "        Filter seed candidates to enforce diversity using JSD on Softmax profiles.\n",
        "        \"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        # Apply Softmax normalization to the entire data matrix for consistent JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "\n",
        "        for i in range(len(seed_indices)):\n",
        "            redundant = False\n",
        "            # Compare with all previously kept seeds\n",
        "            for j in keep: # Compare with previously kept seeds\n",
        "                # Calculate JSD using SOFTMAX-normalized profiles\n",
        "                jsd = jensenshannon(X_softmax[:, seed_indices[i]], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(seed_indices[i])\n",
        "\n",
        "        filtered_names = [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "        return filtered_names\n",
        "\n",
        "    # --- FIXED _hybrid_weights using Softmax ---\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"\n",
        "        Calculate hybrid weights combining similarity, F-score, and JSD dissimilarity.\n",
        "        \"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        # Avoid division by zero\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        if denom == 0:\n",
        "             fs_norm = np.zeros_like(fscores_arr)\n",
        "        else:\n",
        "            fs_norm = (fscores_arr - fs_min) / denom\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        # Apply Softmax normalization for JSD calculation\n",
        "        X_softmax = softmax(X, axis=0) # axis=0: softmax across samples for each feature\n",
        "        jsd_div = np.zeros_like(similarities) # Shape (n_features, n_seeds_filtered)\n",
        "\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile_softmax = X_softmax[:, seed_idx] # Softmax-normalized seed profile\n",
        "            # Compute JSD between each feature and this seed using Softmax profiles\n",
        "            for j in range(X.shape[1]): # Iterate through all features\n",
        "                 gene_profile_softmax = X_softmax[:, j] # Softmax-normalized gene profile\n",
        "                 jsd_div[j, i] = jensenshannon(gene_profile_softmax, seed_profile_softmax)\n",
        "\n",
        "        # Similarity contributes positively, F-score contributes positively, JSD contributes negatively\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None) # Ensure non-negative weights\n",
        "        if self.verbose:\n",
        "            print(f\"âš™ï¸ Weight matrix shape: {weights.shape}\")\n",
        "            print(f\"ðŸ“Œ Max weight: {weights.max():.4f} | Min weight: {weights.min():.4f}\")\n",
        "        return weights\n",
        "\n",
        "    # --- FIXED AND ROBUST _graph_regularization to build graph on X ---\n",
        "    def _graph_regularization(self, X, seed_names): # Takes X and seed_names\n",
        "        \"\"\"\n",
        "        Constructs a k-NN graph based on feature similarities in X.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                 print(f\"   _graph_regularization input X shape: {X.shape}\")\n",
        "\n",
        "            # 1. Compute pairwise similarities between features\n",
        "            #    X is (n_samples, n_features).\n",
        "            #    cosine_similarity(X.T) gives (n_features, n_features) similarity matrix.\n",
        "            feature_similarities = cosine_similarity(X.T) # Shape: (n_features, n_features)\n",
        "\n",
        "            # 2. Construct k-NN graph based on feature similarities\n",
        "            #    include_self=False is important.\n",
        "            graph = kneighbors_graph(\n",
        "                feature_similarities, # The data representing points (features) and their similarities\n",
        "                n_neighbors=self.k_graph,\n",
        "                metric='precomputed', # Because we provide a precomputed similarity matrix\n",
        "                mode='connectivity', # Binary adjacency matrix\n",
        "                include_self=False, # Important: Seed should be explicitly added later\n",
        "                n_jobs=-1 # Use all cores\n",
        "            )\n",
        "            graph_dense = graph.toarray() # Convert to dense (n_features, n_features)\n",
        "\n",
        "            if self.verbose:\n",
        "                density = np.count_nonzero(graph_dense) / (graph_dense.shape[0] * graph_dense.shape[1])\n",
        "                print(f\"âœ… Graph built with k={self.k_graph}, density={density:.6f}, metric='cosine'\")\n",
        "\n",
        "            return graph_dense # Shape: (n_features, n_features)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {type(e).__name__} - {e}. Using fully connected graph.\")\n",
        "            # Fallback: Fully connected graph (no regularization effect)\n",
        "            return np.ones((X.shape[1], X.shape[1]), dtype=float)\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"\n",
        "        Fuse features within defined neighborhoods to create cohort representations.\n",
        "        \"\"\"\n",
        "        fused = []\n",
        "        members = []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "\n",
        "            # 1. Find neighbors of the seed using the precomputed graph\n",
        "            #    graph[seed_idx] gives a row indicating which features\n",
        "            #    are neighbors of the seed (seed_idx).\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0] # Indices of neighbors\n",
        "\n",
        "            # 2. Ensure the seed itself is included in its cohort\n",
        "            #    (graph was built with include_self=False)\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            if self.verbose and i == 0: # Print info for first cohort\n",
        "                 print(f\"   Cohort 0 (Seed: {seed_name}) - Neighbors found: {len(neighbors)}\")\n",
        "\n",
        "            # 3. Get weights for the selected neighbors for this specific seed\n",
        "            #    weights[neighbors, i] gets the weights assigned to each neighbor\n",
        "            #    for the i-th seed.\n",
        "            w = weights[neighbors, i]\n",
        "\n",
        "            # 4. Normalize weights for convex combination\n",
        "            w_sum = w.sum()\n",
        "            if w_sum > 0:\n",
        "                w = w / w_sum\n",
        "            else:\n",
        "                # Fallback: uniform weights if all are zero\n",
        "                w = np.ones_like(w) / len(w)\n",
        "\n",
        "            # 5. Fuse the feature vectors using the weights\n",
        "            #    X[:, neighbors] is (n_samples, n_neighbors)\n",
        "            #    w is (n_neighbors,)\n",
        "            #    Result is (n_samples,) - the fused cohort vector\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "\n",
        "            # 6. Store cohort details\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "\n",
        "        # 7. Combine all fused cohort vectors into the final matrix Z\n",
        "        if fused:\n",
        "            Z = np.column_stack(fused) # Shape: (n_samples, n_seeds_filtered)\n",
        "        else:\n",
        "            # Edge case: no cohorts formed\n",
        "            Z = np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    # --- UPDATED _final_filter using Permutation Testing with Empirical p-values ---\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using Permutation Testing with Empirical p-values.\n",
        "        \"\"\"\n",
        "        from scipy.stats import ttest_ind\n",
        "        stabilities = []\n",
        "        for i in range(Z.shape[1]): # Iterate through each cohort feature\n",
        "            p_emp_vals = []\n",
        "            # Use the instance's random state correctly\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=self.random_state)\n",
        "\n",
        "                # 1. Ensure at least 2 classes exist in bootstrap sample for t-test\n",
        "                if len(np.unique(yb)) > 1:\n",
        "                    try:\n",
        "                        # 2. Calculate two-sample t-statistic 't_stat'\n",
        "                        #    This tests if the distribution of Zb[:, i] values differs\n",
        "                        #    significantly between the two groups defined by yb.\n",
        "                        group0 = Zb[yb == 0, i]\n",
        "                        group1 = Zb[yb == 1, i]\n",
        "                        t_stat_result = ttest_ind(group0, group1)\n",
        "                        t_stat = t_stat_result.statistic\n",
        "\n",
        "                        # 3. Generate null distribution T_null via permutation testing\n",
        "                        #    Perform B permutations of the target labels yb\n",
        "                        T_null = []\n",
        "                        for _ in range(self.n_bootstrap): # Use n_bootstrap for null dist\n",
        "                            yb_perm = self.random_state.permutation(yb) # Shuffle labels\n",
        "                            group0_perm = Zb[yb_perm == 0, i]\n",
        "                            group1_perm = Zb[yb_perm == 1, i]\n",
        "                            # Compute t-statistic on permuted data\n",
        "                            t_stat_perm_result = ttest_ind(group0_perm, group1_perm)\n",
        "                            t_stat_perm = t_stat_perm_result.statistic\n",
        "                            T_null.append(t_stat_perm)\n",
        "\n",
        "                        # 4. Calculate empirical p-value p_emp\n",
        "                        #    Determine how extreme the observed t_stat is under the null.\n",
        "                        #    For a two-sided test: p_emp = (number of |T_null| >= |t_stat|) / B\n",
        "                        T_null = np.array(T_null)\n",
        "                        p_emp = np.mean(np.abs(T_null) >= np.abs(t_stat))\n",
        "\n",
        "                        # 5. Derive stability score S_j from p_emp\n",
        "                        #    A low p_emp (strong evidence against H0) indicates high stability.\n",
        "                        #    S_j = 1 - p_emp ensures S_j is bounded [0, 1].\n",
        "                        S_j = 1 - p_emp\n",
        "\n",
        "                        # 6. Append the calculated stability score S_j\n",
        "                        #    Handle potential NaN or Inf from numerical edge cases\n",
        "                        if np.isfinite(S_j):\n",
        "                             p_emp_vals.append(S_j)\n",
        "                        else:\n",
        "                             p_emp_vals.append(0.0) # Default score for invalid S_j\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # print(f\"Warning during bootstrap {i}: {e}\") # Optional debug\n",
        "                        # 7. Fallback: Assign default score if calculation fails\n",
        "                        p_emp_vals.append(0.0)\n",
        "                else:\n",
        "                    # 8. Fallback: Assign default score if only one class in bootstrap\n",
        "                    p_emp_vals.append(0.0)\n",
        "\n",
        "            # 9. Calculate the cohort's final stability score as the mean S_j\n",
        "            if p_emp_vals:\n",
        "                stability_score = np.mean(p_emp_vals)\n",
        "            else:\n",
        "                # Edge case: No valid S_j calculated (e.g., all bootstraps failed)\n",
        "                stability_score = 0.0\n",
        "            stabilities.append(stability_score)\n",
        "\n",
        "        # --- Filtering Logic (Remains the same) ---\n",
        "        # Determine which cohorts to keep based on stability\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "        if not kept:\n",
        "            # If none meet threshold, keep the top final_k\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in top_indices if i < len(stabilities)] # Ensure valid indices\n",
        "            if self.verbose and kept:\n",
        "                print(f\" No stable features met threshold. Keeping top {len(kept)}.\")\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0] # Ultimate fallback\n",
        "        if not kept: # If still nothing kept (e.g., Z was empty or stabilities empty)\n",
        "            return np.empty((Z.shape[0], 0)), [], stabilities\n",
        "\n",
        "        return Z[:, kept], kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform new data using the fitted INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            The transformed data matrix consisting of stable cohort features.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # Select columns in the same order as fitted\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "            # Handle potential missing columns (fill with median from fit?)\n",
        "            # For simplicity, assuming columns match after reindex\n",
        "        X = self.scaler_.transform(X)\n",
        "        # Recompute graph if needed - FIXED to use X\n",
        "        graph = self._graph_regularization(X, self.seeds_) # Pass X\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        if len(self.kept_indices_) > 0 and Z_fused.size > 0:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0)) # Return empty if nothing kept\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        Get output feature names.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_features : ignored\n",
        "            Not used, present here for API consistency.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output_feature_names : list of str\n",
        "            Names of the output features (INFUSE Cohorts).\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        # Number of output features corresponds to kept cohorts\n",
        "        n_output_features = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_output_features)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"\n",
        "        Get a summary of the selected cohort features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            A DataFrame summarizing each selected cohort.\n",
        "        \"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_: # Handle case where no cohorts kept\n",
        "             return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        # Iterate through the *kept* indices\n",
        "        for i, original_idx in enumerate(self.kept_indices_):\n",
        "            if original_idx < len(self.cohort_members_):\n",
        "                cohort = self.cohort_members_[original_idx]\n",
        "                stability = self.stabilities_[original_idx] if original_idx < len(self.stabilities_) else np.nan\n",
        "                summary.append({\n",
        "                    'cohort_id': i, # Use new index for kept cohorts\n",
        "                    'seed_gene': cohort['seed'],\n",
        "                    'num_members': len(cohort['members']),\n",
        "                    'member_genes': cohort['members'], # Show all members\n",
        "                    'stability': stability\n",
        "                })\n",
        "            else:\n",
        "                # Handle potential index mismatch gracefully\n",
        "                warnings.warn(f\"Cohort index {original_idx} out of range for summary.\")\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Print a detailed description of the selected cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int, default=5\n",
        "            Number of top member genes to display for each cohort.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        summary_df : pandas.DataFrame\n",
        "            The summary DataFrame returned by get_cohort_summary().\n",
        "        \"\"\"\n",
        "        summary_df = self.get_cohort_summary()\n",
        "        if summary_df.empty:\n",
        "            print(\"No cohorts to describe.\")\n",
        "            return summary_df\n",
        "        for _, row in summary_df.iterrows():\n",
        "            print(f\"\\n Cohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.2f}\") # Increased decimal places\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return summary_df\n",
        "\n",
        "# Note: The _validate_input, _f_score_selection, _graph_regularization (old version),\n",
        "# and other potentially unused methods from earlier drafts have been omitted\n",
        "# for clarity but can be included if needed elsewhere.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-sjLAFGuKmN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "\n",
        "# Load and transpose expression data (to samples x genes)\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\" Loaded expression  {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\" Loaded clinical  {y_df.shape}\")\n",
        "\n",
        "# Standardize sample IDs to first 15 characters\n",
        "y_df['sample_id'] = y_df['sample'].astype(str).str[:15]\n",
        "y_df = y_df.set_index('sample_id')\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Find common samples\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\" Found {len(common_samples)} common samples\")\n",
        "X_df = X_df.loc[common_samples]\n",
        "y_df = y_df.loc[common_samples]\n",
        "\n",
        "# Remove duplicate clinical entries\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# Extract label\n",
        "label_column = 'vital_status.demographic'\n",
        "y = y_df[label_column].values\n",
        "\n",
        "# Remove NaN labels\n",
        "mask = pd.notna(y)\n",
        "X_df = X_df.iloc[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# --- Robustly Handle NaN/Inf Values in Expression Data BEFORE Scaling ---\n",
        "print(\"\\n--- Handling NaN/Inf Values in Expression Data ---\")\n",
        "# Check for initial presence of NaNs or Infs\n",
        "initial_nan_count = np.isnan(X_df.values).sum()\n",
        "initial_inf_count = np.isinf(X_df.values).sum()\n",
        "print(f\"  Initial NaN count: {initial_nan_count}\")\n",
        "print(f\"  Initial Inf count: {initial_inf_count}\")\n",
        "\n",
        "# 1. Replace Infs with NaNs to simplify handling\n",
        "X_df = X_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 2. Impute remaining NaNs (originally present or converted from Inf)\n",
        "# Use median imputation as it's robust to outliers common in biological data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_df_imputed = pd.DataFrame(imputer.fit_transform(X_df), columns=X_df.columns, index=X_df.index)\n",
        "print(f\"  NaN/Inf values imputed using median strategy.\")\n",
        "\n",
        "# Verify no NaNs or Infs remain after imputation\n",
        "final_nan_count = np.isnan(X_df_imputed.values).sum()\n",
        "final_inf_count = np.isinf(X_df_imputed.values).sum()\n",
        "print(f\"  Final NaN count: {final_nan_count}\")\n",
        "print(f\"  Final Inf count: {final_inf_count}\")\n",
        "if final_nan_count == 0 and final_inf_count == 0:\n",
        "    print(\"âœ… Expression data is now free of NaN/Inf values.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: Some NaN/Inf values may still persist after imputation.\")\n",
        "\n",
        "# Update X_df to the imputed version\n",
        "X_df = X_df_imputed\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\" Final label distribution: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Preprocessing step: Ensure target labels are 1D\n",
        "if y_encoded.ndim > 1:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "# Note: Scaling is done on the imputed X_df\n",
        "scaler = StandardScaler()\n",
        "try:\n",
        "    # Fit and transform the imputed data\n",
        "    X_scaled = scaler.fit_transform(X_df.values)\n",
        "    print(f\"âœ… Data successfully scaled. Final scaled data shape: {X_scaled.shape}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âŒ Error during scaling: {e}\")\n",
        "    # Handle potential edge cases (should be rare after imputation)\n",
        "    X_scaled = np.empty((X_df.shape[0], 0))\n",
        "    print(f\"   Returned empty scaled data matrix.\")\n",
        "\n",
        "# Preserve gene names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\" First 10 genes (scaled data): {feature_names[:10]}\")\n",
        "\n",
        "# Convert one-hot or 2D categorical labels to 1D (if needed)\n",
        "if len(np.unique(y_encoded)) > 2 and y_encoded.ndim == 2:\n",
        "    y_encoded = np.argmax(y_encoded, axis=1)\n",
        "elif y_encoded.ndim > 1:\n",
        "    y_encoded = y_encoded.ravel()\n",
        "\n",
        "print(f\"\\nâœ… Data Loading & Preprocessing (with Imputation) Completed:\")\n",
        "print(f\"   - Final Data Matrix Shape (X_scaled): {X_scaled.shape}\")\n",
        "print(f\"   - Final Target Vector Shape (y_encoded): {y_encoded.shape}\")\n",
        "print(f\"   - Classes: {le.classes_}\")\n",
        "print(f\"   - Counts: {np.bincount(y_encoded)}\")\n",
        "\n",
        "# --- Assign final outputs for use in subsequent sections ---\n",
        "X = X_scaled  # Use the scaled, imputed data\n",
        "y = y_encoded # Use the encoded labels\n",
        "# feature_names now refers to the features in the scaled data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcIi05tIuKsE",
        "outputId": "db89ee5f-4da5-4328-e096-1678c353029a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded expression  (1218, 20530)\n",
            " Loaded clinical  (1255, 85)\n",
            " Found 1216 common samples\n",
            "\n",
            "--- Handling NaN/Inf Values in Expression Data ---\n",
            "  Initial NaN count: 0\n",
            "  Initial Inf count: 0\n",
            "  NaN/Inf values imputed using median strategy.\n",
            "  Final NaN count: 0\n",
            "  Final Inf count: 0\n",
            "âœ… Expression data is now free of NaN/Inf values.\n",
            " First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            " Final label distribution: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "âœ… Data successfully scaled. Final scaled data shape: (1215, 20530)\n",
            " First 10 genes (scaled data): ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Data Loading & Preprocessing (with Imputation) Completed:\n",
            "   - Final Data Matrix Shape (X_scaled): (1215, 20530)\n",
            "   - Final Target Vector Shape (y_encoded): (1215,)\n",
            "   - Classes: ['Alive' 'Dead']\n",
            "   - Counts: [1016  199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RUNNING INFUSE WITH FORCED SEED SELECTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# After preprocessing - with parameters matching the class definition\n",
        "# REMOVED min_cohort_size and max_cohort_size as they are not in the __init__\n",
        "# CRITICAL FIX: Lowered stability_thresh to address class imbalance sensitivity\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,          # Number of initial seed candidates based on F-scores\n",
        "    jsd_threshold=0.35,  # Minimum JSD dissimilarity required between seed candidates\n",
        "    alpha=0.6,           # Weight for the cosine similarity component in hybrid weighting\n",
        "    beta=0.2,            # Weight for the JSD dissimilarity penalty in hybrid weighting\n",
        "    # --- CRITICAL FIX: Lowered stability threshold for imbalanced data ---\n",
        "    stability_thresh=0.1, # <-- LOWERED from 0.5 to 0.1 to address low stability scores\n",
        "    # --- END OF CRITICAL FIX ---\n",
        "    #final_k=4,           # Number of top cohorts to keep if none meet stability_thresh\n",
        "    n_bootstrap=100,     # Number of bootstrap iterations for stability evaluation\n",
        "    max_features=1000,   # Initial pre-filtering to this many top F-score features\n",
        "    verbose=True,        # Print progress messages\n",
        "    random_state=42      # Controls the randomness of the estimator\n",
        ")\n",
        "\n",
        "# Ensure X is the raw data (INFUSE handles scaling) and feature_names is correct\n",
        "# X = X_df.values # Should be raw, unscaled data\n",
        "# feature_names = X_df.columns.tolist()\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y_encoded, feature_names=feature_names) # Pass raw X\n",
        "\n",
        "print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "summary = infuse.get_cohort_summary()\n",
        "print(summary)\n",
        "\n",
        "# Detailed analysis\n",
        "print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "print(f\"Total cohorts formed: {len(infuse.cohorts_) if hasattr(infuse, 'cohorts_') else 'N/A (check attribute name)'}\")\n",
        "# Note: The attribute might be named differently, like cohort_members_ or seeds_\n",
        "print(f\"Number of seeds selected: {len(infuse.seeds_) if hasattr(infuse, 'seeds_') else 'N/A'}\")\n",
        "print(f\"Final output cohorts (kept): {len(infuse.kept_indices_) if hasattr(infuse, 'kept_indices_') else 'N/A'}\")\n",
        "\n",
        "# Use the describe_cohorts method for a detailed view\n",
        "print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "infuse.describe_cohorts(top_n=10) # Show more members\n",
        "\n",
        "print(f\"\\nðŸ“Š Final Output Matrix Shape: {Z_final.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2SnkKcfuKxu",
        "outputId": "ddc2e995-f745-4ee8-cd50-90013b56e85a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RUNNING INFUSE WITH FORCED SEED SELECTION\n",
            "==================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âš™ï¸ Weight matrix shape: (1000, 8)\n",
            "ðŸ“Œ Max weight: 1.0000 | Min weight: 0.0000\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   _graph_regularization input X shape: (1215, 1000)\n",
            "âš ï¸ Graph construction failed: ValueError - Negative values in data passed to X.. Using fully connected graph.\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "   Cohort 0 (Seed: KLF10) - Neighbors found: 1000\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10         1000   \n",
            "1          1       APOB         1000   \n",
            "2          2       ADH4         1000   \n",
            "3          3       UBTF         1000   \n",
            "4          4      CRHR2         1000   \n",
            "5          5  LOC729467         1000   \n",
            "6          6     CLEC4M         1000   \n",
            "7          7      SAMD1         1000   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "1  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "2  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     0.9997  \n",
            "3  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "4  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "5  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "6  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "7  [KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ...     1.0000  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: N/A (check attribute name)\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 8\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            " Cohort 0 | Seed: KLF10 | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 1 | Seed: APOB | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 2 | Seed: ADH4 | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 3 | Seed: UBTF | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 4 | Seed: CRHR2 | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 5 | Seed: LOC729467 | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 6 | Seed: CLEC4M | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            " Cohort 7 | Seed: SAMD1 | Stability: 1.00\n",
            "  Top members: KLF10, APOB, LEPR, KLF11, ADH4, UBTF, CRHR2, ZNF295, LRRC45, LOC729467 ...\n",
            "\n",
            "ðŸ“Š Final Output Matrix Shape: (1215, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSiK-FjCNPDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zF7kaxnVNPJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "liYxEdaGNPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GBnMfszcNPVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 4.2 (Final Academic Implementation - Adaptive Final Selection)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# INFUSE (Integrative Neighborhood Feature Selection Using Stability Evaluation)\n",
        "# constructs stable, interpretable cohort features from high-dimensional biological data.\n",
        "# This version removes 'final_k' to allow fully adaptive cohort selection based on\n",
        "# empirical stability (AUC-ROC), without hardcoding the number of outputs.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "\n",
        "    Unlike traditional feature selection, INFUSE builds composite \"cohort\" features\n",
        "    centered around diverse seed features, fusing neighboring features using\n",
        "    hybrid weights (similarity, F-score, JSD penalty), regularized via a feature graph,\n",
        "    and filtered by bootstrap AUC-ROC stability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 n_bootstrap=100, stability_thresh=0.5, verbose=True,\n",
        "                 max_features=1000, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates for diversity.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap AUC-ROC for a cohort to be retained.\n",
        "            Cohorts with mean AUC < threshold are discarded.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.verbose = verbose\n",
        "        self.max_features = max_features\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Fitted transformer.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit INFUSE and return the transformed data matrix of stable cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            Transformed data with only stable cohort features.\n",
        "        \"\"\"\n",
        "        # Validate input\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # Store feature names\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Handle missing values\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_medians)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filter features by F-score\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Step 1: Seed Selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Step 2: Diversity Filtering via JSD (Softmax-normalized profiles)\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Step 3: Compute similarity matrix (features Ã— seeds)\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Step 4: Hybrid weighting (similarity + F-score - JSD penalty)\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Step 5: Graph regularization (k-NN on feature space)\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Step 6: Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Step 7: Final filtering by bootstrap AUC-ROC stability\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Save fitted attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)  # Softmax across samples per feature\n",
        "\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)  # Non-negative\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"Evaluate stability via bootstrap AUC-ROC; keep only cohorts above threshold.\"\"\"\n",
        "        if Z.shape[1] == 0:\n",
        "            return Z, [], []\n",
        "\n",
        "        stabilities = []\n",
        "        rng = self.random_state  # For consistent bootstrapping\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            auc_vals = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000))\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    auc_vals.append(0.5)\n",
        "                    continue\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "                    auc = roc_auc_score(yb, proba)\n",
        "                    auc_vals.append(auc if np.isfinite(auc) else 0.5)\n",
        "                except Exception:\n",
        "                    auc_vals.append(0.5)\n",
        "            S_j = np.mean(auc_vals) if auc_vals else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # Keep cohorts that meet stability threshold\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept:\n",
        "            # Fallback: Keep the single most stable cohort, if any exist\n",
        "            if stabilities:\n",
        "                best_idx = int(np.argmax(stabilities))\n",
        "                kept = [best_idx]\n",
        "                if self.verbose:\n",
        "                    print(f\"âš ï¸  No cohorts met stability_thresh={self.stability_thresh}. \"\n",
        "                          f\"Retaining best single cohort (ID={best_idx}, AUC={stabilities[best_idx]:.3f}).\")\n",
        "            else:\n",
        "                kept = []\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            X = X[:, [self.feature_names_in_.index(name) for name in self.feature_names_in_]]\n",
        "\n",
        "        X = self.scaler_.transform(X)\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        if Z_fused.size > 0 and self.kept_indices_:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'is_fitted_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "us1pkpvxNPbE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing (Revised for Robustness & ICML Readiness) ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "import warnings\n",
        "\n",
        "# Set random state for reproducibility\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "# Optional: Use a time-thresholded survival label instead\n",
        "# Requires: days_to_death, days_to_last_followup, vital_status\n",
        "# See suggestion below.\n",
        "\n",
        "# === 1. Load Data ===\n",
        "print(\"ðŸ“¥ Loading data...\")\n",
        "\n",
        "# Load expression: genes Ã— samples â†’ transpose to samples Ã— genes\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix: {X_df.shape}\")\n",
        "\n",
        "# Load clinical data\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data: {y_df_raw.shape}\")\n",
        "\n",
        "# === 2. Standardize Sample IDs (TCGA 15-char barcode) ===\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "\n",
        "# Drop rows with invalid sample IDs\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "\n",
        "# Set index and deduplicate\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# === 3. Find Common Samples ===\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# === 4. Handle Labels: Clean & Validate ===\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found in clinical data.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "\n",
        "# Filter out invalid/unknown labels\n",
        "valid_classes = {'Alive', 'Dead'}  # Adjust based on actual data\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {y_raw[~mask_valid].unique()}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "# Encode\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_raw)\n",
        "print(f\"Classes: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Final label vector\n",
        "y = y_encoded\n",
        "\n",
        "# === 5. Handle Expression Data: NaN/Inf ===\n",
        "print(\"\\n--- Handling Expression Data ---\")\n",
        "initial_nan = np.isnan(X_df).sum().sum()\n",
        "initial_inf = np.isinf(X_df).sum().sum()\n",
        "print(f\"Initial: NaN={initial_nan}, Inf={initial_inf}\")\n",
        "\n",
        "# Replace Inf with NaN\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute with median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# Final check\n",
        "if np.isnan(X_imputed).any() or np.isinf(X_imputed).any():\n",
        "    raise ValueError(\"âŒ NaN or Inf values remain after imputation!\")\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "print(f\"âœ… Data scaled. Final shape: {X_scaled.shape}\")\n",
        "\n",
        "# Preserve feature names\n",
        "feature_names = X_df.columns.tolist()\n",
        "print(f\"First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# === 6. Final Output ===\n",
        "X = X_scaled\n",
        "y = y\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape}, y: {y.shape}\")\n",
        "print(f\"   Classes: {le.classes_.tolist()}\")\n",
        "\n",
        "# Optional: Save preprocessing objects for later use\n",
        "# joblib.dump(imputer, 'imputer.pkl')\n",
        "# joblib.dump(scaler, 'scaler.pkl')\n",
        "# joblib.dump(le, 'label_encoder.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGDR3BIhNPgj",
        "outputId": "70fe75e9-c0a3-401f-8442-f767a24a2578"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading data...\n",
            "Expression matrix: (1218, 20530)\n",
            "Clinical data: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Expression Data ---\n",
            "Initial: NaN=0, Inf=0\n",
            "âœ… Median imputation applied.\n",
            "âœ… Data scaled. Final shape: (1215, 20530)\n",
            "First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20530), y: (1215,)\n",
            "   Classes: ['Alive', 'Dead']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" RUNNING INFUSE - FEATURE CONSTRUCTION & STABILITY FILTERING \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ensure you're passing RAW, IMPUTED, but UNSCALED data\n",
        "# If your X is already scaled, undo it or restructure preprocessing\n",
        "# For now, assuming X_raw_imputed is available\n",
        "\n",
        "# INFUSE should handle its own scaling\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    jsd_threshold=0.35,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    stability_thresh=0.5,        # âœ… Keep â‰¥0.5; justify if lower\n",
        "    #final_k=4,                   # âœ… Re-enable this fallback\n",
        "    n_bootstrap=100,\n",
        "    max_features=1000,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit and transform\n",
        "Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "\n",
        "print(f\"\\nâœ… INFUSE completed. Final cohort matrix shape: {Z_final.shape}\")\n",
        "\n",
        "# Check for zero cohorts\n",
        "if Z_final.shape[1] == 0:\n",
        "    print(\"âŒ WARNING: No stable cohorts were selected. \"\n",
        "          \"Consider reducing jsd_threshold, beta, or checking class balance.\")\n",
        "else:\n",
        "    print(\"\\nðŸ“‹ INFUSE Cohort Summary:\")\n",
        "    summary = infuse.get_cohort_summary()\n",
        "    print(summary)\n",
        "\n",
        "    print(f\"\\nðŸ“Š Detailed Analysis:\")\n",
        "    print(f\"Total cohorts formed: {len(infuse.cohort_members_)}\")\n",
        "    print(f\"Number of seeds selected: {len(infuse.seeds_)}\")\n",
        "    print(f\"Final output cohorts (kept): {len(infuse.kept_indices_)}\")\n",
        "\n",
        "    print(\"\\nðŸ“‹ INFUSE Detailed Description:\")\n",
        "    infuse.describe_cohorts(top_n=10)\n",
        "\n",
        "    # Optional: Plot stability distribution\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.hist(infuse.stabilities_, bins=10, alpha=0.7, color='skyblue')\n",
        "    plt.axvline(0.5, color='red', linestyle='--', label='Random Guessing (AUC=0.5)')\n",
        "    plt.axvline(infuse.stability_thresh, color='green', linestyle='-', label=f'Threshold ({infuse.stability_thresh})')\n",
        "    plt.xlabel('Bootstrap AUC-ROC (Stability)')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Distribution of Cohort Stability Scores')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y_PHBif-NP04",
        "outputId": "269a749b-cf64-46ed-cd73-219198eaff17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " RUNNING INFUSE - FEATURE CONSTRUCTION & STABILITY FILTERING \n",
            "============================================================\n",
            "ðŸ” Pre-filtering 20530 â†’ 1000 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [  144   283   284   297   321   365   565   732   824   825   839  1077\n",
            "  1100  1188  1255  1256  1259  1338  1363  1367  1399  1425  1430  1461\n",
            "  1619  1655  1743  1766  1891  1993  1994  2003  2031  2032  2224  2225\n",
            "  2231  2236  2248  2476  2691  2693  2698  2699  2733  2889  2903  3039\n",
            "  3048  3049  3076  3079  3273  3284  3288  3425  3463  3895  3994  4036\n",
            "  4050  4051  4052  4135  4933  5009  5033  5242  5299  5371  5418  5439\n",
            "  5606  5607  5609  5648  5755  6030  6049  6051  6118  6125  6147  6323\n",
            "  6324  6825  6852  6855  6856  7207  7218  7357  7403  7420  7421  7440\n",
            "  7602  7800  7857  7858  8000  8025  8107  8565  9029  9200  9305  9485\n",
            "  9621  9625  9666  9755 10262 10315 10458 10464 10502 10527 10528 10585\n",
            " 10605 10608 10668 10690 10958 10959 10962 10963 10964 10965 10966 10996\n",
            " 10999 11124 11125 11192 11372 11776 11905 12140 12144 12231 12585 12593\n",
            " 12628 12680 12709 12752 12820 12822 12829 13030 13032 13108 13189 13236\n",
            " 13297 13303 13304 13307 13322 13472 13608 13629 13667 13668 13746 13862\n",
            " 13866 13882 13905 13908 13909 13911 13912 13918 13963 13989 13996 13997\n",
            " 14006 14029 14149 14490 14607 14618 14639 14765 15189 15192 15202 15205\n",
            " 15209 15237 15259 15304 15328 15350 15460 15481 15538 15654 15887 15916\n",
            " 15938 15940 16160 16198 16241 16315 16324 16539 16585 16614 16615 16617\n",
            " 16618 16623 16658 16688 16774 16898 16906 16914 16980 17079 17127 17193\n",
            " 17210 17220 17402 17406 17410 17411 17412 17502 17679 17751 17921 17979\n",
            " 18118 18195 18224 18225 18486 18822 18882 18884 18902 18960 19154 19160\n",
            " 19257 19315 19330 19373 19446 19451 19478 19788 19805 19827 19902 19961\n",
            " 20018 20059 20112 20116 20120 20152 20238 20244 20245 20246 20316 20319\n",
            " 20327 20410] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "\n",
            "âœ… INFUSE completed. Final cohort matrix shape: (1215, 8)\n",
            "\n",
            "ðŸ“‹ INFUSE Cohort Summary:\n",
            "   cohort_id  seed_gene  num_members  \\\n",
            "0          0      KLF10            6   \n",
            "1          1       APOB            6   \n",
            "2          2       ADH4            6   \n",
            "3          3       UBTF            6   \n",
            "4          4      CRHR2            6   \n",
            "5          5  LOC729467            6   \n",
            "6          6     CLEC4M            6   \n",
            "7          7      SAMD1            6   \n",
            "\n",
            "                                        member_genes  stability  \n",
            "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.590921  \n",
            "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.582742  \n",
            "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.586721  \n",
            "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.590910  \n",
            "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.583972  \n",
            "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.594099  \n",
            "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.593432  \n",
            "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.591618  \n",
            "\n",
            "ðŸ“Š Detailed Analysis:\n",
            "Total cohorts formed: 8\n",
            "Number of seeds selected: 8\n",
            "Final output cohorts (kept): 8\n",
            "\n",
            "ðŸ“‹ INFUSE Detailed Description:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.591\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10 \n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.583\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB \n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.587\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4 \n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.591\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF \n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.584\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2 \n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.594\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467 \n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.593\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M \n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.592\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAGJCAYAAACZ7rtNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaERJREFUeJzt3XdUVMffBvBnl7I0qVKVAIoFLIgdSKwoEqMhxURjT9QUjLFEY0tsiaZYY40/a2LXqClWRIm9ix1iA6PSLFTpO+8fvqyuu0tzl2Xx+Zyz59ydO3dm7p1d+HKZOyMRQggQERERERkgqb4bQERERERUXgxmiYiIiMhgMZglIiIiIoPFYJaIiIiIDBaDWSIiIiIyWAxmiYiIiMhgMZglIiIiIoPFYJaIiIiIDBaDWSIiIiIyWAxmiSqZyZMnQyKRVEhd7dq1Q7t27RTvo6KiIJFIsGXLlgqpf8CAAfD09KyQusorMzMTgwYNgouLCyQSCYYPH16h9a9atQoSiQSnT5+u0HorI4lEgqFDh5aYr+iaxcXFKdKe/6zHxcVBIpFg1apV2m8oEVUoBrNEOlT0S7XoZWZmBjc3N4SEhODnn39GRkaGVuq5d+8eJk+ejOjoaK2Up02VuW2lMX36dKxatQqffvopfvvtN/Tt27fY/IWFhVi5ciXatWsHe3t7yGQyeHp6YuDAgQYRkC5atKhMAV5mZiYmTZqEhg0bwtLSEg4ODmjSpAm++OIL3Lt3T5Fv586dmDx5svYbrEW6amNeXh7mzZsHf39/WFtbw9bWFg0aNMCQIUMQExOj9fqIXjbG+m4A0ctg6tSp8PLyQn5+PhITExEVFYXhw4dj9uzZ+PPPP9G4cWNF3okTJ2Ls2LFlKv/evXuYMmUKPD090aRJk1Ift3fv3jLVUx7Fte1///sf5HK5ztvwIvbv34/WrVtj0qRJJebNzs7G22+/jd27d6NNmzYYP3487O3tERcXh02bNmH16tW4ffs2atasWQEtL59FixahevXqGDBgQIl58/Pz0aZNG8TExKB///74/PPPkZmZicuXL2PdunV466234ObmBuBJoLhw4cIKCWj79u2Lnj17QiaTaczj4eGB7OxsmJiYKNJ01cZ33nkHu3btQq9evTB48GDk5+cjJiYGf//9NwIDA1G/fn2t1kf0smEwS1QBQkND0bx5c8X7cePGYf/+/XjjjTfQvXt3XL16Febm5gAAY2NjGBvr9qv5+PFjWFhYwNTUVKf1lOTZQKKySk5Ohq+vb6nyjh49Grt378acOXNUhiNMmjQJc+bM0UELtaPoM1EW27dvx7lz57B27Vp88MEHSvtycnKQl5enzSaWmpGREYyMjIrNU/SfEl07deoU/v77b3z33XcYP3680r4FCxYgNTVV520okpOTA1NTU0il/KcsVS38RBPpSYcOHfD1118jPj4ea9asUaSrGzMbERGBV199Fba2trCyskK9evUUvxijoqLQokULAMDAgQMVQxqK/lXcrl07NGzYEGfOnEGbNm1gYWGhOPb5cYRFCgsLMX78eLi4uMDS0hLdu3fHf//9p5TH09NT7d27Z8ssqW3qxsxmZWVh1KhRcHd3h0wmQ7169TBz5kwIIZTyFY2f3L59Oxo2bAiZTIYGDRpg9+7d6i/4c5KTk/HRRx/B2dkZZmZm8PPzw+rVqxX7i8YP37p1Czt27FC0/dlxmM+6c+cOfvnlF3Tq1EntuFojIyN8+eWXSndlz507h9DQUFhbW8PKygodO3bE8ePH1Zafm5uLkSNHwtHREZaWlnjrrbeQkpKikm/RokVo0KABZDIZ3NzcEB4erhIwafpMeHp64vLly/jnn38U56vu81Hkxo0bAICgoCCVfWZmZrC2tgbwpJ8XLlwIAErDborMnDkTgYGBcHBwgLm5OZo1a1bsuO21a9eiXr16MDMzQ7NmzXDw4EGl/erGzD7v+TGzmtoohICnpyfefPNNlTJycnJgY2ODjz/+WGM9xV0jIyMjODg4KKXdvXsXH330Edzc3CCTyeDl5YVPP/1U6Q+DmzdvokePHrC3t4eFhQVat26NHTt2KJVT9PndsGEDJk6ciBo1asDCwgLp6ekAgBMnTqBLly6wsbGBhYUF2rZtiyNHjiiVkZGRgeHDh8PT0xMymQxOTk7o1KkTzp49q/F8ifSBd2aJ9Khv374YP3489u7di8GDB6vNc/nyZbzxxhto3Lgxpk6dCplMhuvXryt+8fj4+GDq1Kn45ptvMGTIELz22msAgMDAQEUZDx48QGhoKHr27Ik+ffrA2dm52HZ99913kEgk+Oqrr5CcnIy5c+ciODgY0dHRijvIpVGatj1LCIHu3bvjwIED+Oijj9CkSRPs2bMHo0ePxt27d1XubB4+fBhbt27FZ599hmrVquHnn3/GO++8g9u3b6sECc/Kzs5Gu3btcP36dQwdOhReXl7YvHkzBgwYgNTUVHzxxRfw8fHBb7/9hhEjRqBmzZoYNWoUAMDR0VFtmbt27UJBQUGJY2qLXL58Ga+99hqsra0xZswYmJiY4JdffkG7du3wzz//oFWrVkr5P//8c9jZ2WHSpEmIi4vD3LlzMXToUGzcuFGRZ/LkyZgyZQqCg4Px6aefIjY2FosXL8apU6dw5MgRpTvh6j4T7dq1w+effw4rKytMmDABAIr9rHh4eAAAfv31V0ycOFHjg4sff/wx7t27h4iICPz2228q++fNm4fu3bujd+/eyMvLw4YNG9CjRw/8/fff6Nq1q1Lef/75Bxs3bsSwYcMgk8mwaNEidOnSBSdPnkTDhg1LuOqaaWqjRCJBnz598OOPP+Lhw4ewt7dX7Pvrr7+Qnp6OPn36aCy36BqtXbsWQUFBxf7X5d69e2jZsiVSU1MxZMgQ1K9fH3fv3sWWLVvw+PFjmJqaIikpCYGBgXj8+DGGDRsGBwcHrF69Gt27d8eWLVvw1ltvKZU5bdo0mJqa4ssvv0Rubi5MTU2xf/9+hIaGolmzZpg0aRKkUilWrlyJDh064NChQ2jZsiUA4JNPPsGWLVswdOhQ+Pr64sGDBzh8+DCuXr2Kpk2blus6E+mEICKdWblypQAgTp06pTGPjY2N8Pf3V7yfNGmSeParOWfOHAFApKSkaCzj1KlTAoBYuXKlyr62bdsKAGLJkiVq97Vt21bx/sCBAwKAqFGjhkhPT1ekb9q0SQAQ8+bNU6R5eHiI/v37l1hmcW3r37+/8PDwULzfvn27ACC+/fZbpXzvvvuukEgk4vr164o0AMLU1FQp7fz58wKAmD9/vkpdz5o7d64AINasWaNIy8vLEwEBAcLKykrp3D08PETXrl2LLU8IIUaMGCEAiHPnzpWYVwghwsLChKmpqbhx44Yi7d69e6JatWqiTZs2irSiz1BwcLCQy+VK9RkZGYnU1FQhhBDJycnC1NRUdO7cWRQWFiryLViwQAAQK1asUKQV95lo0KCBUv8V5/Hjx6JevXoCgPDw8BADBgwQy5cvF0lJSSp5w8PDhaZfOY8fP1Z6n5eXJxo2bCg6dOiglA5AABCnT59WpMXHxwszMzPx1ltvKdKKrtmtW7cUac9/Lm/duqXyudTUxtjYWAFALF68WCm9e/fuwtPTU6lfnieXyxXX29nZWfTq1UssXLhQxMfHq+Tt16+fkEqlan9eFNUxfPhwAUAcOnRIsS8jI0N4eXkJT09PRd8XfZdr1aqldH3lcrmoU6eOCAkJUWr348ePhZeXl+jUqZMizcbGRoSHh2s8N6LKgsMMiPTMysqq2FkNbG1tAQB//PFHuR+WkslkGDhwYKnz9+vXD9WqVVO8f/fdd+Hq6oqdO3eWq/7S2rlzJ4yMjDBs2DCl9FGjRkEIgV27dimlBwcHo3bt2or3jRs3hrW1NW7evFliPS4uLujVq5cizcTEBMOGDUNmZib++eefMre96N+3z143TQoLC7F3716EhYWhVq1ainRXV1d88MEHOHz4sKK8IkOGDFG68/naa6+hsLAQ8fHxAIB9+/YhLy8Pw4cPVxoTOXjwYFhbW6v8G7qsnwl1zM3NceLECYwePRrAk3/vf/TRR3B1dcXnn3+O3NzcUpdT5NGjR0hLS8Nrr72m9t/ZAQEBaNasmeL9K6+8gjfffBN79uxBYWHhC52PJnXr1kWrVq2wdu1aRdrDhw+xa9cu9O7du9ip9CQSCfbs2YNvv/0WdnZ2WL9+PcLDw+Hh4YH3339fMQRELpdj+/bt6Natm9L4+mfLAZ58dlu2bIlXX31Vsc/KygpDhgxBXFwcrly5onRc//79la5vdHQ0rl27hg8++AAPHjzA/fv3cf/+fWRlZaFjx444ePCg4ueMra0tTpw4oTQrBVFlxGCWSM8yMzOLDYDef/99BAUFYdCgQXB2dkbPnj2xadOmMgW2NWrUKNPDXnXq1FF6L5FI4O3tXewYRG2Ij4+Hm5ubyvXw8fFR7H/WK6+8olKGnZ0dHj16VGI9derUUXkQRlM9pVE0PrQ0062lpKTg8ePHqFevnso+Hx8fyOVylTHKz5+rnZ0dACjOtajNz5dpamqKWrVqqZxTWT8TmtjY2ODHH39EXFwc4uLisHz5ctSrVw8LFizAtGnTSlXG33//jdatW8PMzAz29vZwdHTE4sWLkZaWppL3+c8m8CTYfPz4sdoxxNrSr18/HDlyRHEdN2/ejPz8/FINK5HJZJgwYQKuXr2Ke/fuYf369WjdujU2bdqkmDc3JSUF6enpJQ6ViI+P1/i5Kdr/LC8vL6X3165dA/AkyHV0dFR6LVu2DLm5uYrr/uOPP+LSpUtwd3dHy5YtMXny5BL/UCTSBwazRHp0584dpKWlwdvbW2Mec3NzHDx4EPv27UPfvn1x4cIFvP/+++jUqVOp70SVZZxraWm6G6Wru2PqaHpiXTz3sFhFKJpe6eLFizopX9vnqovPhIeHBz788EMcOXIEtra2SncyNTl06BC6d+8OMzMzLFq0CDt37kRERAQ++OADvfSjJj179oSJiYninNasWYPmzZurDSyL4+rqip49e+LgwYOoU6cONm3ahIKCAl00GYBqPxf9EfzTTz8hIiJC7cvKygoA8N577+HmzZuYP38+3Nzc8NNPP6FBgwYq/yEh0jcGs0R6VPSgSUhISLH5pFIpOnbsiNmzZ+PKlSv47rvvsH//fhw4cACA5sCyvIru3hQRQuD69etKMw/Y2dmpnVbo+TtDZWmbh4cH7t27p3J3s2hi+aKHaV6Uh4cHrl27pnJ3+0XqCQ0NhZGRkdLMFJo4OjrCwsICsbGxKvtiYmIglUrh7u5epvqL2vx8mXl5ebh161apz0kbnyU7OzvUrl0bCQkJJZb7+++/w8zMDHv27MGHH36I0NBQBAcHayz7+c8mAPz777+wsLDQ+HBeaRV37vb29ujatSvWrl2L+Ph4HDlypNQP+6ljYmKCxo0bIz8/H/fv34ejoyOsra1x6dKlYo/z8PDQ+Lkp2l+comE51tbWCA4OVvt69kFBV1dXfPbZZ9i+fTtu3boFBwcHfPfdd2U9XSKdYjBLpCf79+/HtGnT4OXlhd69e2vM9/DhQ5W0osUHisYkWlpaAoDW5qz89ddflQLKLVu2ICEhAaGhoYq02rVr4/jx40pTBv39998q/x4vS9tef/11FBYWYsGCBUrpc+bMgUQiUar/Rbz++utITExUmgmgoKAA8+fPh5WVFdq2bVvmMt3d3TF48GDs3bsX8+fPV9kvl8sxa9Ys3LlzB0ZGRujcuTP++OMPpaEbSUlJWLduHV599VXFsIXSCg4OhqmpKX7++WelO5rLly9HWlqayqwAmlhaWpb6c3T+/Hncv39fJT0+Ph5XrlxRumup6XNgZGQEiUSidEc/Li4O27dvV1vnsWPHlMbS/vfff/jjjz/QuXPnEueWLUlJn9W+ffviypUrGD16NIyMjNCzZ88Sy7x27Rpu376tkp6amopjx47Bzs4Ojo6OkEqlCAsLw19//aV2pbiiPn399ddx8uRJHDt2TLEvKysLS5cuhaenZ4lzIjdr1gy1a9fGzJkzkZmZqbK/aKhGYWGhyjAPJycnuLm5lXosNFFF4dRcRBVg165diImJQUFBAZKSkrB//35ERETAw8MDf/75Z7GTt0+dOhUHDx5E165d4eHhgeTkZCxatAg1a9ZUPARSu3Zt2NraYsmSJahWrRosLS3RqlUrlfFypWVvb49XX30VAwcORFJSEubOnQtvb2+l6cMGDRqELVu2oEuXLnjvvfdw48YNrFmzRumBrLK2rVu3bmjfvj0mTJiAuLg4+Pn5Ye/evfjjjz8wfPhwlbLLa8iQIfjll18wYMAAnDlzBp6entiyZQuOHDmCuXPnluohLnVmzZqFGzduYNiwYdi6dSveeOMN2NnZ4fbt29i8eTNiYmIUAdC3336rmD/4s88+g7GxMX755Rfk5ubixx9/LHPdjo6OGDduHKZMmYIuXbqge/fuiI2NxaJFi9CiRYtip496VrNmzbB48WJ8++238Pb2hpOTEzp06KA2b0REBCZNmoTu3bujdevWsLKyws2bN7FixQrk5uYqraRV9NDWsGHDEBISoggGu3btitmzZ6NLly744IMPkJycjIULF8Lb2xsXLlxQqbNhw4YICQlRmpoLAKZMmVLGK6b+3NW1sUjXrl3h4OCAzZs3IzQ0FE5OTiWWef78eXzwwQcIDQ3Fa6+9Bnt7e9y9exerV6/GvXv3MHfuXEUQPn36dOzduxdt27bFkCFD4OPjg4SEBGzevBmHDx+Gra0txo4di/Xr1yM0NBTDhg2Dvb09Vq9ejVu3buH3338vcUEEqVSKZcuWITQ0FA0aNMDAgQNRo0YN3L17FwcOHIC1tTX++usvZGRkoGbNmnj33Xfh5+cHKysr7Nu3D6dOncKsWbNe4CoT6YAeZ1IgqvKKpggqepmamgoXFxfRqVMnMW/ePKUpoIo8PzVXZGSkePPNN4Wbm5swNTUVbm5uolevXuLff/9VOu6PP/4Qvr6+wtjYWGnKobZt24oGDRqobZ+mqbnWr18vxo0bJ5ycnIS5ubno2rWr2qmEZs2aJWrUqCFkMpkICgoSp0+fVimzuLY9PzWXEE+mGRoxYoRwc3MTJiYmok6dOuKnn35Smf4IgNppgzRNGfa8pKQkMXDgQFG9enVhamoqGjVqpHb6sNJOzVWkoKBALFu2TLz22mvCxsZGmJiYCA8PDzFw4ECVabvOnj0rQkJChJWVlbCwsBDt27cXR48eVcqjaXq3or46cOCAUvqCBQtE/fr1hYmJiXB2dhaffvqpePTokVKe4j4TiYmJomvXrqJatWoCQLHTdN28eVN88803onXr1sLJyUkYGxsLR0dH0bVrV7F//36V6/L5558LR0dHIZFIlD7jy5cvF3Xq1BEymUzUr19frFy5UuV7IMTTPl+zZo0iv7+/v8o1KO/UXMW1schnn30mAIh169ZpvC7PSkpKEt9//71o27atcHV1FcbGxsLOzk506NBBbNmyRSV/fHy86Nevn3B0dBQymUzUqlVLhIeHi9zcXEWeGzduiHfffVfY2toKMzMz0bJlS/H3338rlVP0+di8ebPadp07d068/fbbwsHBQchkMuHh4SHee+89ERkZKYQQIjc3V4wePVr4+fmJatWqCUtLS+Hn5ycWLVpUqvMmqkgSISrRCHsiIqJKbMSIEVi+fDkSExPLvPwvEekGx8wSERGVQk5ODtasWYN33nmHgSxRJcIxs0RERMVITk7Gvn37sGXLFjx48ABffPGFvptERM9gMEtERFSMK1euoHfv3nBycsLPP/+smE2EiCoHjpklIiIiIoPFMbNEREREZLAYzBIRERGRwXrpxszK5XLcu3cP1apV0/oSoERERET04oQQyMjIgJubW4mLgbx0wey9e/fKvOY5EREREVW8//77DzVr1iw2z0sXzBYtU/nff/+Vee3zssrKy4LbLDcAwJ0Rd1DNrHxLZFLlJZfLkZKSolhbnaoW9m/Vxv6t2ti/hi09PR3u7u6lWl78pQtmi4YWWFtb6zyYNUrNBcyebFubGKOajuujiieXy5GTkwNra2v+sKyC2L9VG/u3amP/Vg2lGRLK3tWlZ2c94wxoRERERFrHYJaIiIiIDBaDWSIiIiIyWAxmiYiIiMhgMZglIiIiIoPFYJaIiIiIDBaDWV16djoJrjZGREREpHV6DWYXL16Mxo0bK+Z8DQgIwK5du4o9ZvPmzahfvz7MzMzQqFEj7Ny5s4JaWw4WFk+3zS005yMiIiKictFrMFuzZk18//33OHPmDE6fPo0OHTrgzTffxOXLl9XmP3r0KHr16oWPPvoI586dQ1hYGMLCwnDp0qUKbjkRERERVQZ6DWa7deuG119/HXXq1EHdunXx3XffwcrKCsePH1ebf968eejSpQtGjx4NHx8fTJs2DU2bNsWCBQsquOVEREREVBlUmuVsCwsLsXnzZmRlZSEgIEBtnmPHjmHkyJFKaSEhIdi+fbvGcnNzc5Gbm6t4n56eDuDJMndyufzFG14MeVbW0+3HWZCbWuq0Pqp4crkcQgidf5ZIP9i/VRv7t2pj/xq2svSb3oPZixcvIiAgADk5ObCyssK2bdvg6+urNm9iYiKcnZ2V0pydnZGYmKix/BkzZmDKlCkq6SkpKcjJyXmxxpfgcdp9xfb95GRk5+m0OtIDuVyOtLQ0CCG49ncVxP6t2ti/VRv7FzickKU2/VXXyn9zLSMjo9R59R7M1qtXD9HR0UhLS8OWLVvQv39//PPPPxoD2rIaN26c0t3c9PR0uLu7w9HREdbW1lqpQ5Ms06fb1atXRzV7J53WRxVPLpdDIpHA0dHxpf1hWZWxf6s29m/Vxv4FRGaa2nQnJ5sKbknZmZmZlTqv3oNZU1NTeHt7AwCaNWuGU6dOYd68efjll19U8rq4uCApKUkpLSkpCS4uLhrLl8lkkMlkKulSqVTnH26p5Gn5FVEf6YdEImH/VmHs36qN/Vu1vfT9K1F/3oZwPcrSxkp3NnK5XGmM67MCAgIQGRmplBYREaFxjC0RERERVW16vTM7btw4hIaG4pVXXkFGRgbWrVuHqKgo7NmzBwDQr18/1KhRAzNmzAAAfPHFF2jbti1mzZqFrl27YsOGDTh9+jSWLl2qz9MgIiIiIj3RazCbnJyMfv36ISEhATY2NmjcuDH27NmDTp06AQBu376tdJs5MDAQ69atw8SJEzF+/HjUqVMH27dvR8OGDfV1CkRERESkR3oNZpcvX17s/qioKJW0Hj16oEePHjpqEREREREZkko3ZrZKsXxm6guLyj8NBhEREZGhYTBLRERERAaLwSwRERERGSwGs7qUna1+m4iIiIi0gsGsLj27rrDg2tBERERE2sZgloiIiIgMFoNZIiIiIjJYDGaJiIiIyGAxmCUiIiIig8VgloiIiIgMFoNZIiIiIjJYDGZ1icvZEhEREekUg1kiIiIiMlgMZomIiIjIYDGY1aWcHPXbRERERKQVDGZ1qbDw6ba8UHM+IiIiIioXBrNEREREZLAYzBIRERGRwWIwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwq0tczpaIiIhIpxjMEhEREZHBYjBLRERERAaLwawucTlbIiIiIp1iMKtLXM6WiIiISKcYzBIRERGRwWIwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwS0REREQGi8GsLllYPN02t9Ccj4iIiIjKhcGsLkkk6reJiIiISCsYzBIRERGRwWIwq0u5ueq3iYiIiEgrGMzqUkHB0+3CAs35iIiIiKhc9BrMzpgxAy1atEC1atXg5OSEsLAwxMbGFnvMqlWrIJFIlF5mZmYV1GIiIiIiqkz0Gsz+888/CA8Px/HjxxEREYH8/Hx07twZWVlZxR5nbW2NhIQExSs+Pr6CWkxERERElYmxPivfvXu30vtVq1bByckJZ86cQZs2bTQeJ5FI4OLiouvmEREREVElp9dg9nlpaWkAAHt7+2LzZWZmwsPDA3K5HE2bNsX06dPRoEEDtXlzc3OR+8zDV+np6QAAuVwOuVyupZarJxdPy6+I+qjiyeVyCCHYt1UU+7dqY/9WbexfAEL9uRvCNSlLGytNMCuXyzF8+HAEBQWhYcOGGvPVq1cPK1asQOPGjZGWloaZM2ciMDAQly9fRs2aNVXyz5gxA1OmTFFJT0lJQU5OjlbP4XmP0+4rtu/fv4/sAj5vV9XI5XKkpaVBCAGplP1b1bB/qzb2b9XG/gUkGeqHbSYnV/4ZljIyMkqdVyKEEDpsS6l9+umn2LVrFw4fPqw2KNUkPz8fPj4+6NWrF6ZNm6ayX92dWXd3dzx69AjW1tZaabsmWanJsJ7vCgBIDb+LavYcGlHVyOVypKSkwNHR8aX9YVmVsX+rNvZv1cb+BX6/maY2/Z1aNhXckrJLT0+HnZ0d0tLSSozXKsWd2aFDh+Lvv//GwYMHyxTIAoCJiQn8/f1x/fp1tftlMhlkMplKulQq1fmHW2pppbT9sn6ZqjqJRFIhnyfSD/Zv1cb+rdpe+v6VqD9vQ7geZWmjXs9GCIGhQ4di27Zt2L9/P7y8vMpcRmFhIS5evAhXV1cdtPAFcTlbIiIiIp3S653Z8PBwrFu3Dn/88QeqVauGxMREAICNjQ3Mzc0BAP369UONGjUwY8YMAMDUqVPRunVreHt7IzU1FT/99BPi4+MxaNAgvZ0HEREREemHXoPZxYsXAwDatWunlL5y5UoMGDAAAHD79m2lW82PHj3C4MGDkZiYCDs7OzRr1gxHjx6Fr69vRTW79J5fztasmv7aQkRERFQF6TWYLc2zZ1FRUUrv58yZgzlz5uioRVrG5WyJiIiIdKryjwAmIiIiItKAwSwRERERGSwGs0RERERksBjMEhEREZHBYjBLRERERAaLwSwRERERGSwGs7r0/ws/AADMzDXnIyIiIqJyYTCrS8+uK2wA6yATERERGRpGWERERERksBjM6lJenvptIiIiItIKBrO6lJ//dLsgX3M+IiIiIioXBrNEREREZLAYzBIRERGRwWIwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwq0tczpaIiIhIpxjM6hKXsyUiIiLSKUZYRERERGSwGMzqEpezJSIiItIpBrO6xOVsiYiIiHSKwSwRERERGSwGs0RERERksBjMEhEREZHBYjBLRERERAaLwSwRERERGSwGs0RERERksBjM6pKZ2dNtmZnmfERERERULgxmdcnISP02EREREWkFg1kiIiIiMlgMZnWJy9kSERER6RSDWV3icrZEREREOsVgloiIiIgMFoNZIiIiIjJYDGaJiIiIyGAxmCUiIiIig8VgloiIiIgMll6D2RkzZqBFixaoVq0anJycEBYWhtjY2BKP27x5M+rXrw8zMzM0atQIO3furIDWEhEREVFlo9dg9p9//kF4eDiOHz+OiIgI5Ofno3PnzsjKytJ4zNGjR9GrVy989NFHOHfuHMLCwhAWFoZLly5VYMtLicvZEhEREemUsT4r3717t9L7VatWwcnJCWfOnEGbNm3UHjNv3jx06dIFo0ePBgBMmzYNERERWLBgAZYsWaLzNpcJl7MlIiIi0im9BrPPS0tLAwDY29trzHPs2DGMHDlSKS0kJATbt29Xmz83Nxe5ubmK9+np6QAAuVwOuVz+gi0u3rPlV0R9VPHkcjmEEOzbKor9W7Wxf6s29i8Aof7cDeGalKWNlSaYlcvlGD58OIKCgtCwYUON+RITE+Hs7KyU5uzsjMTERLX5Z8yYgSlTpqikp6SkICcn58UaXYLHj9Oe1nfvHrKt7HRaH1U8uVyOtLQ0CCEglfJ5yqqG/Vu1sX+rNvYvIMlQP2wzOTlXbToAHE7QPNTzVVfLF25TaWVkZJQ6b6UJZsPDw3Hp0iUcPnxYq+WOGzdO6U5ueno63N3d4ejoCGtra63W9bys1KfbjrY2qGbvpNP6qOLJ5XJIJBI4Ojq+tD8sqzL2b9XG/q3a2L+AyExTm+7kZFPmY0o6TtvMzEr/rFGlCGaHDh2Kv//+GwcPHkTNmjWLzevi4oKkpCSltKSkJLi4uKjNL5PJIJPJVNKlUqnOP9xSydPyK6I+0g+JRML+rcLYv1Ub+7dqe+n7V6L+vIu9HhqOKfE4LStLXXrtXSEEhg4dim3btmH//v3w8vIq8ZiAgABERkYqpUVERCAgIEBXzSQiIiKiSkqvd2bDw8Oxbt06/PHHH6hWrZpi3KuNjQ3Mzc0BAP369UONGjUwY8YMAMAXX3yBtm3bYtasWejatSs2bNiA06dPY+nSpXo7DyIiIiLSD73emV28eDHS0tLQrl07uLq6Kl4bN25U5Ll9+zYSEhIU7wMDA7Fu3TosXboUfn5+2LJlC7Zv317sQ2NEREREVDXp9c6sEKLEPFFRUSppPXr0QI8ePXTQIiIiIiIyJC/piGgiIiIiqgoYzOrSs7MomKrOqEBEREREL4bBrC4ZG6vfJiIiIiKtYDBLRERERAaLwawu5eer3yYiIiIirWAwq0t5eU+38/M05yMiIiKicmEwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwS0REREQGi8EsERERERksBrO6xOVsiYiIiHSKwawucTlbIiIiIp1iMEtEREREBovBrC4VFKjfJiIiIiKtYDCrS7m5T7fzcjXnIyIiIqJyKVcwW6tWLTx48EAlPTU1FbVq1XrhRhERERERlUa5gtm4uDgUFhaqpOfm5uLu3bsv3CgiIiIiotIo0yP2f/75p2J7z549sLGxUbwvLCxEZGQkPD09tdY4IiIiIqLilCmYDQsLAwBIJBL0799faZ+JiQk8PT0xa9YsrTWOiIiIiKg4ZQpm5XI5AMDLywunTp1C9erVddIoIiIiIqLSKNdM/rdu3dJ2O4iIiIiIyqzcy1JFRkYiMjISycnJiju2RVasWPHCDasSTE2fbpuYas5HREREROVSrmB2ypQpmDp1Kpo3bw5XV1dIJBJtt6tqMDFRv01EREREWlGuYHbJkiVYtWoV+vbtq+32EBERERGVWrnmmc3Ly0NgYKC221L1cDlbIiIiIp0qVzA7aNAgrFu3TtttqXq4nC0RERGRTpVrmEFOTg6WLl2Kffv2oXHjxjB5bjzo7NmztdI4IiIiIqLilCuYvXDhApo0aQIAuHTpktI+PgxGRERERBWlXMHsgQMHtN0OIiIiIqIyK9eYWSIiIiKiyqBcd2bbt29f7HCC/fv3l7tBRERERESlVa5gtmi8bJH8/HxER0fj0qVL6N+/vzbaRURERERUonIFs3PmzFGbPnnyZGRmZr5Qg6oULmdLREREpFNaHTPbp08frFixQptFGjYuZ0tERESkU1oNZo8dOwYzMzNtFklEREREpFG5hhm8/fbbSu+FEEhISMDp06fx9ddfa6VhVUJhofptIiIiItKKct2ZtbGxUXrZ29ujXbt22LlzJyZNmlTqcg4ePIhu3brBzc0NEokE27dvLzZ/VFQUJBKJyisxMbE8p6F7OTlPt3NzNOcjIiIionIp153ZlStXaqXyrKws+Pn54cMPP1S521uc2NhYWFtbK947OTlppT1EREREZFjKFcwWOXPmDK5evQoAaNCgAfz9/ct0fGhoKEJDQ8tcr5OTE2xtbct8HBERERFVLeUKZpOTk9GzZ09ERUUpgsrU1FS0b98eGzZsgKOjozbbqKJJkybIzc1Fw4YNMXnyZAQFBWnMm5ubi9zcXMX79PR0AIBcLodcLtdpO+XiafkVUR9VPLlcDiEE+7aKYv9Wbezfqo39C0CoP/dir4mGY0o8TsvKUle5gtnPP/8cGRkZuHz5Mnx8fAAAV65cQf/+/TFs2DCsX7++PMWWyNXVFUuWLEHz5s2Rm5uLZcuWoV27djhx4gSaNm2q9pgZM2ZgypQpKukpKSnIydHtONbHafcV2/fv30d2AVcPrmrkcjnS0tIghIBUyv6tati/VRv7t2pj/wKSjCy16cnJuWrTizumpOO0LSMjo9R5JUIIUdYKbGxssG/fPrRo0UIp/eTJk+jcuTNSU1PLWiQkEgm2bduGsLCwMh3Xtm1bvPLKK/jtt9/U7ld3Z9bd3R2PHj1SGnerC1mpybCe7woASA2/i2r2LjqtjyqeXC5HSkoKHB0dX9ofllUZ+7dqY/9Wbexf4PebaWrT36llU+ZjSjpO29LT02FnZ4e0tLQS47Vy3ZmVy+UwUbMIgImJSYXfzm/ZsiUOHz6scb9MJoNMJlNJl0qlOv9wSyVPy6+I+kg/JBIJ+7cKY/9Wbezfqu2l71+J+vMu9npoOKbE47SsLHWVq1UdOnTAF198gXv37inS7t69ixEjRqBjx47lKbLcoqOj4erqWqF1ltqzAb8xVwAjIiIi0rZy3ZldsGABunfvDk9PT7i7uwMA/vvvPzRs2BBr1qwpdTmZmZm4fv264v2tW7cQHR0Ne3t7vPLKKxg3bhzu3r2LX3/9FQAwd+5ceHl5oUGDBsjJycGyZcuwf/9+7N27tzynoXumpuq3iYiIiEgryhXMuru74+zZs9i3bx9iYmIAAD4+PggODi5TOadPn0b79u0V70eOHAkA6N+/P1atWoWEhATcvn1bsT8vLw+jRo3C3bt3YWFhgcaNG2Pfvn1KZRARERHRy6NMwez+/fsxdOhQHD9+HNbW1ujUqRM6deoEAEhLS0ODBg2wZMkSvPbaa6Uqr127diju+bNVq1YpvR8zZgzGjBlTlibrF5ezJSIiItKpMo2ZnTt3LgYPHqz2qTIbGxt8/PHHmD17ttYaZ/C4nC0RERGRTpUpmD1//jy6dOmicX/nzp1x5syZF24UEREREVFplCmYTUpKUjslVxFjY2OkpKS8cKOIiIiIiEqjTMFsjRo1cOnSJY37L1y4UHmnySIiIiKiKqdMwezrr7+Or7/+Wu0ysNnZ2Zg0aRLeeOMNrTWOiIiIiKg4ZZrNYOLEidi6dSvq1q2LoUOHol69egCAmJgYLFy4EIWFhZgwYYJOGkpERERE9LwyBbPOzs44evQoPv30U4wbN04xrZZEIkFISAgWLlwIZ2dnnTSUiIiIiOh5ZV40wcPDAzt37sSjR49w/fp1CCFQp04d2NnZ6aJ9ho3L2RIRERHpVLlWAAMAOzs7tGjRQpttqXq4nC0RERGRTpXpATAiIiIiosqEwawuyeXqt4mIiIhIKxjM6lJ29tPtnGzN+YiIiIioXBjMEhEREZHBYjBLRERERAaLwSwRERERGSwGs0RERERksBjMEhEREZHBYjBLRERERAaLwawucTlbIiIiIp1iMKtLXM6WiIiISKcYzBIRERGRwWIwq0tczpaIiIhIpxjM6hKXsyUiIiLSKQazRERERGSwGMwSERERkcFiMEtEREREBovBLBEREREZLAazRERERGSwGMwSERERkcFiMKtLxsZPt42MNecjIiIionJhMKtLMpn6bSIiIiLSCgazRERERGSwGMzqkhDqt4mIiIhIKxjM6tLjx0+3sx9rzkdERERE5cJgloiIiIgMFoNZIiIiIjJYDGaJiIiIyGAxmCUiIiIig6XXYPbgwYPo1q0b3NzcIJFIsH379hKPiYqKQtOmTSGTyeDt7Y1Vq1bpvJ1EREREVDnpNZjNysqCn58fFi5cWKr8t27dQteuXdG+fXtER0dj+PDhGDRoEPbs2aPjlhIRERFRZaTXNVZDQ0MRGhpa6vxLliyBl5cXZs2aBQDw8fHB4cOHMWfOHISEhOiqmeXH5WyJiIiIdMqgIqxjx44hODhYKS0kJATDhw/XeExubi5yc3MV79PT0wEAcrkccrlcJ+0sIjcxUdrWdX1U8eRyOYQQ7Nsqiv1btbF/qzb2LwCh/tyLvSYajinxOC0rS10GFcwmJibC2dlZKc3Z2Rnp6enIzs6Gubm5yjEzZszAlClTVNJTUlKQk5Ojs7YCwOP8pwslpKSkIFuWrdP6qOLJ5XKkpaVBCAGplM9TVjXs36qN/Vu1aaN/Dydkleu4V10ty1yepmNehCRDfX3Jyblq04s7pqTjtC0jI6PUeQ0qmC2PcePGYeTIkYr36enpcHd3h6OjI6ytrXVad1ZupmLbsXp1VDPXbX1U8eRyOSQSCRwdHfnLsApi/1Zt7N+qTRv9KzLTynWck5NNmcvTdMyL0FRfcXVVdBs1MTMzK3VegwpmXVxckJSUpJSWlJQEa2trtXdlAUAmk0Emk6mkS6VSnf/wkj5z51eamwOppa1O6yP9kEgkFfJ5Iv1g/1Zt7N+q7YX7V1K+4zTWV0x5OvkMaqiv2Loquo1aqMugvr0BAQGIjIxUSouIiEBAQICeWkRERERE+qTXYDYzMxPR0dGIjo4G8GTqrejoaNy+fRvAkyEC/fr1U+T/5JNPcPPmTYwZMwYxMTFYtGgRNm3ahBEjRuij+URERESkZ3oNZk+fPg1/f3/4+/sDAEaOHAl/f3988803AICEhARFYAsAXl5e2LFjByIiIuDn54dZs2Zh2bJllXNaLiIiIiLSOb2OmW3Xrh2EEBr3q1vdq127djh37pwOW0VEREREhsKgxswSERERET2LwSwRERERGSwGs7pkZPR0W2qkOR8RERERlQuDWV16dsLfMkz+S0RERESlw2CWiIiIiAwWg1kiIiIiMlgMZnUpK+vp9uMszfmIiIiIqFwYzBIRERGRwWIwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwS0REREQGi8GsLnE5WyIiIiKdYjCrS1zOloiIiEinGMwSERERkcFiMEtEREREBovBrC5xOVsiIiIinWIwS0REREQGi8EsERERERksBrNEREREZLAYzBIRERGRwWIwS0REREQGi8EsERERERksBrO6JH3m8kp4qYmIiIi0jRGWLpmbq98mIiIiIq1gMEtEREREBovBLBEREREZLAazusTlbImIiIh0isEsERERERksBrNEREREZLAYzBIRERGRwWIwS0REREQGi8EsERERERksBrNEREREZLAYzOoSl7MlIiIi0ilGWLrE5WyJiIiIdMpY3w0gIu0rLCxEfn6+vpth8ORyOfLz85GTkwOplH/7VzWG3r8mJiYwMjLSdzOI9K5SBLMLFy7ETz/9hMTERPj5+WH+/Plo2bKl2ryrVq3CwIEDldJkMhlycnIqoqlElZoQAomJiUhNTdV3U6oEIQTkcjkyMjIgkUj03RzSsqrQv7a2tnBxcTHY9hNpg96D2Y0bN2LkyJFYsmQJWrVqhblz5yIkJASxsbFwcnJSe4y1tTViY2MV7yvtl/jx46fb2Y8Bs2r6awu9FIoCWScnJ1hYWFTe74aBEEKgoKAAxsbGvJZVkCH3rxACjx8/RnJyMgDA1dVVzy0i0h+9B7OzZ8/G4MGDFXdblyxZgh07dmDFihUYO3as2mMkEglcXFwqspnlI4T6bSIdKCwsVASyDg4O+m5OlWDIwQ6VzND71/z/n8VITk6Gk5MThxzQS0uvwWxeXh7OnDmDcePGKdKkUimCg4Nx7NgxjcdlZmbCw8MDcrkcTZs2xfTp09GgQQO1eXNzc5Gbm6t4n56eDuDJWCm5XK6lM1FPLp6WXxH1UcWTy+WKf1XqW25uLoQQMDc3h+AfT1pTdC15TasmQ+/fou97bm4uzMzM9N2cSkUrP59F+Y7VWGcx5enk94iG+oqtq6LbqIW69BrM3r9/H4WFhXB2dlZKd3Z2RkxMjNpj6tWrhxUrVqBx48ZIS0vDzJkzERgYiMuXL6NmzZoq+WfMmIEpU6aopKekpOh8nO3jtPuK7fv37yO7wPAeMKDiyeVypKWlQQih9wdI8vPzIZfLUVhYiIKCAr22paoQQqCwsBBAJR7OROVWFfq3sLAQcrkcDx48gImJib6bU6lo4+ezJCOrXMclJ+eqTS+uPE3HvAhN9RVXV0W3UZOMjIxS59X7MIOyCggIQEBAgOJ9YGAgfHx88Msvv2DatGkq+ceNG4eRI0cq3qenp8Pd3R2Ojo6wtrbWaVuzTJ9uV69eHdXs1Y8BJsMll8shkUjg6Oio92A2JycHGRkZMDY2hrGxwX21KzUGCVWbIfevsbExpFIpHBwceGf2Odr4+Swy08p1nJOTTZnL03TMi9BUX3F1VXQbNSnL51mvv/GqV68OIyMjJCUlKaUnJSWVekysiYkJ/P39cf36dbX7ZTIZZDKZSrpUKtV58CF9ZqGEiqiP9EMikVSK/pVKpZBIJIoXlZ5EIsG2bdsQFhamlC6EUFzLl/maTp48Gdu3b0d0dLTO68rLy4Ovry9+/fVXBAYG6rSuyt6/V65cQefOnREbGwtLS0u1eYq+75XhZ1Bl9MLXppwLHmmsr5jydNJ/Guortq6KbqMW6tLrJ9/U1BTNmjVDZGSkIk0ulyMyMlLp7mtxCgsLcfHiRT7JSWTABgwYoPilbGJiAi8vL4wZM+almHIvMTERX3zxBby9vWFmZgZnZ2cEBQVh8eLFePzsjCh69OWXXyr9nNalJUuWwMvLS20g+/HHH8PIyAibN29W2TdgwACVP0YAICoqChKJRGm6ury8PPz4449o0qQJbGxs4OjoiKCgIKxcubLc8zM/fPgQvXv3hrW1NWxtbfHRRx8hMzOz2GPatWun9AeoRCLBJ598otjv6+uL1q1bY/bs2eVqE9HLQu//ixw5ciT69++P5s2bo2XLlpg7dy6ysrIUsxv069cPNWrUwIwZMwAAU6dORevWreHt7Y3U1FT89NNPiI+Px6BBg/R5Guo9+5d+Jfyrn6gy6dKliyKYOHPmDPr37w+JRIIffvhB303TmZs3byIoKAi2traYPn06GjVqBJlMhosXL2Lp0qWoUaMGunfvru9mwsrKClZWVjqvRwiBBQsWYOrUqSr7Hj9+jA0bNmDMmDFYsWIFevToUa468vLyEBISgvPnz2Pq1Klo1aoV7O3tceLECcycORP+/v5o0qRJmcvt3bs3EhISEBERgfz8fAwcOBBDhgzBunXrij1u8ODBSudrYWGhtH/gwIEYPHgwxo0bx+FDRBro/X8S77//PmbOnIlvvvkGTZo0QXR0NHbv3q14KOz27dtISEhQ5H/06BEGDx4MHx8fvP7660hPT8fRo0fh6+urr1PQ7NkfSuYWmvMR6VpWlubX83c/i8ubnV26vOUgk8ng4uICd3d3hIWFITg4GBEREYr9Dx48QK9evVCjRg1YWFigUaNGWL9+vVIZ7dq1w7BhwzBmzBjY29vDxcUFkydPVspz7do1tGnTBmZmZvD19VWqo8jFixfRoUMHWFhYwMXFBUOGDFG6y1Z0F3D69OlwdnaGra0tpk6dioKCAowePRr29vaoWbMmVq5cWew5f/bZZzA2Nsbp06fx3nvvwcfHB7Vq1cKbb76JHTt2oFu3bgCAuLg4SCQSpX/zp6amQiKRICoqSpF26dIlhIaGwsrKCs7Ozujbty/u33/6IOqWLVvQqFEjmJubw8HBAcHBwcj6//6KiopCy5YtYWlpCVtbWwQFBSE+Ph7Ak2EGzwZ4Rec/c+ZMuLq6wsHBAeHh4Up3NRMSEtC1a1eYm5vDy8sL69atg6enJ+bOnavxepw5cwY3btxA165dVfZt3rwZvr6+GDt2LA4ePIj//vuv2Gurydy5c3Hw4EFERkYiPDwcTZo0Qa1atfDBBx/gxIkTqFOnTpnLvHr1Knbv3o1ly5ahVatWePXVVzF//nxs2LAB9+7dK/bYos9Y0ev5Zzk6deqEhw8f4p9//ilzu4heFnoPZgFg6NChiI+PR25uLk6cOIFWrVop9kVFRWHVqlWK93PmzFHkTUxMxI4dO+Dv76+HVhMZECsrza933lHO6+SkOW9oqHJeT0/1+V7QpUuXcPToUZiaPn2KMicnB82aNcOOHTtw6dIlDBkyBH379sXJkyeVjl29ejUsLS1x4sQJ/Pjjj5g6daoiYJXL5Xj77bdhamqKEydOYMmSJfjqq6+Ujs/KykJISAjs7Oxw8uRJrF+/HpGRkRg6dKhSvv379+PevXs4ePAgZs+ejUmTJuGNN96AnZ0dTpw4gU8++QQff/wx7ty5o/YcHzx4gL179yI8PLzY8ZCllZqaig4dOsDf3x+nT5/G7t27kZSUhPfeew/Ak+CyV69e+PDDD3H16lVERUXh7bffVsy1GhYWhrZt2+LChQs4duwYhgwZUmz9Bw4cwI0bN3DgwAGsXr0aq1atUvpZ3a9fP9y7dw9RUVH4/fffsXTpUsUE/5ocOnQIdevWRbVqqgvMLF++HH369IGNjQ1CQ0OV6iqLtWvXIjg4WO3vDRMTE0VfTJ8+XXFHWtPr9u3bAIBjx47B1tYWzZs3V5QVHBwMqVSKEydOlNie6tWro2HDhhg3bpzK0BJTU1M0adIEhw4dKtf5Er0M+D8LIqoU/v77b1hZWaGgoAC5ubmQSqVYsGCBYn+NGjXw5ZdfKt5//vnn2LNnDzZt2qS0/HXjxo0xadIkAECdOnWwYMECREZGolOnTti3bx9iYmKwZ88euLm5AXgStIQ+E6SvW7cOOTk5+PXXX2FhYYH69etj/vz56N69O3744QfFf43s7e3x888/QyqVol69evjxxx/x+PFjjB8/HsCTmVS+//57HD58GD179lQ53+vXr0MIgXr16imlV69eXTFWODw8vNTDLBYsWAB/f39Mnz5dkbZixQq4u7vj33//RWZmJgoKCvD222/Dw8MDANCoUSMAT8Z7pqWl4Y033kDt2rUBAD4+PsXWZ2dnhwULFsDIyAj169dH165dERkZicGDByMmJgb79u3DqVOnFAHesmXLSrzrGR8fr+iXZ127dg3Hjx/H1q1bAQB9+vTByJEjMXHixDI/uHXt2jW0a9euxHyffPKJ4g8BTYrampiYqLJipbGxMezt7ZGYmKjx+A8++AAeHh5wc3PDhQsX8NVXXyE2NlZxns/WU3SXnIhUMZjVJS5nS5VFcQ+iPL9qUHF3z55/ujQurtxNel779u2xePFiZGVlYc6cOTA2NsY7z9w1LiwsxPTp07Fp0ybcvXsXeXl5yM3NVRlj2LhxY6X3rq6uijuCV69ehbu7u1LA9PzDplevXoWfnx8sLS0VE+kHBQVBLpcjNjZWEcw2aNBA6WlbZ2dnNGzYUPHeyMgIDg4OJd6NfN7Jkychl8vRu3dvpQVfSnL+/HkcOHBA7djWGzduoHPnzujYsSMaNWqEkJAQdO7cGe+++y7s7Oxgb2+PAQMGICQkBJ06dUJwcDDee++9Yh+sbdCggdKKU66urrh48SIAIDY2FsbGxmjatKliv7e3N+zs7Io9h+zsbLXT8axYsQIhISGoXr06AOD111/HRx99hP3796Njx47FX5jnlHZxBHt7e9jb25ep7LIaMmSIYrtRo0ZwdXVFx44dcePGDcUfFcCThREqy8OARJVRpRhmUGVxOVuqLCwtNb+eDx6Ky/v/y2eWmLdcTbSEt7c3/Pz8sGLFCpw4cQLLly9X7P/pp58wb948fPXVVzhw4ACio6MREhKCvLw8pXKenzNUIpHoZNUadfWUpW5vb29IJBLExsYqpdeqVQve3t6KpUqBp1PUPBuIPf/UfWZmJrp164bo6GilV9EYYSMjI0RERGDXrl3w9fXF/PnzUa9ePdy6dQsAsHLlShw7dgyBgYHYuHEj6tati+PHj5fp/F/0OlevXh2PHj1SSissLMTq1auxY8cOxRzKFhYWePjwIVasWKHIZ21tjbQ01fkxU1NTYWRkpBg+ULduXY2L8jyrLMMMXFxcVP5oKSgowMOHD8u09HrRELvnp5p8+PAhHB0dS10O0cuGwSwRVTpSqRTjx4/HxIkTkf3/D50dOXIEb775Jvr06QM/Pz/UqlUL//77b5nK9fHxwX///af0UOnzAZuPjw/Onz+veDCqqO6i4QTa4uDggE6dOmHBggVKdalTFMg82+7n53xt2rQpLl++DE9PT3h7eyu9igI5iUSCoKAgTJkyBefOnYOpqSm2bdumKMPf3x/jxo3D0aNH0bBhwxKfxNekXr16KCgowLlz5xRp169fVwlUn+fv74+YmBiloH3nzp3IyMjAuXPnlIL09evXY+vWrYopt+rVq4fLly+r3M0+e/YsvLy8FMH3Bx98gH379im1rUh+fr6iLz755BOVPwyefxXd4Q8ICEBqairOnDmjKGv//v2Qy+VKz4CUpKhPn78jfunSJT4bQlQMBrNEVCn16NEDRkZGWLhwIYAn418jIiJw9OhRXL16FR9//LHKgislCQ4ORt26ddG/f3+cP38ehw4dwoQJE5Ty9O7dG2ZmZujfvz8uXbqEqKgoDBs2DH379lVZevtFLVq0CAUFBWjevDk2btyIq1evIjY2FmvWrEFMTIzi3/jm5uZo3bo1vv/+e1y9ehX//PMPJk6cqFRWeHg4Hj58iF69euHUqVO4ceMG9uzZg4EDB6KwsBAnTpzA9OnTcfr0ady+fRtbt25FSkoKfHx8cOvWLYwbNw7Hjh1DfHw89u7di2vXrpU4blaT+vXrIzg4GEOGDMHJkydx7tw5DBkyBObm5sWOcW3fvj0yMzNx+fJlRdry5cvRtWtX+Pn5oWHDhorXe++9B1tbW6xduxbAk36TSCTo168fzpw5g+vXr2PFihWYO3cuRo0apShv+PDhCAoKQseOHbFw4UKcP38eN2/exKZNm9C6dWtcu3YNwJNhBs//UfD8q2iqLB8fH3Tp0gWDBw/GyZMnceTIEQwdOhQ9e/ZUBLx3795F/fr1FQ8s3rhxA9OmTcOZM2cQFxeHP//8E/369UObNm2UhsrExcXh7t27CA4OLldfEL0MGMwSUaVkbGyMoUOH4scff0RWVhYmTpyIpk2bIiQkBO3atYOLi4vaSfKLI5VKsW3bNmRnZ6Nly5YYNGgQvvvuO6U8FhYW2LNnDx4+fIiWLVuiZ8+e6NChg9LDaNpSu3ZtnDt3DsHBwRg3bhz8/PzQvHlzzJ8/H19++aXSEt0rVqxAQUEBmjVrhuHDh+Pbb79VKsvNzQ1HjhxBYWEhOnfujEaNGmH48OGwtbWFVCqFtbU1Dh48iNdffx1169bFxIkTMWvWLISGhsLCwgIxMTF45513ULduXQwZMgTh4eH4+OOPy31uv/76K5ydndGmTRu89dZbGDx4MKpVq1bsEpUODg546623FAFqUlISduzYoTR2uohUKsVbb72lGIpia2uLQ4cOIT8/H927d0eTJk3w888/Y/bs2UrnIZPJEBERgTFjxmDp0qV47bXX0LJlS/z8888YNmyY0rjnsli7di3q16+Pjh074vXXX8err76KpUuXKvbn5+cjNjZWMfbV1NQU+/btQ+fOnVG/fn2MGjUK77zzDv766y+lctevX4/OnTsrHtojIlUSUdrR8FVEeno6bGxskJaWpjKfn7ZlPUqG1c9P7uSkf56AavalHztFhkEulyM5ORlOTk56X0oyJycHt27dgpeXF9do15KiaauMjY0r5XKnhuTOnTtwd3fHvn37in1o68KFC+jUqRNu3Lih84UaKnv/5uXloU6dOli3bh2CgoLU5uH3XjNt/HzefEN1HHZp9KhtU+byNB3zIjTVV1xdFd1GTcoSr3E2AyIi0rr9+/cjMzMTjRo1QkJCAsaMGQNPT0+0adOm2OMaN26MH374Abdu3VJMHfayun37NsaPH68xkCWiJxjM6hKXsyWil1R+fj7Gjx+Pmzdvolq1aggMDMTatWtVZkFQZ8CAAbpvoAEoGptLRMVjMKtLXM6WiF5SISEhCAkJ0XcziOglwAfAiIiIiMhgMZglIiIiIoPFYFaX/n+yd5VtIiIiItIKBrO69OzSjkL7y2kSERERvewYzBIRERGRwWIwS0REREQGi8EsEVV6UVFRkEgkSE1NrdB6V61aBUdHxxcqIy4uDhKJBNHR0RrzlPb8IiMj4ePjg8LCwhdqU0nGjh2Lzz//XKd1EBFpC4NZItIriURS7Gvy5Mn6bmKlMWbMGEycOBFGRkaKtKioKDRt2hQymQze3t5YtWpVsWUUBdfPv44fP67I8+WXX2L16tW4efOmrk6FiEhrGMwSkV4lJCQoXnPnzoW1tbVS2pdfflmucvPy8rTcUv06fPgwbty4gXfeeUeRduvWLXTt2hXt27dHdHQ0hg8fjkGDBmHPnj0llrdv3z6l69ysWTPFvurVqyMkJASLFy/WybkQEWkTg1miKkwIgay8LL28hBClaqOLi4viZWNjA4lEopRmZWWlyHvmzBk0b94cFhYWCAwMRGxsrGLf5MmT0aRJEyxbtgxeXl4wMzMDAKSmpmLQoEFwdHSEtbU1OnTogPPnzyuOO3/+PNq3b49q1arB2toazZo1w+nTp5XauGfPHvj4+MDKygpdunRBQkKCYp9cLsfUqVNRs2ZNyGQyNGnSBLt37y72nHfu3Im6devC3Nwc7du3R1xcXInXacOGDejUqZPivABgyZIl8PLywqxZs+Dj44OhQ4fi3XffxZw5c0osz8HBQek6P7/MbLdu3bBhw4YSyyEi0jcuZ6tLlpZPty0sNecj0pHH+Y9hNcOq5Iw6kDkuE5am2v3cT5gwAbNmzYKjoyM++eQTfPjhhzhy5Ihi//Xr1/H7779j69atin/F9+jRA+bm5ti1axdsbGzwyy+/oGPHjvj3339hb2+P3r17w9/fH4sXL4aRkRGio6OVArvHjx9j1qxZ+O233yCVStGnTx98+eWXWLt2LQBg3rx5mDVrFn755Rf4+/tjxYoV6N69Oy5fvow6deqonMN///2Ht99+G+Hh4RgyZAhOnz6NUaNGlXjuhw4dwgcffKCUduzYMQQHByulhYSEYPjw4SWW1717d+Tk5KBu3boYM2YMunfvrrS/ZcuWuHPnDuLi4uDp6VlieURE+sJglogMxnfffYe2bdsCePKQUteuXZGTk6O4W5mXl4dff/1V8dDW4cOHcfLkSSQnJ0MmkwEAZs6cie3bt2PLli0YMmQIbt++jdGjR6N+/foAoBKA5ufnY/HixfD29gYADB06FFOnTlXsnzlzJr766iv07NkTAPDDDz/gwIEDmDt3LhYuXKhyDosXL0bt2rUxa9YsAEC9evVw8eJF/PDDD8Wee3x8PNzc3JTSEhMT4ezsrJTm7OyM9PR0ZGdnw9zcXKUcKysrzJo1C0FBQZBKpfj9998RFhaG7du3KwW0RXXFx8czmCWiSo3BLFEVZmFigcxxmXqrW9saN26s2HZ1dQUAJCcn45VXXgEAeHh4KM0+cP78eWRmZsLBwUGpnOzsbNy4cQMAMHLkSAwaNAi//fYbgoOD0aNHD9SuXfvpeVhYKL13dXVFcnIyACA9PR337t1DUFCQUvlBQUFKQxmedfXqVbRq1UopLSAgoMRzz87OVhpiUF7Vq1fHyJEjFe9btGiBe/fu4aefflIKZosC4cePH79wnUREusRgVpeeX87WrJr+2kIvJYlEovV/9evTs//+l0gkAJ6MWS1iaal8rpmZmXB1dUVUVJRKWba2tgCejLX94IMPsGPHDuzatQuTJk3Chg0b8NZbb6nUWVRvaccDa1P16tXx6NEjpTQXFxckJSUppSUlJcHa2lrtXVlNWrVqhYiICKW0hw8fAsALT01GRKRrfABMl7icLZFeNW3aFImJiTA2Noa3t7fSq3r16op8devWxYgRI7B37168/fbbWLlyZanKt7a2hpubm9K4XQA4cuQIfH191R7j4+ODkydPKqU9Oy2WJv7+/rhy5YpSWkBAACIjI5XSIiIiSnWn91nR0dGKO91FLl26BBMTEzRo0KBMZRERVTQGs0RUZQUHByMgIABhYWHYu3cv4uLicPToUUyYMAGnT59GdnY2hg4diqioKMTHx+PIkSM4deoUfHx8Sl3H6NGj8cMPP2Djxo2IjY3F2LFjER0djS+++EJt/k8++QTXrl3D6NGjERsbi3Xr1pU4Nyzw5MGuw4cPq5R18+ZNjBkzBjExMVi0aBE2bdqEESNGKPIsWLAAHTt2VLxfvXo11q9fj5iYGMTExGD69OlYsWKFyiIJhw4dwmuvvVamO7xERPrAYQZEVGVJJBLs3LkTEyZMwMCBA5GSkgIXFxe0adMGzs7OMDIywoMHD9CvXz8kJSWhevXqePvttzFlypRS1zFs2DCkpaVh1KhRSE5Ohq+vL/7880+1MxkAwCuvvILff/8dI0aMwPz589GyZUtMnz4dH374YbH19O7dG2PGjEFsbCzq1asHAPDy8sKOHTswYsQIzJs3DzVr1sSyZcsQEhKiOO7+/fuK8cFFpk2bhvj4eBgbG6N+/frYuHEj3n33XaU8GzZs4IIVRGQQJEIfg7/0KD09HTY2NkhLS4O1tbVO68p6lAyrn588aZz+eQKq2bvotD6qeHK5HMnJyXBycoJUqt9/dOTk5ODWrVtKc6zSixFCoKCgAMbGxooxuvo0evRopKen45dfftFpPbt27cKoUaNw4cIFGBtX3Xsela1/y4Pfe8208fN58420ch3Xo7ZNmcvTdMyL0FRfcXVVdBs1KUu8xmEGREQGYsKECfDw8FB66E0XsrKysHLlyiodyBJR1cGfVEREBsLW1hbjx4/XeT3PDzkgIqrMeGeWiIiIiAwWg1ld4nK2RERERDrFYJaoinnJnukkeqnx+07EYJaoyihaqYrLjxK9PIq+78+vVEf0MuEDYLqUk6O8zeVsSYeMjIxga2uL5ORkAICFhYXBTjdUWVSFqZtIM0PuXyEEHj9+jOTkZNja2sLIyEjfTSLSGwazulRY+HRbXqg5H5GWuLg8mcu4KKClFyOEgFwuh1QqNbhgh0pWFfrX1tZW8b0nelkxmCWqQiQSCVxdXeHk5IT8/Hx9N8fgyeVyPHjwAA4ODnpfFIO0z9D718TEhHdkicBglqhKMjIy4i85LZDL5TAxMYGZmZlBBjtUPPYvUdVQKb69CxcuhKenJ8zMzNCqVSucPHmy2PybN29G/fr1YWZmhkaNGmHnzp0V1FIiIiIiqkz0Hsxu3LgRI0eOxKRJk3D27Fn4+fkhJCRE45i/o0ePolevXvjoo49w7tw5hIWFISwsDJcuXarglhMRERGRvuk9mJ09ezYGDx6MgQMHwtfXF0uWLIGFhQVWrFihNv+8efPQpUsXjB49Gj4+Ppg2bRqaNm2KBQsWVHDLiYiIiEjf9DpmNi8vD2fOnMG4ceMUaVKpFMHBwTh27JjaY44dO4aRI0cqpYWEhGD79u1q8+fm5iI3N1fxPi0tDQCQmpoKuVz+gmdQvKy0NOD/Z+dKTUtDodRMp/VRxZPL5UhPT4epqSnH3FVB7N+qjf1btWmjfx+np5XruNRU9YtZFFeepmNehKb6iqurotuoSXp6OoDSLQyi12D2/v37KCwshLOzs1K6s7MzYmJi1B6TmJioNn9iYqLa/DNmzMCUKVNU0j08PMrZ6vJ55fv6FVofERERkaHLyMiAjY1NsXmq/GwG48aNU7qTK5fL8fDhQzg4OFTIvILp6elwd3fHf//9B2tra53XRxWL/Vu1sX+rNvZv1cb+NWxCCGRkZMDNza3EvHoNZqtXrw4jIyMkJSUppSclJWmcBNrFxaVM+WUyGWQymVKara1t+RtdTtbW1vwyVWHs36qN/Vu1sX+rNvav4SrpjmwRvQ4SMjU1RbNmzRAZGalIk8vliIyMREBAgNpjAgIClPIDQEREhMb8RERERFR16X2YwciRI9G/f380b94cLVu2xNy5c5GVlYWBAwcCAPr164caNWpgxowZAIAvvvgCbdu2xaxZs9C1a1ds2LABp0+fxtKlS/V5GkRERESkB3oPZt9//32kpKTgm2++QWJiIpo0aYLdu3crHvK6ffu20lOIgYGBWLduHSZOnIjx48ejTp062L59Oxo2bKivUyiWTCbDpEmTVIY6UNXA/q3a2L9VG/u3amP/vjwkojRzHhARERERVUKcWI+IiIiIDBaDWSIiIiIyWAxmiYiIiMhgMZglIiIiIoPFYLYcFi5cCE9PT5iZmaFVq1Y4efKkxryrVq2CRCJRepmZmSnlEULgm2++gaurK8zNzREcHIxr167p+jRIA232b35+Pr766is0atQIlpaWcHNzQ79+/XDv3r2KOBVSQ9vf32d98sknkEgkmDt3rg5aTiXRRd9evXoV3bt3h42NDSwtLdGiRQvcvn1bl6dBGmi7fzMzMzF06FDUrFkT5ubm8PX1xZIlS3R9GqQDDGbLaOPGjRg5ciQmTZqEs2fPws/PDyEhIUhOTtZ4jLW1NRISEhSv+Ph4pf0//vgjfv75ZyxZsgQnTpyApaUlQkJCkJOTo+vToedou38fP36Ms2fP4uuvv8bZs2exdetWxMbGonv37hVxOvQcXXx/i2zbtg3Hjx8v1dKLpH266NsbN27g1VdfRf369REVFYULFy7g66+/LvYPGtINXfTvyJEjsXv3bqxZswZXr17F8OHDMXToUPz555+6Ph3SNkFl0rJlSxEeHq54X1hYKNzc3MSMGTPU5l+5cqWwsbHRWJ5cLhcuLi7ip59+UqSlpqYKmUwm1q9fr7V2U+lou3/VOXnypAAg4uPjX6SpVA666t87d+6IGjVqiEuXLgkPDw8xZ84cLbWYSksXffv++++LPn36aLOZVE666N8GDRqIqVOnKqU1bdpUTJgw4YXbSxWLd2bLIC8vD2fOnEFwcLAiTSqVIjg4GMeOHdN4XGZmJjw8PODu7o4333wTly9fVuy7desWEhMTlcq0sbFBq1atii2TtE8X/atOWloaJBIJbG1ttdV0KgVd9a9cLkffvn0xevRoNGjQQGftJ8100bdyuRw7duxA3bp1ERISAicnJ7Rq1Qrbt2/X5amQGrr67gYGBuLPP//E3bt3IYTAgQMH8O+//6Jz5846OxfSDQazZXD//n0UFhYqVicr4uzsjMTERLXH1KtXDytWrMAff/yBNWvWQC6XIzAwEHfu3AEAxXFlKZN0Qxf9+7ycnBx89dVX6NWrF6ytrbV+DqSZrvr3hx9+gLGxMYYNG6bT9pNmuujb5ORkZGZm4vvvv0eXLl2wd+9evPXWW3j77bfxzz//6Pyc6CldfXfnz58PX19f1KxZE6ampujSpQsWLlyINm3a6PR8SPv0vpxtVRcQEICAgADF+8DAQPj4+OCXX37BtGnT9Ngy0oay9G9+fj7ee+89CCGwePHiim4qlUNJ/XvmzBnMmzcPZ8+ehUQi0WNLqaxK6lu5XA4AePPNNzFixAgAQJMmTXD06FEsWbIEbdu21Uu7qXRK87N5/vz5OH78OP788094eHjg4MGDCA8Ph5ubm9JdYKr8eGe2DKpXrw4jIyMkJSUppSclJcHFxaVUZZiYmMDf3x/Xr18HAMVxL1ImaYcu+rdIUSAbHx+PiIgI3pXVA13076FDh5CcnIxXXnkFxsbGMDY2Rnx8PEaNGgVPT09tnwJpoIu+rV69OoyNjeHr66uUz8fHh7MZVDBd9G92djbGjx+P2bNno1u3bmjcuDGGDh2K999/HzNnztT6OZBuMZgtA1NTUzRr1gyRkZGKNLlcjsjISKW/AItTWFiIixcvwtXVFQDg5eUFFxcXpTLT09Nx4sSJUpdJ2qGL/gWeBrLXrl3Dvn374ODgoPW2U8l00b99+/bFhQsXEB0drXi5ublh9OjR2LNnj07Og1Tpom9NTU3RokULxMbGKuX7999/4eHhob3GU4l00b/5+fnIz8+HVKocBhkZGSnuypMB0fcTaIZmw4YNQiaTiVWrVokrV66IIUOGCFtbW5GYmCiEEKJv375i7NixivxTpkwRe/bsETdu3BBnzpwRPXv2FGZmZuLy5cuKPN9//72wtbUVf/zxh7hw4YJ48803hZeXl8jOzq7w83vZabt/8/LyRPfu3UXNmjVFdHS0SEhIULxyc3P1co4vM118f5/H2Qz0Qxd9u3XrVmFiYiKWLl0qrl27JubPny+MjIzEoUOHKvz8Xna66N+2bduKBg0aiAMHDoibN2+KlStXCjMzM7Fo0aIKPz96MQxmy2H+/PnilVdeEaampqJly5bi+PHjin1t27YV/fv3V7wfPny4Iq+zs7N4/fXXxdmzZ5XKk8vl4uuvvxbOzs5CJpOJjh07itjY2Io6HXqONvv31q1bAoDa14EDByrwrKiItr+/z2Mwqz+66Nvly5cLb29vYWZmJvz8/MT27dsr4lRIDW33b0JCghgwYIBwc3MTZmZmol69emLWrFlCLpdX1CmRlkiEEEKfd4aJiIiIiMqLY2aJiIiIyGAxmCUiIiIig8VgloiIiIgMFoNZIiIiIjJYDGaJiIiIyGAxmCUiIiIig8VgloiIiIgMFoNZIiIiIjJYDGaJiEjn2rRpg3Xr1um8nri4OEgkEkRHR2vMExUVBYlEgtTUVADAqlWrYGtrq9g/efJkNGnS5IXb0rp1a/z+++8vXA4RFY/BLBGV2oABAyCRSBQvBwcHdOnSBRcuXNBqPaUJSJ6nrQBEW+rXrw+ZTIbExESVfZ6enpg7d65KurpzSExMxOeff45atWpBJpPB3d0d3bp1Q2RkZLH1P9tP1tbWaNGiBf744w+VfNnZ2Zg0aRLq1q0LmUyG6tWro0ePHrh8+bJK3vT0dEyYMAH169eHmZkZXFxcEBwcjK1bt6K4xST//PNPJCUloWfPnoq08+fPo3v37nBycoKZmRk8PT3x/vvvIzk5GYBqwKlNgYGBSEhIgI2Njdr9X375pdL1HTBgAMLCwspcz8SJEzF27FjI5fLyNpWISoHBLBGVSZcuXZCQkICEhARERkbC2NgYb7zxhr6bVWr5+fk6r+Pw4cPIzs7Gu+++i9WrV5e7nLi4ODRr1gz79+/HTz/9hIsXL2L37t1o3749wsPDSzx+5cqVSEhIwOnTpxEUFIR3330XFy9eVOzPzc1FcHAwVqxYgW+//Rb//vsvdu7ciYKCArRq1QrHjx9X5E1NTUVgYCB+/fVXjBs3DmfPnsXBgwfx/vvvY8yYMUhLS9PYjp9//hkDBw6EVPrkV05KSgo6duwIe3t77NmzB1evXsXKlSvh5uaGrKyscl+v0jI1NYWLiwskEona/VZWVnBwcHjhekJDQ5GRkYFdu3a9cFlEVAxBRFRK/fv3F2+++aZS2qFDhwQAkZycrEi7cOGCaN++vTAzMxP29vZi8ODBIiMjQ7G/sLBQTJkyRdSoUUOYmpoKPz8/sWvXLsV+AEqvtm3bCiGEOHDggGjRooWwsLAQNjY2IjAwUMTFxYmVK1eqHLNy5UpFWYsWLRLdunUTFhYWYtKkSaKgoEB8+OGHwtPTU5iZmYm6deuKuXPnqj3XyZMni+rVq4tq1aqJjz/+WOTm5pZ4nQYMGCDGjh0rdu3aJerWrauy38PDQ8yZM0clfdKkScLPz0/xPjQ0VNSoUUNkZmaq5H306FGxbQAgtm3bpnifnp4uAIh58+Yp0r7//nshkUhEdHS00rGFhYWiefPmwtfXV8jlciGEEJ9++qmwtLQUd+/eVakrIyND5Ofnq21HcnKykEgk4tKlS4q0bdu2CWNjY43H3Lp1S6U/+/fvL4QQYteuXSIoKEjY2NgIe3t70bVrV3H9+nWVY9evXy8CAgKETCYTDRo0EFFRUYo8Bw4cEAAU13DlypXCxsZGsf/Zfpg0aZJKWw4cOCDat28vwsPDVc7VxMRE7Nu3T5E2cOBA0adPH7XnSUTawTuzRFRumZmZWLNmDby9vRV3srKyshASEgI7OzucOnUKmzdvxr59+zB06FDFcfPmzcOsWbMwc+ZMXLhwASEhIejevTuuXbsGADh58iQAYN++fUhISMDWrVtRUFCAsLAwtG3bFhcuXMCxY8cwZMgQSCQSvP/++xg1ahQaNGiguGv8/vvvK+qbPHky3nrrLVy8eBEffvgh5HI5atasic2bN+PKlSv45ptvMH78eGzatEnp/CIjI3H16lVERUVh/fr12Lp1K6ZMmVLsNcnIyMDmzZvRp08fdOrUCWlpaTh06FCZr+3Dhw+xe/duhIeHw9LSUmX/s2M8S1JQUIDly5cDeHJXssi6devQqVMn+Pn5KeWXSqUYMWIErly5gvPnz0Mul2PDhg3o3bs33NzcVMq3srKCsbGx2roPHz4MCwsL+Pj4KNJcXFxQUFCAbdu2qR2e4O7urhhrGhsbi4SEBMybNw/Ak8/XyJEjcfr0aURGRkIqleKtt95S+Vf+6NGjMWrUKJw7dw4BAQHo1q0bHjx4UJrLpeTLL7/Ee++9p/QficDAQAwaNAjr1q1Dbm6uIu+aNWtQo0YNdOjQQZHWsmXLcvU/EZWBvqNpIjIc/fv3F0ZGRsLS0lJYWloKAMLV1VWcOXNGkWfp0qXCzs5O6W7ijh07hFQqFYmJiUIIIdzc3MR3332nVHaLFi3EZ599JoR4enft3Llziv0PHjwQAJTusD3r+buaRQCI4cOHl3hu4eHh4p133lE6V3t7e5GVlaVIW7x4sbCyshKFhYUay1m6dKlo0qSJ4v0XX3yhuKtYpDR3Zk+cOCEAiK1bt5bYdnUACDMzM2FpaSmkUqkAIDw9PcWDBw8UeczMzMQXX3yh9vizZ88KAGLjxo0iKSlJABCzZ88uczvmzJkjatWqpZI+fvx4YWxsLOzt7UWXLl3Ejz/+qPh8CKF691STlJQUAUBcvHhRCPH0s/P9998r8uTn54uaNWuKH374QW3Zxd2ZFUL9fySys7OFnZ2d2LhxoyKtcePGYvLkyUr5/vjjDyGVSov9zBDRi+GdWSIqk/bt2yM6OhrR0dE4efIkQkJCEBoaivj4eADA1atX4efnp3Q3MSgoCHK5HLGxsUhPT8e9e/cQFBSkVG5QUBCuXr2qsV57e3sMGDAAISEh6NatG+bNm4eEhIRStbl58+YqaQsXLkSzZs3g6OgIKysrLF26FLdv31bK4+fnBwsLC8X7gIAAZGZm4r///tNY14oVK9CnTx/F+z59+mDz5s3IyMgoVVuLiGIeqHrWJ598AisrK8XrWXPmzEF0dDR27doFX19fLFu2DPb29mWup7RtUSc7OxtmZmYq6d999x0SExOxZMkSNGjQAEuWLEH9+vWVxvSqc+3aNfTq1Qu1atWCtbU1PD09AUCl7wICAhTbxsbGaN68ebGfr7IyMzND3759sWLFCgDA2bNncenSJQwYMEApn7m5OeRyudIdXCLSLgazRFQmlpaW8Pb2hre3N1q0aIFly5YhKysL//vf/3Re98qVK3Hs2DEEBgZi48aNqFu3rtJDSsW1+VkbNmzAl19+iY8++gh79+5FdHQ0Bg4ciLy8vBdq35UrV3D8+HGMGTMGxsbGMDY2RuvWrfH48WNs2LBBkc/a2lrtA1OpqamKJ+zr1KkDiUSCmJiYYuucOnWq4o+L52d/cHFxgbe3Nzp37oyVK1cqzRYAAHXr1tUY4BWl161bF46OjrC1tS2xLepUr14djx49UrvPwcEBPXr0wMyZM3H16lW4ublh5syZxZbXrVs3PHz4EP/73/9w4sQJnDhxAgBeuO/KY9CgQYiIiMCdO3ewcuVKdOjQAR4eHkp5Hj58CEtLS5ibm1d4+4heFgxmieiFSCQSSKVSZGdnAwB8fHxw/vx5pafSjxw5AqlUinr16sHa2hpubm44cuSIUjlHjhyBr68vgKfjOgsLC1Xq8/f3x7hx43D06FE0bNhQMXepqamp2vzqHDlyBIGBgfjss8/g7+8Pb29v3LhxQyXf+fPnFecFAMePH4eVlRXc3d3Vlrt8+XK0adMG58+fVwowR44cqRizCgD16tXDmTNnVI4/e/Ys6tatC+DJneiQkBAsXLhQ7RP+RVNWOTk5Kf648Pb21njOLVu2RLNmzfDdd98p0nr27Il9+/bh/PnzSnnlcjnmzJkDX19f+Pn5QSqVomfPnli7di3u3bunUnZmZiYKCgrU1uvv74/ExESNAW0RU1NT1K5dW3Gu6j4DDx48QGxsLCZOnIiOHTvCx8dHY7nP/pFTUFCAM2fOKI3bLQtNn61GjRqhefPm+N///od169bhww8/VMlz6dIl+Pv7l6teIiolPQ9zICID0r9/f9GlSxeRkJAgEhISxJUrV8Rnn30mJBKJOHDggBBCiKysLOHq6ireeecdcfHiRbF//35Rq1YtpXGjc+bMEdbW1mLDhg0iJiZGfPXVV8LExET8+++/QognYxzNzc3Ft99+KxITE0Vqaqq4efOmGDt2rDh69KiIi4sTe/bsEQ4ODmLRokVCCCHWrl0rLC0txblz50RKSorIyckRQqg+1S+EEPPmzRPW1tZi9+7dIjY2VkycOFFYW1urjJO0srISvXr1EpcvXxY7duwQzs7OYuzYsWqvTV5ennB0dBSLFy9W2XflyhUBQPFE/5EjR4RUKhXffvutuHLlirh48aJiDGnR2E8hhLhx44ZwcXERvr6+YsuWLeLff/8VV65cEfPmzRP169cvtq/UnffOnTuFTCYTd+7cEUI8GffZqlUr4e7uLjZt2iTi4+PFyZMnRVhYmLC0tBTHjh1THPvgwQNRv359UbNmTbF69Wpx+fJl8e+//4rly5cLb29vjWNbCwoKhKOjo/jrr78UaX/99Zfo3bu3+Ouvv0RsbKyIiYkRP/30kzAyMhK//vqrEEKIO3fuCIlEIlatWiWSk5NFRkaGKCwsFA4ODqJPnz7i2rVrIjIyUrRo0ULpXIvGzL7yyiti69at4urVq2LIkCHCyspKpKSkCCHKPmb2u+++E6+88oqIiYkRKSkpIi8vT7Fv6dKlwtTUVNjZ2Yns7GyV82/btq2YOnVqsX1FRC+GwSwRlVr//v2VpiiqVq2aaNGihdiyZYtSvtJMzTV58mRRo0YNYWJiojI1lxBC/O9//xPu7u5CKpWKtm3bisTERBEWFiZcXV2Fqamp8PDwEN98843iwZqcnBzxzjvvCFtbW5WpuZ4P6nJycsSAAQOEjY2NsLW1FZ9++qkYO3as2od+vvnmG+Hg4CCsrKzE4MGDFUHy87Zs2aL0kNvzfHx8xIgRIxTv9+zZI4KCgoSdnZ1wcHAQ7dq1E//884/Kcffu3RPh4eHCw8NDmJqaiho1aoju3bsr/njQRN15y+VyUb9+ffHpp58q0rKyssSECROEt7e3MDExEfb29oo/RJ6Xmpoqxo4dK+rUqSNMTU2Fs7OzCA4OFtu2bVNM4aXOmDFjRM+ePRXvb9y4IQYPHizq1q0rzM3Nha2trWjRooWiz4pMnTpVuLi4CIlEovhjKCIiQvj4+AiZTCYaN24soqKi1Aaz69atEy1bthSmpqbC19dX7N+/X1FuWYPZ5ORk0alTJ2FlZaWYmqtIRkaGsLCwUDy8+Kw7d+4IExMT8d9//2m8NkT04iRCvMDIfiKiKmrAgAFITU3F9u3b9d0Ug5eYmIgGDRrg7NmzKmNKDV1cXBxq166NU6dOoWnTpkr7vvrqKzx69AhLly7VU+uIXg4cM0tERDrl4uKC5cuXq8w4YMjy8/ORmJiIiRMnonXr1iqBLPBkPPO0adP00Dqil4v6Wa6JiIi0KCwsTN9N0KojR46gffv2qFu3LrZs2aI2z6hRoyq4VUQvJw4zICIiIiKDxWEGRERERGSwGMwSERERkcFiMEtEREREBovBLBEREREZLAazRERERGSwGMwSERERkcFiMEtEREREBovBLBEREREZrP8DVC0MxUPIIxUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLTMY-gJNP7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvaR0LCQNQAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Xv-eZgLNQHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Excellent Version of INFUSE"
      ],
      "metadata": {
        "id": "IGIQ2qNCaPhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 5.0 (ICML-Ready: Robust, Interpretable, Reproducible)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# INFUSE (Integrative Neighborhood Feature Selection Using Stability Evaluation)\n",
        "# constructs stable, interpretable cohort features from high-dimensional biological data.\n",
        "# This version ensures correctness, handles edge cases, and supports publication.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, verbose=True, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap AUC-ROC for a cohort to be retained.\n",
        "            Cohorts with mean AUC < threshold are discarded.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Fitted transformer.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit INFUSE and return the transformed data matrix of stable cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            Transformed data with only stable cohort features.\n",
        "        \"\"\"\n",
        "        # Validate input\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # Store feature names\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # --- NEW: Remove Constant Features ---\n",
        "        non_constant_mask = ~(X == X[0, :]).all(axis=0)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        # Handle missing values\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_median)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filter features by F-score\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Step 1: Seed Selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Step 2: Diversity Filtering via JSD\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Log JSD matrix if verbose\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        # Step 3: Compute similarity matrix\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Step 4: Hybrid weighting\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Step 5: Graph regularization\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Step 6: Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Step 7: Final filtering by bootstrap AUC-ROC stability\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Warn if stability scores are borderline\n",
        "        if stabilities and self.verbose:\n",
        "            avg_stab = np.mean([s for s in stabilities if s >= 0.5])\n",
        "            if 0.5 <= avg_stab < 0.6:\n",
        "                warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking class imbalance or adjusting parameters.\")\n",
        "\n",
        "        # Save fitted attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"Evaluate stability via bootstrap AUC-ROC; keep only cohorts above threshold.\"\"\"\n",
        "        if Z.shape[1] == 0:\n",
        "            return Z, [], []\n",
        "\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            auc_vals = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                # --- NEW: Stratified Resampling ---\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    auc_vals.append(0.5)\n",
        "                    continue\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "                    auc = roc_auc_score(yb, proba)\n",
        "                    auc_vals.append(auc if np.isfinite(auc) else 0.5)\n",
        "                except Exception:\n",
        "                    auc_vals.append(0.5)\n",
        "            S_j = np.mean(auc_vals) if auc_vals else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept:\n",
        "            best_idx = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(i) for i in best_idx if i < len(stabilities)]\n",
        "            if self.verbose and kept:\n",
        "                print(f\"âš ï¸ No cohorts met stability_thresh={self.stability_thresh}. \"\n",
        "                      f\"Retaining top {len(kept)} by stability.\")\n",
        "            if not kept:\n",
        "                kept = [0] if stabilities else []\n",
        "\n",
        "        Z_final = Z[:, kept] if kept and Z.size > 0 else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        X = self.scaler_.transform(X)\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        if Z_fused.size > 0 and self.kept_indices_:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "            # Placeholder for biological interpretation\n",
        "            # print(f\"  ðŸ§¬ Pathway enrichment (example): Possible immune response module.\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "sWx2MjcORMC2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing (No Scaling) ---\n",
        "# This script prepares raw data for INFUSE, which handles its own scaling and imputation.\n",
        "# DO NOT scale here â€” only impute missing values.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder  # âœ… CRITICAL: This was missing!\n",
        "import warnings\n",
        "\n",
        "# Suppress non-critical warnings (optional)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Set random state for reproducibility\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "expression_file = \"/content/HiSeqV2\"                    # Gene expression (genes Ã— samples)\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"  # Clinical data\n",
        "label_column = 'vital_status.demographic'               # Target variable\n",
        "\n",
        "# ========================\n",
        "# 1. Load Expression Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "try:\n",
        "    X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T  # Transpose to samples Ã— genes\n",
        "    print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Expression file not found: {e}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Load Clinical Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "try:\n",
        "    y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "    print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Clinical file not found: {e}\")\n",
        "\n",
        "# ========================\n",
        "# 3. Standardize Sample IDs (TCGA 15-character barcode)\n",
        "# ========================\n",
        "print(\"\\nðŸ”§ Standardizing sample IDs (first 15 characters)...\")\n",
        "\n",
        "# Expression  index is sample ID\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Clinical  extract sample ID from 'sample' column\n",
        "if 'sample' not in y_df_raw.columns:\n",
        "    raise ValueError(\"Clinical data must have a 'sample' column.\")\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "\n",
        "# Drop rows with invalid sample IDs (less than 15 chars)\n",
        "valid_len_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_len_mask]\n",
        "\n",
        "# Set index and deduplicate (keep first)\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# ========================\n",
        "# 4. Find Common Samples\n",
        "# ========================\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "if len(common_samples) == 0:\n",
        "    raise ValueError(\"No common samples between expression and clinical data.\")\n",
        "\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# ========================\n",
        "# 5. Extract and Clean Labels\n",
        "# ========================\n",
        "print(f\"\\nðŸ” Extracting label: '{label_column}'\")\n",
        "\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found in clinical data.\")\n",
        "\n",
        "# Extract and clean label\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "\n",
        "# Filter out invalid/unknown labels\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)', 'Survived'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid/unknown labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "# Remove any remaining 'nan' strings\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Final label vector\n",
        "y = y_encoded\n",
        "\n",
        "# ========================\n",
        "# 6. Handle Missing Values in Expression (Impute Only)\n",
        "# ========================\n",
        "print(\"\\n--- Handling Missing Values in Expression Data ---\")\n",
        "initial_nan = np.isnan(X_df).values.sum()\n",
        "initial_inf = np.isinf(X_df).values.sum()\n",
        "print(f\"Initial: NaN={initial_nan}, Inf={initial_inf}\")\n",
        "\n",
        "# Replace Inf with NaN\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Median imputation\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# Final check\n",
        "if np.isnan(X_imputed).any() or np.isinf(X_imputed).any():\n",
        "    raise ValueError(\"âŒ NaN or Inf values remain after imputation!\")\n",
        "\n",
        "# Convert back to DataFrame for consistency\n",
        "X_imputed_df = pd.DataFrame(X_imputed, index=X_df.index, columns=X_df.columns)\n",
        "print(f\"Imputed data shape: {X_imputed_df.shape}\")\n",
        "\n",
        "# ========================\n",
        "# 7. Remove Constant Features\n",
        "# ========================\n",
        "print(\"\\nðŸ” Removing constant features...\")\n",
        "variances = X_imputed_df.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed_df = X_imputed_df.loc[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"  Removed {dropped_count} constant features.\")\n",
        "else:\n",
        "    print(\"  No constant features found.\")\n",
        "\n",
        "# ========================\n",
        "# 8. Final Output for INFUSE\n",
        "# ========================\n",
        "# Use raw, imputed, unscaled data â€” INFUSE will handle scaling\n",
        "X = X_imputed_df.values\n",
        "feature_names = X_imputed_df.columns.tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X (for INFUSE): shape {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: shape {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   Feature names: {len(feature_names)} genes\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Optional: Save encoder and imputer\n",
        "# import joblib\n",
        "# joblib.dump(le, 'label_encoder.pkl')\n",
        "# joblib.dump(imputer, 'imputer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8IihluJRMIq",
        "outputId": "c3dc2f6b-2e76-4ff9-db29-7c5605c810eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "\n",
            "ðŸ”§ Standardizing sample IDs (first 15 characters)...\n",
            "Found 1216 common samples.\n",
            "\n",
            "ðŸ” Extracting label: 'vital_status.demographic'\n",
            "âš ï¸  Dropping 1 samples with invalid/unknown labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values in Expression Data ---\n",
            "Initial: NaN=0, Inf=0\n",
            "âœ… Median imputation applied.\n",
            "Imputed data shape: (1215, 20530)\n",
            "\n",
            "ðŸ” Removing constant features...\n",
            "  Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X (for INFUSE): shape (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: shape (1215,), classes: 2\n",
            "   Feature names: 20252 genes\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.1,\n",
        "    beta=0.1,\n",
        "    jsd_threshold=0.35,\n",
        "    #final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,  # Keep â‰¥0.5\n",
        "    max_features=1000,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "\n",
        "print(f\"Final shape: {Z_final.shape}\")\n",
        "infuse.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ykEOi-PGRMPW",
        "outputId": "4ae2acdf-029c-4349-d59d-c24ab93d2618"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20252 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "   JSD between seeds:\n",
            "           KLF10   APOB   ADH4   UBTF  CRHR2  LOC729467  CLEC4M  SAMD1\n",
            "KLF10      0.000  0.416  0.427  0.500  0.438      0.580   0.696  0.523\n",
            "APOB       0.416  0.000  0.411  0.564  0.438      0.567   0.692  0.578\n",
            "ADH4       0.427  0.411  0.000  0.572  0.487      0.571   0.703  0.586\n",
            "UBTF       0.500  0.564  0.572  0.000  0.537      0.699   0.721  0.369\n",
            "CRHR2      0.438  0.438  0.487  0.537  0.000      0.582   0.713  0.544\n",
            "LOC729467  0.580  0.567  0.571  0.699  0.582      0.000   0.754  0.703\n",
            "CLEC4M     0.696  0.692  0.703  0.721  0.713      0.754   0.000  0.726\n",
            "SAMD1      0.523  0.578  0.586  0.369  0.544      0.703   0.726  0.000\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "Final shape: (1215, 8)\n",
            "\n",
            "ðŸ” INFUSE Cohort Descriptions:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.582\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1 ...\n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.584\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392 ...\n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.589\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1 ...\n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.612\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446 ...\n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.572\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP ...\n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.594\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B ...\n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.586\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182 ...\n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.590\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1909281171.py:218: UserWarning: âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking class imbalance or adjusting parameters.\n",
            "  warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking class imbalance or adjusting parameters.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cohort_id  seed_gene  num_members  \\\n",
              "0          0      KLF10            6   \n",
              "1          1       APOB            6   \n",
              "2          2       ADH4            6   \n",
              "3          3       UBTF            6   \n",
              "4          4      CRHR2            6   \n",
              "5          5  LOC729467            6   \n",
              "6          6     CLEC4M            6   \n",
              "7          7      SAMD1            6   \n",
              "\n",
              "                                        member_genes  stability  \n",
              "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.581850  \n",
              "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.583727  \n",
              "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.588915  \n",
              "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.612126  \n",
              "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.572306  \n",
              "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.593975  \n",
              "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.586304  \n",
              "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.590243  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9103c9a0-59ec-4a40-a318-3e46b6594629\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohort_id</th>\n",
              "      <th>seed_gene</th>\n",
              "      <th>num_members</th>\n",
              "      <th>member_genes</th>\n",
              "      <th>stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLF10</td>\n",
              "      <td>6</td>\n",
              "      <td>[DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]</td>\n",
              "      <td>0.581850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>APOB</td>\n",
              "      <td>6</td>\n",
              "      <td>[GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]</td>\n",
              "      <td>0.583727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ADH4</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]</td>\n",
              "      <td>0.588915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>UBTF</td>\n",
              "      <td>6</td>\n",
              "      <td>[WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]</td>\n",
              "      <td>0.612126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CRHR2</td>\n",
              "      <td>6</td>\n",
              "      <td>[FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]</td>\n",
              "      <td>0.572306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LOC729467</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]</td>\n",
              "      <td>0.593975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>CLEC4M</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]</td>\n",
              "      <td>0.586304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>SAMD1</td>\n",
              "      <td>6</td>\n",
              "      <td>[C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]</td>\n",
              "      <td>0.590243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9103c9a0-59ec-4a40-a318-3e46b6594629')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9103c9a0-59ec-4a40-a318-3e46b6594629 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9103c9a0-59ec-4a40-a318-3e46b6594629');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cff96803-b485-4ed4-bbfb-52067c79470e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff96803-b485-4ed4-bbfb-52067c79470e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cff96803-b485-4ed4-bbfb-52067c79470e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"infuse\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"cohort_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"APOB\",\n          \"LOC729467\",\n          \"KLF10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_members\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"member_genes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011496330720058743,\n        \"min\": 0.5723064386895106,\n        \"max\": 0.612125736952479,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5837272484469591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btYPBuVSaqGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modified _final_filter Function: PR-AUC + Stratified Bootstrapping\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# FILE: infuse_final.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 5.0 (ICML-Ready: Robust, Interpretable, Reproducible)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# INFUSE (Integrative Neighborhood Feature Selection Using Stability Evaluation)\n",
        "# constructs stable, interpretable cohort features from high-dimensional biological data.\n",
        "# This version ensures correctness, handles edge cases, and supports publication.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.0.0\n",
        "# - scipy>=1.7.0\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "import warnings\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, verbose=True, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap AUC-ROC for a cohort to be retained.\n",
        "            Cohorts with mean AUC < threshold are discarded.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        \"\"\"\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.scaler_ = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Fitted transformer.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit INFUSE and return the transformed data matrix of stable cohort features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            Transformed data with only stable cohort features.\n",
        "        \"\"\"\n",
        "        # Validate input\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # Store feature names\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # --- NEW: Remove Constant Features ---\n",
        "        non_constant_mask = ~(X == X[0, :]).all(axis=0)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        # Handle missing values\n",
        "        if np.isnan(X).any():\n",
        "            if self.verbose:\n",
        "                print(\"ðŸ” Handling NaNs in input data...\")\n",
        "            col_medians = np.nanmedian(X, axis=0)\n",
        "            col_medians = np.where(np.isnan(col_medians), 0.0, col_median)\n",
        "            nan_mask = np.where(np.isnan(X))\n",
        "            X[nan_mask] = np.take(col_medians, nan_mask[1])\n",
        "\n",
        "        # Pre-filter features by F-score\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Step 1: Seed Selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Step 2: Diversity Filtering via JSD\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Log JSD matrix if verbose\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        # Step 3: Compute similarity matrix\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        # Step 4: Hybrid weighting\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Step 5: Graph regularization\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        # Step 6: Cohort fusion\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Step 7: Final filtering by bootstrap AUC-ROC stability\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Warn if stability scores are borderline\n",
        "        if stabilities and self.verbose:\n",
        "            avg_stab = np.mean([s for s in stabilities if s >= 0.5])\n",
        "            if 0.5 <= avg_stab < 0.6:\n",
        "                warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking class imbalance or adjusting parameters.\")\n",
        "\n",
        "        # Save fitted attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using PR-AUC (better for imbalance)\n",
        "        and stratified resampling.\n",
        "        \"\"\"\n",
        "        from sklearn.metrics import average_precision_score  # PR-AUC\n",
        "\n",
        "        stabilities = []\n",
        "        rng = self.random_state  # For consistent sampling\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            pr_auc_vals = []\n",
        "\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                # --- KEY CHANGE 1: Stratified Resampling ---\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    pr_auc_vals.append(0.5)  # fallback\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    # --- KEY CHANGE 2: Use PR-AUC instead of ROC-AUC ---\n",
        "                    pr_auc = average_precision_score(yb, y_proba)\n",
        "                    pr_auc_vals.append(pr_auc if np.isfinite(pr_auc) else 0.5)\n",
        "                except Exception:\n",
        "                    pr_auc_vals.append(0.5)\n",
        "\n",
        "            S_j = np.mean(pr_auc_vals) if pr_auc_vals else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # Filtering logic remains the same\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept:\n",
        "            # Fallback: keep top final_k by stability\n",
        "            top_indices = np.argsort(stabilities)[::-1][:self.final_k]\n",
        "            kept = [int(idx) for idx in top_indices if idx < len(stabilities)]\n",
        "            if not kept and len(stabilities) > 0:\n",
        "                kept = [0]  # ultimate fallback\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        X = self.scaler_.transform(X)\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        if Z_fused.size > 0 and self.kept_indices_:\n",
        "            return Z_fused[:, self.kept_indices_]\n",
        "        else:\n",
        "            return np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "            # Placeholder for biological interpretation\n",
        "            # print(f\"  ðŸ§¬ Pathway enrichment (example): Possible immune response module.\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "-hSFubXLaqMK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Data Loading & Preprocessing (No Scaling) ---\n",
        "# This script prepares raw data for INFUSE, which handles its own scaling and imputation.\n",
        "# DO NOT scale here â€” only impute missing values.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder  # âœ… CRITICAL: This was missing!\n",
        "import warnings\n",
        "\n",
        "# Suppress non-critical warnings (optional)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Set random state for reproducibility\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "expression_file = \"/content/HiSeqV2\"                    # Gene expression (genes Ã— samples)\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"  # Clinical data\n",
        "label_column = 'vital_status.demographic'               # Target variable\n",
        "\n",
        "# ========================\n",
        "# 1. Load Expression Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "try:\n",
        "    X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T  # Transpose to samples Ã— genes\n",
        "    print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Expression file not found: {e}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Load Clinical Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "try:\n",
        "    y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "    print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    raise FileNotFoundError(f\"Clinical file not found: {e}\")\n",
        "\n",
        "# ========================\n",
        "# 3. Standardize Sample IDs (TCGA 15-character barcode)\n",
        "# ========================\n",
        "print(\"\\nðŸ”§ Standardizing sample IDs (first 15 characters)...\")\n",
        "\n",
        "# Expression  index is sample ID\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "\n",
        "# Clinical  extract sample ID from 'sample' column\n",
        "if 'sample' not in y_df_raw.columns:\n",
        "    raise ValueError(\"Clinical data must have a 'sample' column.\")\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "\n",
        "# Drop rows with invalid sample IDs (less than 15 chars)\n",
        "valid_len_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_len_mask]\n",
        "\n",
        "# Set index and deduplicate (keep first)\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# ========================\n",
        "# 4. Find Common Samples\n",
        "# ========================\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "if len(common_samples) == 0:\n",
        "    raise ValueError(\"No common samples between expression and clinical data.\")\n",
        "\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# ========================\n",
        "# 5. Extract and Clean Labels\n",
        "# ========================\n",
        "print(f\"\\nðŸ” Extracting label: '{label_column}'\")\n",
        "\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found in clinical data.\")\n",
        "\n",
        "# Extract and clean label\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "\n",
        "# Filter out invalid/unknown labels\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)', 'Survived'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid/unknown labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "# Remove any remaining 'nan' strings\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y_encoded)))}\")\n",
        "\n",
        "# Final label vector\n",
        "y = y_encoded\n",
        "\n",
        "# ========================\n",
        "# 6. Handle Missing Values in Expression (Impute Only)\n",
        "# ========================\n",
        "print(\"\\n--- Handling Missing Values in Expression Data ---\")\n",
        "initial_nan = np.isnan(X_df).values.sum()\n",
        "initial_inf = np.isinf(X_df).values.sum()\n",
        "print(f\"Initial: NaN={initial_nan}, Inf={initial_inf}\")\n",
        "\n",
        "# Replace Inf with NaN\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Median imputation\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# Final check\n",
        "if np.isnan(X_imputed).any() or np.isinf(X_imputed).any():\n",
        "    raise ValueError(\"âŒ NaN or Inf values remain after imputation!\")\n",
        "\n",
        "# Convert back to DataFrame for consistency\n",
        "X_imputed_df = pd.DataFrame(X_imputed, index=X_df.index, columns=X_df.columns)\n",
        "print(f\"Imputed data shape: {X_imputed_df.shape}\")\n",
        "\n",
        "# ========================\n",
        "# 7. Remove Constant Features\n",
        "# ========================\n",
        "print(\"\\nðŸ” Removing constant features...\")\n",
        "variances = X_imputed_df.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed_df = X_imputed_df.loc[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"  Removed {dropped_count} constant features.\")\n",
        "else:\n",
        "    print(\"  No constant features found.\")\n",
        "\n",
        "# ========================\n",
        "# 8. Final Output for INFUSE\n",
        "# ========================\n",
        "# Use raw, imputed, unscaled data â€” INFUSE will handle scaling\n",
        "X = X_imputed_df.values\n",
        "feature_names = X_imputed_df.columns.tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X (for INFUSE): shape {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: shape {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   Feature names: {len(feature_names)} genes\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")\n",
        "\n",
        "# Optional: Save encoder and imputer\n",
        "# import joblib\n",
        "# joblib.dump(le, 'label_encoder.pkl')\n",
        "# joblib.dump(imputer, 'imputer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKuOLjR8aqSs",
        "outputId": "aaf298e4-88b1-460c-ef95-7050acc35695"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "\n",
            "ðŸ”§ Standardizing sample IDs (first 15 characters)...\n",
            "Found 1216 common samples.\n",
            "\n",
            "ðŸ” Extracting label: 'vital_status.demographic'\n",
            "âš ï¸  Dropping 1 samples with invalid/unknown labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values in Expression Data ---\n",
            "Initial: NaN=0, Inf=0\n",
            "âœ… Median imputation applied.\n",
            "Imputed data shape: (1215, 20530)\n",
            "\n",
            "ðŸ” Removing constant features...\n",
            "  Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X (for INFUSE): shape (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: shape (1215,), classes: 2\n",
            "   Feature names: 20252 genes\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.1,\n",
        "    beta=0.1,\n",
        "    jsd_threshold=0.35,\n",
        "    #final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.5,  # Keep â‰¥0.5\n",
        "    max_features=1000,\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "\n",
        "print(f\"Final shape: {Z_final.shape}\")\n",
        "infuse.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "m8FqJL5OaqYu",
        "outputId": "611e9ebd-2ce8-478e-ce64-0f578daf3951"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Pre-filtering 20252 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "   JSD between seeds:\n",
            "           KLF10   APOB   ADH4   UBTF  CRHR2  LOC729467  CLEC4M  SAMD1\n",
            "KLF10      0.000  0.416  0.427  0.500  0.438      0.580   0.696  0.523\n",
            "APOB       0.416  0.000  0.411  0.564  0.438      0.567   0.692  0.578\n",
            "ADH4       0.427  0.411  0.000  0.572  0.487      0.571   0.703  0.586\n",
            "UBTF       0.500  0.564  0.572  0.000  0.537      0.699   0.721  0.369\n",
            "CRHR2      0.438  0.438  0.487  0.537  0.000      0.582   0.713  0.544\n",
            "LOC729467  0.580  0.567  0.571  0.699  0.582      0.000   0.754  0.703\n",
            "CLEC4M     0.696  0.692  0.703  0.721  0.713      0.754   0.000  0.726\n",
            "SAMD1      0.523  0.578  0.586  0.369  0.544      0.703   0.726  0.000\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 2)\n",
            "Final shape: (1215, 2)\n",
            "\n",
            "ðŸ” INFUSE Cohort Descriptions:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.255\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1 ...\n",
            "\n",
            "Cohort 1 | Seed: CLEC4M | Stability: 0.244\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cohort_id seed_gene  num_members  \\\n",
              "0          0     KLF10            6   \n",
              "1          1    CLEC4M            6   \n",
              "\n",
              "                                       member_genes  stability  \n",
              "0     [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.255091  \n",
              "1  [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.243946  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0157bed1-585a-4fc4-9e9d-475f10516cc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohort_id</th>\n",
              "      <th>seed_gene</th>\n",
              "      <th>num_members</th>\n",
              "      <th>member_genes</th>\n",
              "      <th>stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLF10</td>\n",
              "      <td>6</td>\n",
              "      <td>[DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]</td>\n",
              "      <td>0.255091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CLEC4M</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]</td>\n",
              "      <td>0.243946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0157bed1-585a-4fc4-9e9d-475f10516cc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0157bed1-585a-4fc4-9e9d-475f10516cc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0157bed1-585a-4fc4-9e9d-475f10516cc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3a55cc79-188a-4628-a1e6-4e6f409dd8e8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a55cc79-188a-4628-a1e6-4e6f409dd8e8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3a55cc79-188a-4628-a1e6-4e6f409dd8e8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"infuse\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cohort_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CLEC4M\",\n          \"KLF10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_members\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"member_genes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007880803201757412,\n        \"min\": 0.24394578024415892,\n        \"max\": 0.25509091901447756,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.24394578024415892\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "\n",
        "# Run all experiments\n",
        "results = {}\n",
        "\n",
        "for exp_name, use_pr_auc, use_stratify in [\n",
        "    (\"Baseline (ROC-AUC)\", False, False),\n",
        "    (\"PR-AUC Only\", True, False),\n",
        "    (\"Stratified Only\", False, True),\n",
        "    (\"PR-AUC + Stratified\", True, True)\n",
        "]:\n",
        "    print(f\"\\nðŸ§ª Running: {exp_name}\")\n",
        "\n",
        "    # Create a fresh INFUSE instance\n",
        "    infuse = INFUSE(\n",
        "        k_seeds=20,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        jsd_threshold=0.35,\n",
        "        final_k=2,\n",
        "        n_bootstrap=100,\n",
        "        stability_thresh=0.5,\n",
        "        max_features=1000,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Monkey-patch _final_filter dynamically\n",
        "    def make_final_filter(use_pr_auc, use_stratify):\n",
        "        def _final_filter(Z, y):\n",
        "            stabilities = []\n",
        "            rng = infuse.random_state\n",
        "\n",
        "            for i in range(Z.shape[1]):\n",
        "                scores = []\n",
        "                for _ in range(infuse.n_bootstrap):\n",
        "                    # Resampling\n",
        "                    kwargs = {'random_state': rng.randint(0, 10000)}\n",
        "                    if use_stratify:\n",
        "                        kwargs['stratify'] = y\n",
        "                    Zb, yb = resample(Z, y, **kwargs)\n",
        "\n",
        "                    if len(np.unique(yb)) < 2:\n",
        "                        scores.append(0.5)\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                        clf.fit(Zb[:, [i]], yb)\n",
        "                        proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                        # Score type\n",
        "                        if use_pr_auc:\n",
        "                            score = average_precision_score(yb, proba)\n",
        "                        else:\n",
        "                            score = roc_auc_score(yb, proba)\n",
        "\n",
        "                        scores.append(score if np.isfinite(score) else 0.5)\n",
        "                    except Exception:\n",
        "                        scores.append(0.5)\n",
        "\n",
        "                S_j = np.mean(scores) if scores else 0.5\n",
        "                stabilities.append(S_j)\n",
        "\n",
        "            kept = [i for i, s in enumerate(stabilities) if s >= infuse.stability_thresh]\n",
        "            if not kept:\n",
        "                top_k = min(infuse.final_k, len(stabilities))\n",
        "                kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "\n",
        "            Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "            return Z_final, kept, stabilities\n",
        "        return _final_filter\n",
        "\n",
        "    # Inject the dynamic _final_filter\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    infuse._final_filter = make_final_filter(use_pr_auc, use_stratify).__get__(infuse, INFUSE)\n",
        "\n",
        "    # Run\n",
        "    Z_final_exp = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "    mean_stab = np.mean(infuse.stabilities_) if infuse.stabilities_ else 0.0\n",
        "    results[exp_name] = {\n",
        "        'stabilities': deepcopy(infuse.stabilities_),\n",
        "        'mean_stability': mean_stab,\n",
        "        'n_cohorts': Z_final_exp.shape[1],\n",
        "        'kept_indices': deepcopy(infuse.kept_indices_)\n",
        "    }\n",
        "\n",
        "    print(f\"   Mean Stability: {mean_stab:.4f}, Cohorts Kept: {Z_final_exp.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "MJ6tjfE7aqfN",
        "outputId": "a2d67394-c84d-4e03-a44f-d3b6464cfc57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§ª Running: Baseline (ROC-AUC)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "make_final_filter.<locals>._final_filter() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3338392906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mZ_final_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mmean_stab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstabilities_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minfuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstabilities_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     results[exp_name] = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3936938780.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Step 7: Final filtering by bootstrap AUC-ROC stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mZ_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Final filtering completed: {Z_final.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: make_final_filter.<locals>._final_filter() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSXRWpL5l_Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nL7wHXuil_Z8",
        "outputId": "68e4be7d-7309-4a57-dd08-807a50915096"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "0cddc6fe3f1d4bb8aa78f7d595cc75ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1jORl4nnO9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdPZhcrSnPET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUp_cqK4nPLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** The Fully Robust INFUSE Transformer**"
      ],
      "metadata": {
        "id": "R6cb_CWbmG97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scikit-learn-1.7.1\n",
        "\n",
        "\n",
        "# --- 1. Data Loading & Preprocessing (No Scaling) ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "\n",
        "# ========================\n",
        "# 1. Load Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Standardize Sample IDs\n",
        "# ========================\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# ========================\n",
        "# 3. Find Common Samples\n",
        "# ========================\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# ========================\n",
        "# 4. Extract and Clean Labels\n",
        "# ========================\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
        "\n",
        "# ========================\n",
        "# 5. Handle Missing Values\n",
        "# ========================\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# ========================\n",
        "# 6. Remove Constant Features\n",
        "# ========================\n",
        "variances = X_imputed.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed = X_imputed[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"ðŸ” Removed {dropped_count} constant features.\")\n",
        "\n",
        "# ========================\n",
        "# 7. Final Output\n",
        "# ========================\n",
        "X = X_imputed\n",
        "feature_names = X_df.columns[non_constant_mask].tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sjMS4Hdl_oy",
        "outputId": "7a669e6f-d7e0-4e0a-c549-83ce9334312d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values ---\n",
            "âœ… Median imputation applied.\n",
            "ðŸ” Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: (1215,), classes: 2\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: infuse_final.py\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "# DATE: [Current Date]\n",
        "# VERSION: 6.0 (Final: Undeniably Robust, ICML-Ready)\n",
        "#\n",
        "# DESCRIPTION:\n",
        "# INFUSE (Integrative Neighborhood Feature Selection Using Stability Evaluation)\n",
        "# constructs stable, interpretable cohort features from high-dimensional biological data.\n",
        "# This version is hardened for robustness, reproducibility, and publication.\n",
        "#\n",
        "# DEPENDENCIES:\n",
        "# - numpy>=1.20.0\n",
        "# - pandas>=1.3.0\n",
        "# - scikit-learn>=1.7.1\n",
        "# - scipy>=1.7.0\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Corrected import path for SimpleImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "import warnings\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, imputation_strategy='median',\n",
        "                 use_pr_auc=True, verbose=True, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap score for a cohort to be retained.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        imputation_strategy : str, default='median'\n",
        "            Strategy for imputing missing values ('mean', 'median', 'most_frequent').\n",
        "        use_pr_auc : bool, default=True\n",
        "            Whether to use PR-AUC (better for imbalance) or ROC-AUC for stability.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        \"\"\"\n",
        "        # Validate parameters\n",
        "        assert 0 <= alpha <= 1, \"alpha must be in [0, 1]\"\n",
        "        assert 0 <= beta <= 1, \"beta must be in [0, 1]\"\n",
        "        assert stability_thresh >= 0.0, \"stability_thresh must be >= 0\"\n",
        "        assert final_k >= 0, \"final_k must be >= 0\"\n",
        "\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.imputation_strategy = imputation_strategy\n",
        "        self.use_pr_auc = use_pr_auc\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "\n",
        "        # Internal components\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.imputer_ = SimpleImputer(strategy=imputation_strategy)\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Fitted transformer.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit INFUSE and return the transformed data matrix of stable cohort features.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            Transformed data with only stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- 1. Input Validation ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # --- 2. Feature Names ---\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            assert len(feature_names) == X.shape[1], \"feature_names length mismatch\"\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # --- 3. Remove Constant Features ---\n",
        "        non_constant_mask = (X.var(axis=0) > 1e-8)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        # --- 4. Handle Missing Values ---\n",
        "        if np.isnan(X).any() or np.isinf(X).any():\n",
        "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            X = self.imputer_.fit_transform(X)\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Imputed missing values using '{self.imputation_strategy}' strategy.\")\n",
        "\n",
        "        # --- 5. Pre-filter by F-score ---\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores, nan=0.0)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # --- 6. Scale ---\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # --- 7. Seed Selection ---\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # --- 8. Diversity Filtering ---\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if not seed_names_filtered:\n",
        "            raise ValueError(\"No diverse seeds found. Try lowering jsd_threshold.\")\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Log JSD matrix if verbose\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        # --- 9. Similarity & Weights ---\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- 10. Graph & Fusion ---\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # --- 11. Stability Evaluation ---\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Warn if stability is borderline\n",
        "        if stabilities and self.verbose:\n",
        "            above_thresh = [s for s in stabilities if s >= self.stability_thresh]\n",
        "            if above_thresh:\n",
        "                avg_stab = np.mean(above_thresh)\n",
        "                if avg_stab < 0.6:\n",
        "                    warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking label quality.\")\n",
        "\n",
        "        # --- 12. Save & Return ---\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using PR-AUC or ROC-AUC.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            scores = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                # Stratified resampling\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    scores.append(0.5)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    # Use PR-AUC for imbalance\n",
        "                    if self.use_pr_auc:\n",
        "                        score = average_precision_score(yb, y_proba)\n",
        "                    else:\n",
        "                        score = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                    scores.append(score if np.isfinite(score) else 0.5)\n",
        "                except Exception:\n",
        "                    scores.append(0.5)\n",
        "\n",
        "            S_j = np.mean(scores) if scores else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # Filtering logic\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept and stabilities:\n",
        "            # Fallback: keep top final_k\n",
        "            top_k = min(self.final_k, len(stabilities))\n",
        "            kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ No cohorts met threshold. Keeping top {len(kept)} by stability.\")\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        # Apply imputation and scaling\n",
        "        X = np.nan_to_num(X)\n",
        "        X = self.imputer_.transform(X)\n",
        "        X = self.scaler_.transform(X)\n",
        "\n",
        "        # Recompute graph and fuse\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        return Z_fused[:, self.kept_indices_] if self.kept_indices_ else np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_members']) > top_n else \"\" # Corrected 'member_genes' to 'member_members'\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "xIqQ8QU0l_gY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. INFUSE Execution ---\n",
        "from infuse_final import INFUSE\n",
        "\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    jsd_threshold=0.35,\n",
        "    final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.3,  # Lower for PR-AUC\n",
        "    max_features=1000,\n",
        "    imputation_strategy='median',\n",
        "    use_pr_auc=True,       # Use PR-AUC\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "print(f\"Final shape: {Z_final.shape}\")\n",
        "infuse.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RPlIdEPfl_vX",
        "outputId": "d4673e0c-d8d8-453c-ad28-80aa5da7d67b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'infuse_final'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3382753640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- 2. INFUSE Execution ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minfuse_final\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINFUSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m infuse = INFUSE(\n\u001b[1;32m      5\u001b[0m     \u001b[0mk_seeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'infuse_final'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffemGs9yl_1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2FpVU8Xq7i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulCKVyzwq7p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scikit-learn-1.7.1\n",
        "\n",
        "\n",
        "# --- 1. Data Loading & Preprocessing (No Scaling) ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "\n",
        "# ========================\n",
        "# 1. Load Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Standardize Sample IDs\n",
        "# ========================\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# ========================\n",
        "# 3. Find Common Samples\n",
        "# ========================\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# ========================\n",
        "# 4. Extract and Clean Labels\n",
        "# ========================\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
        "\n",
        "# ========================\n",
        "# 5. Handle Missing Values\n",
        "# ========================\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# ========================\n",
        "# 6. Remove Constant Features\n",
        "# ========================\n",
        "variances = X_imputed.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed = X_imputed[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"ðŸ” Removed {dropped_count} constant features.\")\n",
        "\n",
        "# ========================\n",
        "# 7. Final Output\n",
        "# ========================\n",
        "X = X_imputed\n",
        "feature_names = X_df.columns[non_constant_mask].tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqMymnlEq7xj",
        "outputId": "52bc7734-32d3-437d-f9bb-32a38480dc4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values ---\n",
            "âœ… Median imputation applied.\n",
            "ðŸ” Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: (1215,), classes: 2\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1\n",
        "# FILE: INFUSE - In-Notebook Definition for Colab\n",
        "# VERSION: 6.0 (Final: Undeniably Robust, ICML-Ready)\n",
        "# AUTHOR: [Your Name/Organization]\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "import warnings\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.3,\n",
        "                 max_features=1000, imputation_strategy='median',\n",
        "                 use_pr_auc=True, verbose=True,\n",
        "                 stability_metric='pr_auc', random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap score for a cohort to be retained.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        imputation_strategy : str, default='median'\n",
        "            Strategy for imputing missing values ('mean', 'median', 'most_frequent').\n",
        "        use_pr_auc : bool, default=True\n",
        "            Whether to use PR-AUC (better for imbalance) or ROC-AUC for stability.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        stability_metric : str, default='pr_auc'\n",
        "            The metric used to evaluate cohort stability.\n",
        "            Options: 'pr_auc' (Precision-Recall AUC), 'roc_auc' (ROC AUC).\n",
        "        \"\"\"\n",
        "        # Validate parameters\n",
        "        assert 0 <= alpha <= 1, \"alpha must be in [0, 1]\"\n",
        "        assert 0 <= beta <= 1, \"beta must be in [0, 1]\"\n",
        "        assert stability_thresh >= 0.0, \"stability_thresh must be >= 0\"\n",
        "        assert final_k >= 0, \"final_k must be >= 0\"\n",
        "\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_metric = stability_metric\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.imputation_strategy = imputation_strategy\n",
        "        self.use_pr_auc = use_pr_auc\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "\n",
        "        # Internal components\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.imputer_ = SimpleImputer(strategy=imputation_strategy)\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit the INFUSE transformer to X and y.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Fitted transformer.\n",
        "        \"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Fit INFUSE and return the transformed data matrix of stable cohort features.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values.\n",
        "        feature_names : list of str, optional\n",
        "            Names for the input features.\n",
        "        Returns\n",
        "        -------\n",
        "        Z_final : ndarray of shape (n_samples, k'')\n",
        "            Transformed data with only stable cohort features.\n",
        "        \"\"\"\n",
        "        # --- 1. Input Validation ---\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # --- 2. Feature Names ---\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            assert len(feature_names) == X.shape[1], \"feature_names length mismatch\"\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # --- 3. Remove Constant Features ---\n",
        "        non_constant_mask = (X.var(axis=0) > 1e-8)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        # --- 4. Handle Missing Values ---\n",
        "        if np.isnan(X).any() or np.isinf(X).any():\n",
        "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            X = self.imputer_.fit_transform(X)\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Imputed missing values using '{self.imputation_strategy}' strategy.\")\n",
        "\n",
        "        # --- 5. Pre-filter by F-score ---\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores, nan=0.0)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # --- 6. Scale ---\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # --- 7. Seed Selection ---\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # --- 8. Diversity Filtering ---\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if not seed_names_filtered:\n",
        "            raise ValueError(\"No diverse seeds found. Try lowering jsd_threshold.\")\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Log JSD matrix if verbose\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        # --- 9. Similarity & Weights ---\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # --- 10. Graph & Fusion ---\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # --- 11. Stability Evaluation ---\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Warn if stability is borderline\n",
        "        if stabilities and self.verbose:\n",
        "            above_thresh = [s for s in stabilities if s >= self.stability_thresh]\n",
        "            if above_thresh:\n",
        "                avg_stab = np.mean(above_thresh)\n",
        "                if avg_stab < 0.6:\n",
        "                    warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking label quality.\")\n",
        "\n",
        "        # --- 12. Save & Return ---\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using PR-AUC or ROC-AUC.\n",
        "        \"\"\"\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            scores = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                # Stratified resampling\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    scores.append(0.5)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    # Use PR-AUC for imbalance\n",
        "                    if self.use_pr_auc:\n",
        "                        score = average_precision_score(yb, y_proba)\n",
        "                    else:\n",
        "                        score = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                    scores.append(score if np.isfinite(score) else 0.5)\n",
        "                except Exception:\n",
        "                    scores.append(0.5)\n",
        "\n",
        "            S_j = np.mean(scores) if scores else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # Filtering logic\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept and stabilities:\n",
        "            # Fallback: keep top final_k\n",
        "            top_k = min(self.final_k, len(stabilities))\n",
        "            kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ No cohorts met threshold. Keeping top {len(kept)} by stability.\")\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        # Apply imputation and scaling\n",
        "        X = np.nan_to_num(X)\n",
        "        X = self.imputer_.transform(X)\n",
        "        X = self.scaler_.transform(X)\n",
        "\n",
        "        # Recompute graph and fuse\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        return Z_fused[:, self.kept_indices_] if self.kept_indices_ else np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "J0PBGaJTl_8P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCystrBezqmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SdhswErkzsJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL FINAL FINAL"
      ],
      "metadata": {
        "id": "CoHv1ujhzv7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scikit-learn-1.7.1\n",
        "\n",
        "\n",
        "# --- 1. Data Loading & Preprocessing (No Scaling) ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "expression_file = \"/content/HiSeqV2\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "\n",
        "# ========================\n",
        "# 1. Load Data\n",
        "# ========================\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "\n",
        "# ========================\n",
        "# 2. Standardize Sample IDs\n",
        "# ========================\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "# ========================\n",
        "# 3. Find Common Samples\n",
        "# ========================\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "# ========================\n",
        "# 4. Extract and Clean Labels\n",
        "# ========================\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
        "\n",
        "# ========================\n",
        "# 5. Handle Missing Values\n",
        "# ========================\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "# ========================\n",
        "# 6. Remove Constant Features\n",
        "# ========================\n",
        "variances = X_imputed.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed = X_imputed[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"ðŸ” Removed {dropped_count} constant features.\")\n",
        "\n",
        "# ========================\n",
        "# 7. Final Output\n",
        "# ========================\n",
        "X = X_imputed\n",
        "feature_names = X_df.columns[non_constant_mask].tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIQSffiBzsRj",
        "outputId": "6c47f77e-4fbc-4403-cc87-350baadfbecc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values ---\n",
            "âœ… Median imputation applied.\n",
            "ðŸ” Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: (1215,), classes: 2\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL: Define INFUSE Class (Run this first)\n",
        "# This cell includes all necessary imports and the full INFUSE class definition.\n",
        "\n",
        "# --- 1. Import All Dependencies ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "import warnings\n",
        "\n",
        "# --- 2. Define the INFUSE Class ---\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    INFUSE: Integrative Neighborhood Feature Selection Using Stability Evaluation.\n",
        "    A transformer that constructs new, stable, and potentially interpretable\n",
        "    cohort features from high-dimensional data by integrating diversity,\n",
        "    multi-criteria association, locality, and empirical stability.\n",
        "    \"\"\"\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, imputation_strategy='median',\n",
        "                 use_pr_auc=True, stability_metric='pr_auc', verbose=True, random_state=42):\n",
        "        \"\"\"\n",
        "        Initialize the INFUSE transformer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        k_seeds : int, default=20\n",
        "            Number of initial seed candidates based on F-scores.\n",
        "        alpha : float, default=0.6\n",
        "            Weight for the cosine similarity component in hybrid weighting.\n",
        "        beta : float, default=0.2\n",
        "            Weight for the JSD dissimilarity penalty in hybrid weighting.\n",
        "        jsd_threshold : float, default=0.35\n",
        "            Minimum JSD dissimilarity required between seed candidates.\n",
        "        final_k : int, default=2\n",
        "            Number of top cohorts to keep if none meet stability_thresh.\n",
        "        n_bootstrap : int, default=100\n",
        "            Number of bootstrap iterations for stability evaluation.\n",
        "        stability_thresh : float, default=0.5\n",
        "            Minimum average bootstrap score for a cohort to be retained.\n",
        "        max_features : int, default=1000\n",
        "            Pre-filter input to this many top F-score features before processing.\n",
        "        imputation_strategy : str, default='median'\n",
        "            Strategy for imputing missing values ('mean', 'median', 'most_frequent').\n",
        "        use_pr_auc : bool, default=True\n",
        "            (Deprecated) Use `stability_metric` instead.\n",
        "        stability_metric : str, default='pr_auc'\n",
        "            The metric used for stability evaluation: 'pr_auc' or 'roc_auc'.\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress messages.\n",
        "        random_state : int or RandomState instance, default=42\n",
        "            Controls randomness for bootstrapping and model fitting.\n",
        "        \"\"\"\n",
        "        # Validate parameters\n",
        "        assert 0 <= alpha <= 1, \"alpha must be in [0, 1]\"\n",
        "        assert 0 <= beta <= 1, \"beta must be in [0, 1]\"\n",
        "        assert stability_thresh >= 0.0, \"stability_thresh must be >= 0\"\n",
        "        assert final_k >= 0, \"final_k must be >= 0\"\n",
        "        assert stability_metric in ['pr_auc', 'roc_auc'], \"stability_metric must be 'pr_auc' or 'roc_auc'\"\n",
        "\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.imputation_strategy = imputation_strategy\n",
        "        self.stability_metric = stability_metric  # New tunable parameter\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "\n",
        "        # Internal components\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.imputer_ = SimpleImputer(strategy=imputation_strategy)\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"Fit the INFUSE transformer.\"\"\"\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        \"\"\"Fit INFUSE and return transformed data.\"\"\"\n",
        "        # Input validation\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        # Feature names\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            assert len(feature_names) == X.shape[1], \"feature_names length mismatch\"\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        # Remove constant features\n",
        "        non_constant_mask = (X.var(axis=0) > 1e-8)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        # Handle missing values\n",
        "        if np.isnan(X).any() or np.isinf(X).any():\n",
        "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            X = self.imputer_.fit_transform(X)\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Imputed missing values using '{self.imputation_strategy}' strategy.\")\n",
        "\n",
        "        # Pre-filter by F-score\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores, nan=0.0)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        # Scale\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        # Seed selection\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        # Diversity filtering\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if not seed_names_filtered:\n",
        "            raise ValueError(\"No diverse seeds found. Try lowering jsd_threshold.\")\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        # Log JSD matrix\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        # Similarity & weights\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        # Graph & fusion\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        # Stability evaluation\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        # Warn if stability is borderline\n",
        "        if stabilities and self.verbose:\n",
        "            above_thresh = [s for s in stabilities if s >= self.stability_thresh]\n",
        "            if above_thresh:\n",
        "                avg_stab = np.mean(above_thresh)\n",
        "                if avg_stab < 0.6:\n",
        "                    warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking label quality.\")\n",
        "\n",
        "        # Save fitted attributes\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        \"\"\"Filter seeds for diversity using JSD on softmax-normalized expression profiles.\"\"\"\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        \"\"\"Compute hybrid weights: Î±Â·sim + (1-Î±)Â·F-score - Î²Â·JSD.\"\"\"\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        \"\"\"Build k-NN graph over features using cosine distance.\"\"\"\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        \"\"\"Fuse features in each seed's neighborhood into a cohort.\"\"\"\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        \"\"\"\n",
        "        Evaluate cohort stability via bootstrapping using PR-AUC or ROC-AUC.\n",
        "        \"\"\"\n",
        "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            scores = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                # Stratified resampling\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    # Use no-skill baseline\n",
        "                    baseline = np.mean(y) if self.stability_metric == 'pr_auc' else 0.5\n",
        "                    scores.append(baseline)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    if self.stability_metric == 'pr_auc':\n",
        "                        score = average_precision_score(yb, y_proba)\n",
        "                    else:  # 'roc_auc'\n",
        "                        score = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                    scores.append(score if np.isfinite(score) else 0.5)\n",
        "                except Exception:\n",
        "                    scores.append(0.5)\n",
        "\n",
        "            S_j = np.mean(scores) if scores else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        # Filtering logic\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept and stabilities:\n",
        "            # Fallback: keep top final_k\n",
        "            top_k = min(self.final_k, len(stabilities))\n",
        "            kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ No cohorts met threshold. Keeping top {len(kept)} by stability.\")\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform new data using fitted INFUSE model.\"\"\"\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        # Apply imputation and scaling\n",
        "        X = np.nan_to_num(X)\n",
        "        X = self.imputer_.transform(X)\n",
        "        X = self.scaler_.transform(X)\n",
        "\n",
        "        # Recompute graph and fuse\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "\n",
        "        return Z_fused[:, self.kept_indices_] if self.kept_indices_ else np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"Return output feature names.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        \"\"\"Return a DataFrame summarizing the selected cohorts.\"\"\"\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        \"\"\"Print a readable summary of the selected cohorts.\"\"\"\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "mC75UkEwzFA3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: INFUSE Execution\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" RUNNING INFUSE - FEATURE CONSTRUCTION & STABILITY FILTERING \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ensure scikit-learn is up to date\n",
        "#!pip install --upgrade scikit-learn\n",
        "\n",
        "# Create and fit INFUSE\n",
        "infuse = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    jsd_threshold=0.35,\n",
        "    #final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.2,  # Lower for PR-AUC\n",
        "    max_features=1000,\n",
        "    imputation_strategy='median',\n",
        "    use_pr_auc=True,       # Use PR-AUC for imbalance\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit and transform\n",
        "Z_final = infuse.fit_transform(X, y, feature_names=feature_names)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nâœ… Final shape: {Z_final.shape}\")\n",
        "infuse.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I2iYgQe5mADF",
        "outputId": "d17a8827-d405-4777-db4c-7576e04c9536"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " RUNNING INFUSE - FEATURE CONSTRUCTION & STABILITY FILTERING \n",
            "============================================================\n",
            "ðŸ” Pre-filtering 20252 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "   JSD between seeds:\n",
            "           KLF10   APOB   ADH4   UBTF  CRHR2  LOC729467  CLEC4M  SAMD1\n",
            "KLF10      0.000  0.416  0.427  0.500  0.438      0.580   0.696  0.523\n",
            "APOB       0.416  0.000  0.411  0.564  0.438      0.567   0.692  0.578\n",
            "ADH4       0.427  0.411  0.000  0.572  0.487      0.571   0.703  0.586\n",
            "UBTF       0.500  0.564  0.572  0.000  0.537      0.699   0.721  0.369\n",
            "CRHR2      0.438  0.438  0.487  0.537  0.000      0.582   0.713  0.544\n",
            "LOC729467  0.580  0.567  0.571  0.699  0.582      0.000   0.754  0.703\n",
            "CLEC4M     0.696  0.692  0.703  0.721  0.713      0.754   0.000  0.726\n",
            "SAMD1      0.523  0.578  0.586  0.369  0.544      0.703   0.726  0.000\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "\n",
            "âœ… Final shape: (1215, 8)\n",
            "\n",
            "ðŸ” INFUSE Cohort Descriptions:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.262\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1 ...\n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.239\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392 ...\n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.241\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1 ...\n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.220\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446 ...\n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.223\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP ...\n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.236\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B ...\n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.245\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182 ...\n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.242\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1 ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cohort_id  seed_gene  num_members  \\\n",
              "0          0      KLF10            6   \n",
              "1          1       APOB            6   \n",
              "2          2       ADH4            6   \n",
              "3          3       UBTF            6   \n",
              "4          4      CRHR2            6   \n",
              "5          5  LOC729467            6   \n",
              "6          6     CLEC4M            6   \n",
              "7          7      SAMD1            6   \n",
              "\n",
              "                                        member_genes  stability  \n",
              "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.261560  \n",
              "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.238860  \n",
              "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.241147  \n",
              "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.220370  \n",
              "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.223461  \n",
              "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.236223  \n",
              "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.244707  \n",
              "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.242176  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e11f082-7ef9-4673-a777-862473bd0889\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohort_id</th>\n",
              "      <th>seed_gene</th>\n",
              "      <th>num_members</th>\n",
              "      <th>member_genes</th>\n",
              "      <th>stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLF10</td>\n",
              "      <td>6</td>\n",
              "      <td>[DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]</td>\n",
              "      <td>0.261560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>APOB</td>\n",
              "      <td>6</td>\n",
              "      <td>[GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]</td>\n",
              "      <td>0.238860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ADH4</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]</td>\n",
              "      <td>0.241147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>UBTF</td>\n",
              "      <td>6</td>\n",
              "      <td>[WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]</td>\n",
              "      <td>0.220370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CRHR2</td>\n",
              "      <td>6</td>\n",
              "      <td>[FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]</td>\n",
              "      <td>0.223461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LOC729467</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]</td>\n",
              "      <td>0.236223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>CLEC4M</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]</td>\n",
              "      <td>0.244707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>SAMD1</td>\n",
              "      <td>6</td>\n",
              "      <td>[C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]</td>\n",
              "      <td>0.242176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e11f082-7ef9-4673-a777-862473bd0889')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e11f082-7ef9-4673-a777-862473bd0889 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e11f082-7ef9-4673-a777-862473bd0889');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ec7e8ed1-219c-43c6-aed7-22ca72c3075d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec7e8ed1-219c-43c6-aed7-22ca72c3075d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ec7e8ed1-219c-43c6-aed7-22ca72c3075d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"infuse\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"cohort_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"APOB\",\n          \"LOC729467\",\n          \"KLF10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_members\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"member_genes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012822945763403305,\n        \"min\": 0.22036966062459787,\n        \"max\": 0.26156049456494157,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.23886016320611017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZWX3tgfmAJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarking Experiments"
      ],
      "metadata": {
        "id": "d43YXUAaFK8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FULL BENCHMARKING EXPERIMENT: INFUSE vs. OTHER FEATURE METHODS ---\n",
        "# This script compares the downstream classification performance of\n",
        "# INFUSE cohort features against 7 standard feature selection/extraction methods.\n",
        "# It uses the exact preprocessing and INFUSE implementation from your pipeline.\n",
        "\n",
        "# --- 1. Import All Dependencies ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "print(\"âœ… All dependencies loaded.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHR0ch3oFPXI",
        "outputId": "e8789524-87a8-4070-ab9a-1cdaa266547a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All dependencies loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Paste the FULL INFUSE CLASS HERE (From your latest version) ---\n",
        "# This ensures the benchmark uses the exact same INFUSE you've developed.\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, imputation_strategy='median',\n",
        "                 stability_metric='pr_auc', verbose=True, random_state=42):\n",
        "        assert 0 <= alpha <= 1, \"alpha must be in [0, 1]\"\n",
        "        assert 0 <= beta <= 1, \"beta must be in [0, 1]\"\n",
        "        assert stability_thresh >= 0.0, \"stability_thresh must be >= 0\"\n",
        "        assert final_k >= 0, \"final_k must be >= 0\"\n",
        "        assert stability_metric in ['pr_auc', 'roc_auc'], \"stability_metric must be 'pr_auc' or 'roc_auc'\"\n",
        "\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.imputation_strategy = imputation_strategy\n",
        "        self.stability_metric = stability_metric\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.imputer_ = SimpleImputer(strategy=imputation_strategy)\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            assert len(feature_names) == X.shape[1], \"feature_names length mismatch\"\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        non_constant_mask = (X.var(axis=0) > 1e-8)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        if np.isnan(X).any() or np.isinf(X).any():\n",
        "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            X = self.imputer_.fit_transform(X)\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Imputed missing values using '{self.imputation_strategy}' strategy.\")\n",
        "\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores, nan=0.0)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if not seed_names_filtered:\n",
        "            raise ValueError(\"No diverse seeds found. Try lowering jsd_threshold.\")\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        if stabilities and self.verbose:\n",
        "            above_thresh = [s for s in stabilities if s >= self.stability_thresh]\n",
        "            if above_thresh:\n",
        "                avg_stab = np.mean(above_thresh)\n",
        "                if avg_stab < 0.6:\n",
        "                    warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking label quality.\")\n",
        "\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            scores = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    baseline = np.mean(y) if self.stability_metric == 'pr_auc' else 0.5\n",
        "                    scores.append(baseline)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    if self.stability_metric == 'pr_auc':\n",
        "                        score = average_precision_score(yb, y_proba)\n",
        "                    else:\n",
        "                        score = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                    scores.append(score if np.isfinite(score) else 0.5)\n",
        "                except Exception:\n",
        "                    scores.append(0.5)\n",
        "\n",
        "            S_j = np.mean(scores) if scores else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept and stabilities:\n",
        "            top_k = min(self.final_k, len(stabilities))\n",
        "            kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ No cohorts met threshold. Keeping top {len(kept)} by stability.\")\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        X = np.nan_to_num(X)\n",
        "        X = self.imputer_.transform(X)\n",
        "        X = self.scaler_.transform(X)\n",
        "\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        return Z_fused[:, self.kept_indices_] if self.kept_indices_ else np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df\n",
        "\n",
        "print(\"âœ… INFUSE class defined.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD1sFBL2FPho",
        "outputId": "c39aa786-a775-433d-d805-403f0565e839"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… INFUSE class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Preprocessing Code ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rng = check_random_state(42)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 1. RUNNING DATA PREPROCESSING \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
        "\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "variances = X_imputed.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed = X_imputed[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"ðŸ” Removed {dropped_count} constant features.\")\n",
        "\n",
        "X = X_imputed\n",
        "feature_names = X_df.columns[non_constant_mask].tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1NUDTOlF8Z_",
        "outputId": "3859a8c7-24fa-4879-9193-92f2ced08c70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 1. RUNNING DATA PREPROCESSING \n",
            "============================================================\n",
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values ---\n",
            "âœ… Median imputation applied.\n",
            "ðŸ” Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: (1215,), classes: 2\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Run INFUSE to get its features ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 2. RUNNING INFUSE \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "infuse_model = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    jsd_threshold=0.35,\n",
        "    final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.2,\n",
        "    max_features=1000,\n",
        "    imputation_strategy='median',\n",
        "    stability_metric='pr_auc',\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_infuse = infuse_model.fit_transform(X, y, feature_names=feature_names)\n",
        "print(f\"âœ… INFUSE produced {X_infuse.shape[1]} cohort features.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASX01jJqF8hy",
        "outputId": "5e3211d4-bde8-43f0-a464-2c6eb7528480"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 2. RUNNING INFUSE \n",
            "============================================================\n",
            "ðŸ” Pre-filtering 20252 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "   JSD between seeds:\n",
            "           KLF10   APOB   ADH4   UBTF  CRHR2  LOC729467  CLEC4M  SAMD1\n",
            "KLF10      0.000  0.416  0.427  0.500  0.438      0.580   0.696  0.523\n",
            "APOB       0.416  0.000  0.411  0.564  0.438      0.567   0.692  0.578\n",
            "ADH4       0.427  0.411  0.000  0.572  0.487      0.571   0.703  0.586\n",
            "UBTF       0.500  0.564  0.572  0.000  0.537      0.699   0.721  0.369\n",
            "CRHR2      0.438  0.438  0.487  0.537  0.000      0.582   0.713  0.544\n",
            "LOC729467  0.580  0.567  0.571  0.699  0.582      0.000   0.754  0.703\n",
            "CLEC4M     0.696  0.692  0.703  0.721  0.713      0.754   0.000  0.726\n",
            "SAMD1      0.523  0.578  0.586  0.369  0.544      0.703   0.726  0.000\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "âœ… INFUSE produced 8 cohort features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Benchmarking Setup ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 3. RUNNING BENCHMARK \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "\n",
        "# Downstream model\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Number of components\n",
        "n_components = X_infuse.shape[1] if X_infuse.size > 0 else 8\n",
        "\n",
        "# Define all pipelines\n",
        "pipelines = {}\n",
        "\n",
        "# Method 1: Top 1000 F-score\n",
        "selector_fscore = SelectKBest(f_classif, k=1000)\n",
        "X_fscore = selector_fscore.fit_transform(X, y)\n",
        "print(f\"Top-1000 F-score features: {X_fscore.shape}\")\n",
        "pipelines['Top-1000-Fscore'] = ('data', X_fscore)\n",
        "\n",
        "# Method 2: PCA\n",
        "pca = PCA(n_components=n_components, random_state=42)\n",
        "pipelines['PCA'] = Pipeline([('scaler', StandardScaler()), ('pca', pca), ('model', downstream_model)])\n",
        "\n",
        "# Method 3: NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- NMF Pipeline ---\n",
        "pipelines['NMF'] = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),  # Only NMF uses MinMaxScaler\n",
        "    ('nmf', NMF(n_components=n_components, init='random', random_state=42, max_iter=500)),\n",
        "    ('model', downstream_model)\n",
        "])\n",
        "# Method 4: SelectKBest (k=n_components)\n",
        "select_kbest = SelectKBest(f_classif, k=n_components)\n",
        "pipelines['SelectKBest'] = Pipeline([('scaler', StandardScaler()), ('select', select_kbest), ('model', downstream_model)])\n",
        "\n",
        "# Method 5: LASSO-RFE\n",
        "lasso_selector = RFE(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
        "    n_features_to_select=n_components,\n",
        "    step=0.1\n",
        ")\n",
        "pipelines['LASSO-RFE'] = Pipeline([('scaler', StandardScaler()), ('rfe', lasso_selector), ('model', downstream_model)])\n",
        "\n",
        "# Method 6: RFE with Logistic Regression\n",
        "rfe_lr = RFE(\n",
        "    estimator=LogisticRegression(random_state=42),\n",
        "    n_features_to_select=n_components,\n",
        "    step=0.1\n",
        ")\n",
        "pipelines['RFE-LR'] = Pipeline([('scaler', StandardScaler()), ('rfe', rfe_lr), ('model', downstream_model)])\n",
        "\n",
        "# Method 7: Autoencoder (Simple)\n",
        "class AutoencoderFeatures:\n",
        "    def __init__(self, n_components, epochs=200):\n",
        "        self.n_components = n_components\n",
        "        self.epochs = epochs\n",
        "        self.scaler_ = StandardScaler()\n",
        "    def fit(self, X, y=None):\n",
        "        from tensorflow.keras.models import Model\n",
        "        from tensorflow.keras.layers import Input, Dense\n",
        "        from tensorflow.keras.optimizers import Adam\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(42)\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "        input_dim = X_scaled.shape[1]\n",
        "        encoding_dim = self.n_components\n",
        "        input_layer = Input(shape=(input_dim,))\n",
        "        encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "        decoded = Dense(input_dim, activation='linear')(encoded)\n",
        "        autoencoder = Model(input_layer, decoded)\n",
        "        encoder = Model(input_layer, encoded)\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "        autoencoder.fit(X_scaled, X_scaled, epochs=self.epochs, batch_size=16, shuffle=True, verbose=0)\n",
        "        self.encoder_ = encoder\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        return self.encoder_.predict(X_scaled)\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X)\n",
        "\n",
        "autoencoder = AutoencoderFeatures(n_components=n_components)\n",
        "X_ae = autoencoder.fit_transform(X)\n",
        "pipelines['Autoencoder'] = ('data', X_ae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hncPOoFbF8pF",
        "outputId": "414f4b77-60d8-47ff-89b7-fa277827de26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 3. RUNNING BENCHMARK \n",
            "============================================================\n",
            "Top-1000 F-score features: (1215, 1000)\n",
            "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Run Benchmark ---\n",
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(f\"\\nðŸ§ª Evaluating: {name}\")\n",
        "    if isinstance(pipeline, tuple) and pipeline[0] == 'data':\n",
        "        X_data = pipeline[1]\n",
        "        cv_results = cross_validate(\n",
        "            downstream_model, X_data, y,\n",
        "            cv=cv,\n",
        "            scoring=['roc_auc', 'average_precision'],\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    else:\n",
        "        cv_results = cross_validate(\n",
        "            pipeline, X, y,\n",
        "            cv=cv,\n",
        "            scoring=['roc_auc', 'average_precision'],\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    results[name] = {\n",
        "        'ROC-AUC': cv_results['test_roc_auc'].mean(),\n",
        "        'ROC-AUC_std': cv_results['test_roc_auc'].std(),\n",
        "        'PR-AUC': cv_results['test_average_precision'].mean(),\n",
        "        'PR-AUC_std': cv_results['test_average_precision'].std()\n",
        "    }\n",
        "    print(f\"   ROC-AUC: {results[name]['ROC-AUC']:.4f} Â± {results[name]['ROC-AUC_std']:.4f}\")\n",
        "    print(f\"   PR-AUC:  {results[name]['PR-AUC']:.4f} Â± {results[name]['PR-AUC_std']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoTm86xLF8xX",
        "outputId": "c55156e8-5262-4642-9c7e-3528c22b3b94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§ª Evaluating: Top-1000-Fscore\n",
            "   ROC-AUC: 0.6650 Â± 0.0269\n",
            "   PR-AUC:  0.3311 Â± 0.0743\n",
            "\n",
            "ðŸ§ª Evaluating: PCA\n",
            "   ROC-AUC: 0.5883 Â± 0.0488\n",
            "   PR-AUC:  0.2703 Â± 0.0330\n",
            "\n",
            "ðŸ§ª Evaluating: NMF\n",
            "   ROC-AUC: nan Â± nan\n",
            "   PR-AUC:  nan Â± nan\n",
            "\n",
            "ðŸ§ª Evaluating: SelectKBest\n",
            "   ROC-AUC: 0.6090 Â± 0.0400\n",
            "   PR-AUC:  0.3181 Â± 0.0443\n",
            "\n",
            "ðŸ§ª Evaluating: LASSO-RFE\n",
            "   ROC-AUC: 0.5627 Â± 0.0312\n",
            "   PR-AUC:  0.2371 Â± 0.0331\n",
            "\n",
            "ðŸ§ª Evaluating: RFE-LR\n",
            "   ROC-AUC: 0.5462 Â± 0.0385\n",
            "   PR-AUC:  0.2266 Â± 0.0525\n",
            "\n",
            "ðŸ§ª Evaluating: Autoencoder\n",
            "   ROC-AUC: 0.5666 Â± 0.0447\n",
            "   PR-AUC:  0.2489 Â± 0.0353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Display Results ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" FINAL BENCHMARK RESULTS \")\n",
        "print(\"=\"*60)\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "results_df['ROC-AUC'].plot(kind='barh', ax=ax[0], xerr=results_df['ROC-AUC_std'], color='skyblue', edgecolor='black')\n",
        "ax[0].set_title('ROC-AUC Comparison')\n",
        "ax[0].set_xlabel('Mean AUC')\n",
        "results_df['PR-AUC'].plot(kind='barh', ax=ax[1], xerr=results_df['PR-AUC_std'], color='teal', edgecolor='black')\n",
        "ax[1].set_title('PR-AUC Comparison')\n",
        "ax[1].set_xlabel('Mean AUC')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "H0oJUWb_F85Q",
        "outputId": "ada5e52a-4aca-4e07-a01f-e7eb19469767"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " FINAL BENCHMARK RESULTS \n",
            "============================================================\n",
            "                 ROC-AUC  ROC-AUC_std  PR-AUC  PR-AUC_std\n",
            "Top-1000-Fscore   0.6650       0.0269  0.3311      0.0743\n",
            "SelectKBest       0.6090       0.0400  0.3181      0.0443\n",
            "PCA               0.5883       0.0488  0.2703      0.0330\n",
            "Autoencoder       0.5666       0.0447  0.2489      0.0353\n",
            "LASSO-RFE         0.5627       0.0312  0.2371      0.0331\n",
            "RFE-LR            0.5462       0.0385  0.2266      0.0525\n",
            "NMF                  NaN          NaN     NaN         NaN\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Final INFUSE Summary ---\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "print(\" INFUSE COHORT SUMMARY \")\n",
        "print(\"-\"*50)\n",
        "infuse_model.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "ZFhkO-vbF9Ay",
        "outputId": "d99d95f2-7680-4720-d4cf-348e3479984a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            " INFUSE COHORT SUMMARY \n",
            "--------------------------------------------------\n",
            "\n",
            "ðŸ” INFUSE Cohort Descriptions:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.262\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1 ...\n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.239\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392 ...\n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.241\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1 ...\n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.220\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446 ...\n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.223\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP ...\n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.236\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B ...\n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.245\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182 ...\n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.242\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1 ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cohort_id  seed_gene  num_members  \\\n",
              "0          0      KLF10            6   \n",
              "1          1       APOB            6   \n",
              "2          2       ADH4            6   \n",
              "3          3       UBTF            6   \n",
              "4          4      CRHR2            6   \n",
              "5          5  LOC729467            6   \n",
              "6          6     CLEC4M            6   \n",
              "7          7      SAMD1            6   \n",
              "\n",
              "                                        member_genes  stability  \n",
              "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.261560  \n",
              "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.238860  \n",
              "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.241147  \n",
              "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.220370  \n",
              "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.223461  \n",
              "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.236223  \n",
              "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.244707  \n",
              "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.242176  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b308154-9bfe-4476-a102-08676dd41dc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohort_id</th>\n",
              "      <th>seed_gene</th>\n",
              "      <th>num_members</th>\n",
              "      <th>member_genes</th>\n",
              "      <th>stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLF10</td>\n",
              "      <td>6</td>\n",
              "      <td>[DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]</td>\n",
              "      <td>0.261560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>APOB</td>\n",
              "      <td>6</td>\n",
              "      <td>[GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]</td>\n",
              "      <td>0.238860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ADH4</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]</td>\n",
              "      <td>0.241147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>UBTF</td>\n",
              "      <td>6</td>\n",
              "      <td>[WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]</td>\n",
              "      <td>0.220370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CRHR2</td>\n",
              "      <td>6</td>\n",
              "      <td>[FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]</td>\n",
              "      <td>0.223461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LOC729467</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]</td>\n",
              "      <td>0.236223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>CLEC4M</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]</td>\n",
              "      <td>0.244707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>SAMD1</td>\n",
              "      <td>6</td>\n",
              "      <td>[C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]</td>\n",
              "      <td>0.242176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b308154-9bfe-4476-a102-08676dd41dc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b308154-9bfe-4476-a102-08676dd41dc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b308154-9bfe-4476-a102-08676dd41dc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e1af07e-798e-463b-b69e-465c6503b44a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e1af07e-798e-463b-b69e-465c6503b44a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e1af07e-798e-463b-b69e-465c6503b44a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"infuse_model\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"cohort_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"APOB\",\n          \"LOC729467\",\n          \"KLF10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_members\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"member_genes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012822945763403305,\n        \"min\": 0.22036966062459787,\n        \"max\": 0.26156049456494157,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.23886016320611017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PkSrvnInF9It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhgxrlCwOafk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Li-Do5s7Oanq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-NBW6gt-Oau_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updated"
      ],
      "metadata": {
        "id": "b2IuldFWPJ_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FULL BENCHMARKING EXPERIMENT: INFUSE vs. OTHER FEATURE METHODS ---\n",
        "# This script compares the downstream classification performance of\n",
        "# INFUSE cohort features against 7 standard feature selection/extraction methods.\n",
        "# It uses the exact preprocessing and INFUSE implementation from your pipeline.\n",
        "\n",
        "# --- 1. Import All Dependencies ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_X_y, resample, check_random_state\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "print(\"âœ… All dependencies loaded.\")\n",
        "\n",
        "# --- 2. Paste the FULL INFUSE CLASS HERE (From your latest version) ---\n",
        "# This ensures the benchmark uses the exact same INFUSE you've developed.\n",
        "\n",
        "class INFUSE(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "                 final_k=2, n_bootstrap=100, stability_thresh=0.5,\n",
        "                 max_features=1000, imputation_strategy='median',\n",
        "                 stability_metric='pr_auc', verbose=True, random_state=42):\n",
        "        assert 0 <= alpha <= 1, \"alpha must be in [0, 1]\"\n",
        "        assert 0 <= beta <= 1, \"beta must be in [0, 1]\"\n",
        "        assert stability_thresh >= 0.0, \"stability_thresh must be >= 0\"\n",
        "        assert final_k >= 0, \"final_k must be >= 0\"\n",
        "        assert stability_metric in ['pr_auc', 'roc_auc'], \"stability_metric must be 'pr_auc' or 'roc_auc'\"\n",
        "\n",
        "        self.k_seeds = k_seeds\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.jsd_threshold = jsd_threshold\n",
        "        self.final_k = final_k\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.stability_thresh = stability_thresh\n",
        "        self.max_features = max_features\n",
        "        self.imputation_strategy = imputation_strategy\n",
        "        self.stability_metric = stability_metric\n",
        "        self.verbose = verbose\n",
        "        self.random_state = check_random_state(random_state)\n",
        "\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.imputer_ = SimpleImputer(strategy=imputation_strategy)\n",
        "        self.is_fitted_ = False\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        self.fit_transform(X, y, feature_names)\n",
        "        return self\n",
        "\n",
        "    def fit_transform(self, X, y, feature_names=None):\n",
        "        X, y = check_X_y(X, y, ensure_all_finite='allow-nan', accept_sparse=False)\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            self.feature_names_in_ = list(X.columns)\n",
        "        elif feature_names is not None:\n",
        "            assert len(feature_names) == X.shape[1], \"feature_names length mismatch\"\n",
        "            self.feature_names_in_ = feature_names\n",
        "        else:\n",
        "            self.feature_names_in_ = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "        non_constant_mask = (X.var(axis=0) > 1e-8)\n",
        "        if self.verbose and not non_constant_mask.all():\n",
        "            dropped = np.sum(~non_constant_mask)\n",
        "            print(f\"ðŸ” Removing {dropped} constant features.\")\n",
        "        X = X[:, non_constant_mask]\n",
        "        self.feature_names_in_ = [name for name, keep in zip(self.feature_names_in_, non_constant_mask) if keep]\n",
        "\n",
        "        if np.isnan(X).any() or np.isinf(X).any():\n",
        "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            X = self.imputer_.fit_transform(X)\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Imputed missing values using '{self.imputation_strategy}' strategy.\")\n",
        "\n",
        "        if self.max_features and X.shape[1] > self.max_features:\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ” Pre-filtering {X.shape[1]} â†’ {self.max_features} features\")\n",
        "            scores, _ = f_classif(X, y)\n",
        "            scores = np.nan_to_num(scores, nan=0.0)\n",
        "            top_idx = np.argsort(scores)[::-1][:self.max_features]\n",
        "            X = X[:, top_idx]\n",
        "            self.feature_names_in_ = [self.feature_names_in_[i] for i in top_idx]\n",
        "\n",
        "        X = self.scaler_.fit_transform(X)\n",
        "\n",
        "        scores, _ = f_classif(X, y)\n",
        "        scores = np.nan_to_num(scores)\n",
        "        top_idx = np.argsort(scores)[::-1][:self.k_seeds]\n",
        "        seed_names_raw = [self.feature_names_in_[i] for i in top_idx]\n",
        "        self.fscores_ = {name: scores[self.feature_names_in_.index(name)] for name in seed_names_raw}\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (raw): {seed_names_raw}\")\n",
        "\n",
        "        seed_names_filtered = self._dissimilarity_filter(X, seed_names_raw)\n",
        "        if not seed_names_filtered:\n",
        "            raise ValueError(\"No diverse seeds found. Try lowering jsd_threshold.\")\n",
        "        if self.verbose:\n",
        "            print(f\" Seeds (filtered): {seed_names_filtered}\")\n",
        "\n",
        "        if self.verbose and len(seed_names_filtered) > 1:\n",
        "            X_softmax = softmax(X, axis=0)\n",
        "            seed_indices = [self.feature_names_in_.index(name) for name in seed_names_filtered]\n",
        "            jsd_mat = np.array([\n",
        "                [jensenshannon(X_softmax[:, i], X_softmax[:, j]) for j in seed_indices]\n",
        "                for i in seed_indices\n",
        "            ])\n",
        "            print(\"   JSD between seeds:\")\n",
        "            print(pd.DataFrame(jsd_mat, index=seed_names_filtered, columns=seed_names_filtered).round(3))\n",
        "\n",
        "        X_named = pd.DataFrame(X, columns=self.feature_names_in_)\n",
        "        similarities = cosine_similarity(X_named.T, X_named[seed_names_filtered].T)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Similarity matrix computed: {similarities.shape}\")\n",
        "\n",
        "        weights = self._hybrid_weights(X, seed_names_filtered, similarities)\n",
        "        if np.isnan(weights).any() or np.allclose(weights, weights.flat[0]):\n",
        "            raise ValueError(\"âŒ Weight matrix collapsed â€” check input structure.\")\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Weight matrix computed: {weights.shape}\")\n",
        "\n",
        "        graph = self._graph_regularization(X, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Graph regularization computed: {graph.shape}\")\n",
        "\n",
        "        Z, cohorts = self._cohort_fusion(X, weights, graph, seed_names_filtered)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Cohort fusion completed: {Z.shape}\")\n",
        "\n",
        "        Z_final, kept, stabilities = self._final_filter(Z, y)\n",
        "        if self.verbose:\n",
        "            print(f\"âœ… Final filtering completed: {Z_final.shape}\")\n",
        "\n",
        "        if stabilities and self.verbose:\n",
        "            above_thresh = [s for s in stabilities if s >= self.stability_thresh]\n",
        "            if above_thresh:\n",
        "                avg_stab = np.mean(above_thresh)\n",
        "                if avg_stab < 0.6:\n",
        "                    warnings.warn(\"âš ï¸ Average stability of kept cohorts is < 0.6. Consider checking label quality.\")\n",
        "\n",
        "        self.seeds_ = seed_names_filtered\n",
        "        self.cohort_weights_ = weights\n",
        "        self.cohort_members_ = cohorts\n",
        "        self.kept_indices_ = kept\n",
        "        self.stabilities_ = stabilities\n",
        "        self.is_fitted_ = True\n",
        "\n",
        "        return Z_final\n",
        "\n",
        "    def _dissimilarity_filter(self, X, seed_names):\n",
        "        seed_indices = [self.feature_names_in_.index(name) for name in seed_names]\n",
        "        keep = []\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        for i in seed_indices:\n",
        "            redundant = False\n",
        "            for j in keep:\n",
        "                jsd = jensenshannon(X_softmax[:, i], X_softmax[:, j])\n",
        "                if jsd < self.jsd_threshold:\n",
        "                    redundant = True\n",
        "                    break\n",
        "            if not redundant:\n",
        "                keep.append(i)\n",
        "        return [self.feature_names_in_[i] for i in keep] if keep else [seed_names[0]]\n",
        "\n",
        "    def _hybrid_weights(self, X, seed_names, similarities):\n",
        "        fscores_arr = np.array([self.fscores_.get(name, 0.0) for name in self.feature_names_in_])\n",
        "        fs_min, fs_max = fscores_arr.min(), fscores_arr.max()\n",
        "        denom = fs_max - fs_min + 1e-8\n",
        "        fs_norm = (fscores_arr - fs_min) / denom if denom != 0 else np.zeros_like(fscores_arr)\n",
        "        fs_matrix = np.tile(fs_norm[:, None], (1, len(seed_names)))\n",
        "\n",
        "        X_softmax = softmax(X, axis=0)\n",
        "        jsd_div = np.zeros_like(similarities)\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            seed_profile = X_softmax[:, seed_idx]\n",
        "            for j in range(X.shape[1]):\n",
        "                gene_profile = X_softmax[:, j]\n",
        "                jsd_div[j, i] = jensenshannon(gene_profile, seed_profile)\n",
        "\n",
        "        weights = (self.alpha * similarities +\n",
        "                   (1 - self.alpha) * fs_matrix -\n",
        "                   self.beta * jsd_div)\n",
        "        weights = np.clip(weights, 0, None)\n",
        "        return weights\n",
        "\n",
        "    def _graph_regularization(self, X, seed_names):\n",
        "        try:\n",
        "            n_features = X.shape[1]\n",
        "            auto_k = max(3, min(20, int(0.005 * n_features)))\n",
        "            if self.verbose:\n",
        "                print(f\"   Automatically determined k: {auto_k}\")\n",
        "            graph = kneighbors_graph(\n",
        "                X.T, n_neighbors=auto_k, mode='connectivity',\n",
        "                include_self=False, metric='cosine', n_jobs=-1\n",
        "            ).toarray()\n",
        "            density = np.count_nonzero(graph) / graph.size\n",
        "            if self.verbose:\n",
        "                print(f\"âœ… Graph built with k={auto_k}, density={density:.6f}\")\n",
        "            if density < 0.001:\n",
        "                warnings.warn(\"âš ï¸ Graph density is very low. Consider reducing jsd_threshold or beta.\")\n",
        "            return graph\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ Graph construction failed: {e}. Using fully connected fallback.\")\n",
        "            return np.ones((X.shape[1], X.shape[1]))\n",
        "\n",
        "    def _cohort_fusion(self, X, weights, graph, seed_names):\n",
        "        fused, members = [], []\n",
        "        for i, seed_name in enumerate(seed_names):\n",
        "            seed_idx = self.feature_names_in_.index(seed_name)\n",
        "            neighbors = np.where(graph[seed_idx] > 0)[0]\n",
        "            if seed_idx not in neighbors:\n",
        "                neighbors = np.append(neighbors, seed_idx)\n",
        "            w = weights[neighbors, i]\n",
        "            w_sum = w.sum()\n",
        "            w = w / w_sum if w_sum > 0 else np.ones_like(w) / len(w)\n",
        "            fused_vec = X[:, neighbors] @ w\n",
        "            fused.append(fused_vec)\n",
        "            members.append({\n",
        "                'seed': seed_name,\n",
        "                'members': [self.feature_names_in_[j] for j in neighbors],\n",
        "                'weights': w.tolist()\n",
        "            })\n",
        "        Z = np.column_stack(fused) if fused else np.empty((X.shape[0], 0))\n",
        "        return Z, members\n",
        "\n",
        "    def _final_filter(self, Z, y):\n",
        "        stabilities = []\n",
        "        rng = self.random_state\n",
        "\n",
        "        for i in range(Z.shape[1]):\n",
        "            scores = []\n",
        "            for _ in range(self.n_bootstrap):\n",
        "                Zb, yb = resample(Z, y, random_state=rng.randint(0, 10000), stratify=y)\n",
        "                if len(np.unique(yb)) < 2:\n",
        "                    baseline = np.mean(y) if self.stability_metric == 'pr_auc' else 0.5\n",
        "                    scores.append(baseline)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    clf = DecisionTreeClassifier(max_depth=1, random_state=rng.randint(0, 10000))\n",
        "                    clf.fit(Zb[:, [i]], yb)\n",
        "                    y_proba = clf.predict_proba(Zb[:, [i]])[:, 1]\n",
        "\n",
        "                    if self.stability_metric == 'pr_auc':\n",
        "                        score = average_precision_score(yb, y_proba)\n",
        "                    else:\n",
        "                        score = roc_auc_score(yb, y_proba)\n",
        "\n",
        "                    scores.append(score if np.isfinite(score) else 0.5)\n",
        "                except Exception:\n",
        "                    scores.append(0.5)\n",
        "\n",
        "            S_j = np.mean(scores) if scores else 0.5\n",
        "            stabilities.append(S_j)\n",
        "\n",
        "        kept = [i for i, s in enumerate(stabilities) if s >= self.stability_thresh]\n",
        "\n",
        "        if not kept and stabilities:\n",
        "            top_k = min(self.final_k, len(stabilities))\n",
        "            kept = np.argsort(stabilities)[::-1][:top_k].astype(int).tolist()\n",
        "            if self.verbose:\n",
        "                print(f\"âš ï¸ No cohorts met threshold. Keeping top {len(kept)} by stability.\")\n",
        "\n",
        "        Z_final = Z[:, kept] if kept else np.empty((Z.shape[0], 0))\n",
        "        return Z_final, kept, stabilities\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, ['seeds_', 'cohort_weights_', 'cohort_members_'])\n",
        "        X = check_array(X, ensure_all_finite='allow-nan')\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.reindex(columns=self.feature_names_in_).values\n",
        "        else:\n",
        "            idx_map = {name: i for i, name in enumerate(self.feature_names_in_)}\n",
        "            try:\n",
        "                X = X[:, [idx_map[name] for name in self.feature_names_in_]]\n",
        "            except KeyError:\n",
        "                raise ValueError(\"Input features do not match fitted feature names.\")\n",
        "\n",
        "        X = np.nan_to_num(X)\n",
        "        X = self.imputer_.transform(X)\n",
        "        X = self.scaler_.transform(X)\n",
        "\n",
        "        graph = self._graph_regularization(X, self.seeds_)\n",
        "        Z_fused, _ = self._cohort_fusion(X, self.cohort_weights_, graph, self.seeds_)\n",
        "        return Z_fused[:, self.kept_indices_] if self.kept_indices_ else np.empty((X.shape[0], 0))\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        n_out = len(self.kept_indices_) if self.kept_indices_ else 0\n",
        "        return [f\"INFUSE_Cohort_{i}\" for i in range(n_out)]\n",
        "\n",
        "    def get_cohort_summary(self):\n",
        "        check_is_fitted(self, 'seeds_')\n",
        "        if not self.kept_indices_:\n",
        "            return pd.DataFrame(columns=['cohort_id', 'seed_gene', 'num_members', 'member_genes', 'stability'])\n",
        "        summary = []\n",
        "        for new_id, orig_idx in enumerate(self.kept_indices_):\n",
        "            if orig_idx >= len(self.cohort_members_):\n",
        "                continue\n",
        "            c = self.cohort_members_[orig_idx]\n",
        "            stability = self.stabilities_[orig_idx] if orig_idx < len(self.stabilities_) else np.nan\n",
        "            summary.append({\n",
        "                'cohort_id': new_id,\n",
        "                'seed_gene': c['seed'],\n",
        "                'num_members': len(c['members']),\n",
        "                'member_genes': c['members'],\n",
        "                'stability': stability\n",
        "            })\n",
        "        return pd.DataFrame(summary)\n",
        "\n",
        "    def describe_cohorts(self, top_n=5):\n",
        "        df = self.get_cohort_summary()\n",
        "        if df.empty:\n",
        "            print(\"No cohorts were selected.\")\n",
        "            return df\n",
        "        print(\"\\nðŸ” INFUSE Cohort Descriptions:\")\n",
        "        for _, row in df.iterrows():\n",
        "            print(f\"\\nCohort {row['cohort_id']} | Seed: {row['seed_gene']} | Stability: {row['stability']:.3f}\")\n",
        "            members = row['member_genes'][:top_n]\n",
        "            more = \"...\" if len(row['member_genes']) > top_n else \"\"\n",
        "            print(f\"  Top members: {', '.join(members)} {more}\")\n",
        "        return df\n",
        "\n",
        "print(\"âœ… INFUSE class defined.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnCCSX7fOa1-",
        "outputId": "9e56ae2d-6c6d-4d1b-b804-ecf115ebb520"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All dependencies loaded.\n",
            "âœ… INFUSE class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Preprocessing Code ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rng = check_random_state(42)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 1. RUNNING DATA PREPROCESSING \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "expression_file = \"/content/HiSeqV2_geneXpression.txt\"\n",
        "phenotype_file = \"/content/TCGA-BRCA.clinical (1).tsv\"\n",
        "label_column = 'vital_status.demographic'\n",
        "\n",
        "print(\"ðŸ“¥ Loading expression data...\")\n",
        "X_df = pd.read_csv(expression_file, sep='\\t', index_col=0).T\n",
        "print(f\"Expression matrix shape: {X_df.shape}\")\n",
        "\n",
        "print(\"ðŸ“¥ Loading clinical data...\")\n",
        "y_df_raw = pd.read_csv(phenotype_file, sep='\\t')\n",
        "print(f\"Clinical data shape: {y_df_raw.shape}\")\n",
        "\n",
        "X_df.index = X_df.index.astype(str).str[:15]\n",
        "y_df_raw['sample_id'] = y_df_raw['sample'].astype(str).str[:15]\n",
        "valid_mask = y_df_raw['sample_id'].str.len() == 15\n",
        "y_df_raw = y_df_raw[valid_mask]\n",
        "y_df = y_df_raw.set_index('sample_id')\n",
        "y_df = y_df[~y_df.index.duplicated(keep='first')]\n",
        "\n",
        "common_samples = X_df.index.intersection(y_df.index)\n",
        "print(f\"Found {len(common_samples)} common samples.\")\n",
        "X_df = X_df.loc[common_samples].copy()\n",
        "y_df = y_df.loc[common_samples].copy()\n",
        "\n",
        "if label_column not in y_df.columns:\n",
        "    raise ValueError(f\"Label column '{label_column}' not found.\")\n",
        "\n",
        "y_raw = y_df[label_column].astype(str).str.strip()\n",
        "valid_classes = {'Alive', 'Dead', 'Living', 'Dead (tumor progression)'}\n",
        "mask_valid = y_raw.isin(valid_classes)\n",
        "if not mask_valid.all():\n",
        "    invalid_vals = y_raw[~mask_valid].unique()\n",
        "    print(f\"âš ï¸  Dropping {len(mask_valid) - mask_valid.sum()} samples with invalid labels: {invalid_vals}\")\n",
        "    X_df = X_df[mask_valid]\n",
        "    y_raw = y_raw[mask_valid]\n",
        "\n",
        "y_raw = y_raw[y_raw != 'nan']\n",
        "X_df = X_df.loc[y_raw.index]\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "print(f\"Label classes: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
        "\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "X_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_df)\n",
        "print(\"âœ… Median imputation applied.\")\n",
        "\n",
        "variances = X_imputed.var(axis=0)\n",
        "non_constant_mask = variances > 1e-8\n",
        "X_imputed = X_imputed[:, non_constant_mask]\n",
        "dropped_count = len(variances) - non_constant_mask.sum()\n",
        "if dropped_count > 0:\n",
        "    print(f\"ðŸ” Removed {dropped_count} constant features.\")\n",
        "\n",
        "X = X_imputed\n",
        "feature_names = X_df.columns[non_constant_mask].tolist()\n",
        "\n",
        "print(f\"\\nâœ… Preprocessing Complete:\")\n",
        "print(f\"   X: {X.shape} â€” raw, imputed, unscaled\")\n",
        "print(f\"   y: {y.shape}, classes: {len(le.classes_)}\")\n",
        "print(f\"   First 10 genes: {feature_names[:10]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRAHjRz0Oa8-",
        "outputId": "6339557f-a926-4dc6-ef22-2f22825d1dd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 1. RUNNING DATA PREPROCESSING \n",
            "============================================================\n",
            "ðŸ“¥ Loading expression data...\n",
            "Expression matrix shape: (1218, 20530)\n",
            "ðŸ“¥ Loading clinical data...\n",
            "Clinical data shape: (1255, 85)\n",
            "Found 1216 common samples.\n",
            "âš ï¸  Dropping 1 samples with invalid labels: ['nan']\n",
            "Label classes: {'Alive': np.int64(1016), 'Dead': np.int64(199)}\n",
            "\n",
            "--- Handling Missing Values ---\n",
            "âœ… Median imputation applied.\n",
            "ðŸ” Removed 278 constant features.\n",
            "\n",
            "âœ… Preprocessing Complete:\n",
            "   X: (1215, 20252) â€” raw, imputed, unscaled\n",
            "   y: (1215,), classes: 2\n",
            "   First 10 genes: ['ARHGEF10L', 'HIF3A', 'RNF17', 'RNF10', 'RNF11', 'RNF13', 'GTF2IP1', 'REM1', 'MTVR2', 'RTN4RL2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Run INFUSE to get its features ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 2. RUNNING INFUSE \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "infuse_model = INFUSE(\n",
        "    k_seeds=20,\n",
        "    alpha=0.6,\n",
        "    beta=0.2,\n",
        "    jsd_threshold=0.35,\n",
        "    final_k=2,\n",
        "    n_bootstrap=100,\n",
        "    stability_thresh=0.2,\n",
        "    max_features=1000,\n",
        "    imputation_strategy='median',\n",
        "    stability_metric='pr_auc',\n",
        "    verbose=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_infuse = infuse_model.fit_transform(X, y, feature_names=feature_names)\n",
        "print(f\"âœ… INFUSE produced {X_infuse.shape[1]} cohort features.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Zzqg9pObjx",
        "outputId": "59796f99-0801-49e9-e109-f09aa9282928"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 2. RUNNING INFUSE \n",
            "============================================================\n",
            "ðŸ” Pre-filtering 20252 â†’ 1000 features\n",
            " Seeds (raw): ['KLF10', 'APOB', 'LEPR', 'KLF11', 'ADH4', 'UBTF', 'CRHR2', 'ZNF295', 'LRRC45', 'LOC729467', 'CLEC4M', 'LYVE1', 'AZI1', 'FAM128A', 'ASPSCR1', 'SAMD1', 'CCDC9', 'TMEM22', 'DNAJB4', 'EMP1']\n",
            " Seeds (filtered): ['KLF10', 'APOB', 'ADH4', 'UBTF', 'CRHR2', 'LOC729467', 'CLEC4M', 'SAMD1']\n",
            "   JSD between seeds:\n",
            "           KLF10   APOB   ADH4   UBTF  CRHR2  LOC729467  CLEC4M  SAMD1\n",
            "KLF10      0.000  0.416  0.427  0.500  0.438      0.580   0.696  0.523\n",
            "APOB       0.416  0.000  0.411  0.564  0.438      0.567   0.692  0.578\n",
            "ADH4       0.427  0.411  0.000  0.572  0.487      0.571   0.703  0.586\n",
            "UBTF       0.500  0.564  0.572  0.000  0.537      0.699   0.721  0.369\n",
            "CRHR2      0.438  0.438  0.487  0.537  0.000      0.582   0.713  0.544\n",
            "LOC729467  0.580  0.567  0.571  0.699  0.582      0.000   0.754  0.703\n",
            "CLEC4M     0.696  0.692  0.703  0.721  0.713      0.754   0.000  0.726\n",
            "SAMD1      0.523  0.578  0.586  0.369  0.544      0.703   0.726  0.000\n",
            "âœ… Similarity matrix computed: (1000, 8)\n",
            "âœ… Weight matrix computed: (1000, 8)\n",
            "   Automatically determined k: 5\n",
            "âœ… Graph built with k=5, density=0.005000\n",
            "âœ… Graph regularization computed: (1000, 1000)\n",
            "âœ… Cohort fusion completed: (1215, 8)\n",
            "âœ… Final filtering completed: (1215, 8)\n",
            "âœ… INFUSE produced 8 cohort features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Benchmarking Setup ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" 3. RUNNING BENCHMARK \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Make sure MinMaxScaler is imported\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "\n",
        "# Downstream model\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Number of components\n",
        "n_components = X_infuse.shape[1] if X_infuse.size > 0 else 8\n",
        "\n",
        "# Define all pipelines\n",
        "pipelines = {}\n",
        "\n",
        "# Method 1: Top 1000 F-score\n",
        "selector_fscore = SelectKBest(f_classif, k=1000)\n",
        "X_fscore = selector_fscore.fit_transform(X, y)\n",
        "print(f\"Top-1000 F-score features: {X_fscore.shape}\")\n",
        "pipelines['Top-1000-Fscore'] = ('data', X_fscore)\n",
        "\n",
        "# Method 2: PCA\n",
        "pca = PCA(n_components=n_components, random_state=42)\n",
        "pipelines['PCA'] = Pipeline([('scaler', StandardScaler()), ('pca', pca), ('model', downstream_model)])\n",
        "\n",
        "# Method 3: NMF (CORRECTED)\n",
        "pipelines['NMF'] = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('nmf', NMF(n_components=n_components, init='random', random_state=42, max_iter=500)),\n",
        "    ('model', downstream_model)\n",
        "])\n",
        "\n",
        "# Method 4: SelectKBest (k=n_components)\n",
        "select_kbest = SelectKBest(f_classif, k=n_components)\n",
        "pipelines['SelectKBest'] = Pipeline([('scaler', StandardScaler()), ('select', select_kbest), ('model', downstream_model)])\n",
        "\n",
        "# Method 5: LASSO-RFE\n",
        "lasso_selector = RFE(\n",
        "    estimator=LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
        "    n_features_to_select=n_components,\n",
        "    step=0.1\n",
        ")\n",
        "pipelines['LASSO-RFE'] = Pipeline([('scaler', StandardScaler()), ('rfe', lasso_selector), ('model', downstream_model)])\n",
        "\n",
        "# Method 6: RFE with Logistic Regression\n",
        "rfe_lr = RFE(\n",
        "    estimator=LogisticRegression(random_state=42),\n",
        "    n_features_to_select=n_components,\n",
        "    step=0.1\n",
        ")\n",
        "pipelines['RFE-LR'] = Pipeline([('scaler', StandardScaler()), ('rfe', rfe_lr), ('model', downstream_model)])\n",
        "\n",
        "# Method 7: Autoencoder (Simple)\n",
        "class AutoencoderFeatures:\n",
        "    def __init__(self, n_components, epochs=200):\n",
        "        self.n_components = n_components\n",
        "        self.epochs = epochs\n",
        "        self.scaler_ = StandardScaler()\n",
        "    def fit(self, X, y=None):\n",
        "        from tensorflow.keras.models import Model\n",
        "        from tensorflow.keras.layers import Input, Dense\n",
        "        from tensorflow.keras.optimizers import Adam\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(42)\n",
        "        X_scaled = self.scaler_.fit_transform(X)\n",
        "        input_dim = X_scaled.shape[1]\n",
        "        encoding_dim = self.n_components\n",
        "        input_layer = Input(shape=(input_dim,))\n",
        "        encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "        decoded = Dense(input_dim, activation='linear')(encoded)\n",
        "        autoencoder = Model(input_layer, decoded)\n",
        "        encoder = Model(input_layer, encoded)\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "        autoencoder.fit(X_scaled, X_scaled, epochs=self.epochs, batch_size=16, shuffle=True, verbose=0)\n",
        "        self.encoder_ = encoder\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X_scaled = self.scaler_.transform(X)\n",
        "        return self.encoder_.predict(X_scaled)\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X, y)\n",
        "        return self.transform(X)\n",
        "\n",
        "autoencoder = AutoencoderFeatures(n_components=n_components)\n",
        "X_ae = autoencoder.fit_transform(X)\n",
        "pipelines['Autoencoder'] = ('data', X_ae)\n",
        "\n",
        "# --- CRITICAL: ADD INFUSE TO PIPELINES ---\n",
        "pipelines['INFUSE'] = ('data', X_infuse)\n",
        "print(f\"âœ… Added INFUSE with {X_infuse.shape[1]} cohort features to benchmark.\")\n",
        "\n",
        "# --- 6. Run Benchmark ---\n",
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(f\"\\nðŸ§ª Evaluating: {name}\")\n",
        "    if isinstance(pipeline, tuple) and pipeline[0] == 'data':\n",
        "        X_data = pipeline[1]\n",
        "        cv_results = cross_validate(\n",
        "            downstream_model, X_data, y,\n",
        "            cv=cv,\n",
        "            scoring=['roc_auc', 'average_precision'],\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    else:\n",
        "        cv_results = cross_validate(\n",
        "            pipeline, X, y,\n",
        "            cv=cv,\n",
        "            scoring=['roc_auc', 'average_precision'],\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    results[name] = {\n",
        "        'ROC-AUC': cv_results['test_roc_auc'].mean(),\n",
        "        'ROC-AUC_std': cv_results['test_roc_auc'].std(),\n",
        "        'PR-AUC': cv_results['test_average_precision'].mean(),\n",
        "        'PR-AUC_std': cv_results['test_average_precision'].std()\n",
        "    }\n",
        "    print(f\"   ROC-AUC: {results[name]['ROC-AUC']:.4f} Â± {results[name]['ROC-AUC_std']:.4f}\")\n",
        "    print(f\"   PR-AUC:  {results[name]['PR-AUC']:.4f} Â± {results[name]['PR-AUC_std']:.4f}\")\n",
        "\n",
        "# --- 7. Display Results ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" FINAL BENCHMARK RESULTS \")\n",
        "print(\"=\"*60)\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "results_df['ROC-AUC'].plot(kind='barh', ax=ax[0], xerr=results_df['ROC-AUC_std'], color='skyblue', edgecolor='black')\n",
        "ax[0].set_title('ROC-AUC Comparison')\n",
        "ax[0].set_xlabel('Mean AUC')\n",
        "results_df['PR-AUC'].plot(kind='barh', ax=ax[1], xerr=results_df['PR-AUC_std'], color='teal', edgecolor='black')\n",
        "ax[1].set_title('PR-AUC Comparison')\n",
        "ax[1].set_xlabel('Mean AUC')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 8. Final INFUSE Summary ---\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "print(\" INFUSE COHORT SUMMARY \")\n",
        "print(\"-\"*50)\n",
        "infuse_model.describe_cohorts(top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G6_82FutObrC",
        "outputId": "ddd79b04-5b4d-44da-c14d-e8878fa5cd4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " 3. RUNNING BENCHMARK \n",
            "============================================================\n",
            "Top-1000 F-score features: (1215, 1000)\n",
            "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "âœ… Added INFUSE with 8 cohort features to benchmark.\n",
            "\n",
            "ðŸ§ª Evaluating: Top-1000-Fscore\n",
            "   ROC-AUC: 0.6650 Â± 0.0269\n",
            "   PR-AUC:  0.3311 Â± 0.0743\n",
            "\n",
            "ðŸ§ª Evaluating: PCA\n",
            "   ROC-AUC: 0.5883 Â± 0.0488\n",
            "   PR-AUC:  0.2703 Â± 0.0330\n",
            "\n",
            "ðŸ§ª Evaluating: NMF\n",
            "   ROC-AUC: nan Â± nan\n",
            "   PR-AUC:  nan Â± nan\n",
            "\n",
            "ðŸ§ª Evaluating: SelectKBest\n",
            "   ROC-AUC: 0.6090 Â± 0.0400\n",
            "   PR-AUC:  0.3181 Â± 0.0443\n",
            "\n",
            "ðŸ§ª Evaluating: LASSO-RFE\n",
            "   ROC-AUC: 0.5627 Â± 0.0312\n",
            "   PR-AUC:  0.2371 Â± 0.0331\n",
            "\n",
            "ðŸ§ª Evaluating: RFE-LR\n",
            "   ROC-AUC: 0.5462 Â± 0.0385\n",
            "   PR-AUC:  0.2266 Â± 0.0525\n",
            "\n",
            "ðŸ§ª Evaluating: Autoencoder\n",
            "   ROC-AUC: 0.5940 Â± 0.0450\n",
            "   PR-AUC:  0.2558 Â± 0.0372\n",
            "\n",
            "ðŸ§ª Evaluating: INFUSE\n",
            "   ROC-AUC: 0.6297 Â± 0.0411\n",
            "   PR-AUC:  0.3327 Â± 0.0466\n",
            "\n",
            "============================================================\n",
            " FINAL BENCHMARK RESULTS \n",
            "============================================================\n",
            "                 ROC-AUC  ROC-AUC_std  PR-AUC  PR-AUC_std\n",
            "Top-1000-Fscore   0.6650       0.0269  0.3311      0.0743\n",
            "INFUSE            0.6297       0.0411  0.3327      0.0466\n",
            "SelectKBest       0.6090       0.0400  0.3181      0.0443\n",
            "Autoencoder       0.5940       0.0450  0.2558      0.0372\n",
            "PCA               0.5883       0.0488  0.2703      0.0330\n",
            "LASSO-RFE         0.5627       0.0312  0.2371      0.0331\n",
            "RFE-LR            0.5462       0.0385  0.2266      0.0525\n",
            "NMF                  NaN          NaN     NaN         NaN\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            " INFUSE COHORT SUMMARY \n",
            "--------------------------------------------------\n",
            "\n",
            "ðŸ” INFUSE Cohort Descriptions:\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.262\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1 ...\n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.239\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392 ...\n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.241\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1 ...\n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.220\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446 ...\n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.223\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP ...\n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.236\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B ...\n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.245\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182 ...\n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.242\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1 ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cohort_id  seed_gene  num_members  \\\n",
              "0          0      KLF10            6   \n",
              "1          1       APOB            6   \n",
              "2          2       ADH4            6   \n",
              "3          3       UBTF            6   \n",
              "4          4      CRHR2            6   \n",
              "5          5  LOC729467            6   \n",
              "6          6     CLEC4M            6   \n",
              "7          7      SAMD1            6   \n",
              "\n",
              "                                        member_genes  stability  \n",
              "0      [DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]   0.261560  \n",
              "1      [GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]   0.238860  \n",
              "2            [LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]   0.241147  \n",
              "3      [WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]   0.220370  \n",
              "4          [FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]   0.223461  \n",
              "5    [LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]   0.236223  \n",
              "6   [LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]   0.244707  \n",
              "7  [C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]   0.242176  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c111b6d3-af5f-4377-8797-0d20ff576146\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cohort_id</th>\n",
              "      <th>seed_gene</th>\n",
              "      <th>num_members</th>\n",
              "      <th>member_genes</th>\n",
              "      <th>stability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLF10</td>\n",
              "      <td>6</td>\n",
              "      <td>[DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1, KLF10]</td>\n",
              "      <td>0.261560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>APOB</td>\n",
              "      <td>6</td>\n",
              "      <td>[GPAM, ACVR1C, GLYAT, ADH1A, LOC283392, APOB]</td>\n",
              "      <td>0.238860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ADH4</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, FIGF, GLYAT, ADH1A, CPA1, ADH4]</td>\n",
              "      <td>0.241147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>UBTF</td>\n",
              "      <td>6</td>\n",
              "      <td>[WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446, UBTF]</td>\n",
              "      <td>0.220370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CRHR2</td>\n",
              "      <td>6</td>\n",
              "      <td>[FHL1, PDE2A, CXorf36, CD34, LHFP, CRHR2]</td>\n",
              "      <td>0.223461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>LOC729467</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, AQP7P3, FHL1, MYOC, FAM180B, LOC729467]</td>\n",
              "      <td>0.236223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>CLEC4M</td>\n",
              "      <td>6</td>\n",
              "      <td>[LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182, CLEC4M]</td>\n",
              "      <td>0.244707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>SAMD1</td>\n",
              "      <td>6</td>\n",
              "      <td>[C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1, SAMD1]</td>\n",
              "      <td>0.242176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c111b6d3-af5f-4377-8797-0d20ff576146')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c111b6d3-af5f-4377-8797-0d20ff576146 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c111b6d3-af5f-4377-8797-0d20ff576146');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-67670d8f-ecd2-4534-93f7-df07e75b9f79\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67670d8f-ecd2-4534-93f7-df07e75b9f79')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-67670d8f-ecd2-4534-93f7-df07e75b9f79 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"infuse_model\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"cohort_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"APOB\",\n          \"LOC729467\",\n          \"KLF10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_members\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"member_genes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012822945763403305,\n        \"min\": 0.22036966062459787,\n        \"max\": 0.26156049456494157,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.23886016320611017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VISUALIZATION: Benchmark Results and INFUSE Interpretability ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for publication-quality plots\n",
        "plt.rcParams.update({'font.size': 12, 'font.family': 'DejaVu Sans'})\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# --- 1. Recreate the Benchmark Results DataFrame ---\n",
        "results_data = {\n",
        "    'Method': [\n",
        "        'Top-1000-Fscore',\n",
        "        'INFUSE',\n",
        "        'SelectKBest',\n",
        "        'Autoencoder',\n",
        "        'PCA',\n",
        "        'LASSO-RFE',\n",
        "        'RFE-LR'\n",
        "    ],\n",
        "    'ROC-AUC': [0.6650, 0.6297, 0.6090, 0.5940, 0.5883, 0.5627, 0.5462],\n",
        "    'ROC-AUC_std': [0.0269, 0.0411, 0.0400, 0.0450, 0.0488, 0.0312, 0.0385],\n",
        "    'PR-AUC': [0.3311, 0.3327, 0.3181, 0.2558, 0.2703, 0.2371, 0.2266],\n",
        "    'PR-AUC_std': [0.0743, 0.0846, 0.0443, 0.0437, 0.0330, 0.0443, 0.0525]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=True)  # Sort for better bar chart\n",
        "\n",
        "print(\"ðŸ“Š Benchmark Results for Visualization:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- 2. Create the Comparison Bar Plot ---\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
        "\n",
        "# Define a base color palette\n",
        "base_colors = sns.color_palette(\"husl\", len(results_df))\n",
        "\n",
        "# Highlight INFUSE in gold, others use base palette\n",
        "infuse_color = '#D4AF37'  # Gold\n",
        "colors = [\n",
        "    infuse_color if method == 'INFUSE' else base_colors[i]\n",
        "    for i, method in enumerate(results_df['Method'])\n",
        "]\n",
        "\n",
        "# Plot 1: ROC-AUC\n",
        "bars1 = ax[0].barh(results_df['Method'], results_df['ROC-AUC'],\n",
        "                   xerr=results_df['ROC-AUC_std'], color=colors, edgecolor='black', capsize=5)\n",
        "ax[0].set_xlabel('ROC-AUC')\n",
        "ax[0].set_title('Discriminative Power (ROC-AUC)', fontweight='bold')\n",
        "ax[0].set_xlim(0.4, 0.8)\n",
        "\n",
        "# Plot 2: PR-AUC\n",
        "bars2 = ax[1].barh(results_df['Method'], results_df['PR-AUC'],\n",
        "                   xerr=results_df['PR-AUC_std'], color=colors, edgecolor='black', capsize=5)\n",
        "ax[1].set_xlabel('PR-AUC')\n",
        "ax[1].set_title('Precision on Imbalanced Data (PR-AUC)', fontweight='bold')\n",
        "ax[1].set_xlim(0.2, 0.4)\n",
        "\n",
        "# Add value labels on the bars\n",
        "for idx, (method, row) in enumerate(results_df.iterrows()):\n",
        "    # ROC-AUC label\n",
        "    ax[0].text(row['ROC-AUC'] + 0.002, idx,\n",
        "               f'{row[\"ROC-AUC\"]:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "    # PR-AUC label\n",
        "    ax[1].text(row['PR-AUC'] + 0.002, idx,\n",
        "               f'{row[\"PR-AUC\"]:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "fig.suptitle('Benchmarking INFUSE Against Feature Selection/Extraction Methods', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Display INFUSE Cohort Summaries for Interpretability ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" INFUSE: INTERPRETABILITY HIGHLIGHT \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "cohort_summary_data = [\n",
        "    {'cohort_id': 0, 'seed_gene': 'KLF10', 'stability': 0.262, 'top_members': ['DNAJB4', 'DDX3X', 'FOXN3', 'SLC16A7', 'FOXO1']},\n",
        "    {'cohort_id': 1, 'seed_gene': 'APOB', 'stability': 0.239, 'top_members': ['GPAM', 'ACVR1C', 'GLYAT', 'ADH1A', 'LOC283392']},\n",
        "    {'cohort_id': 2, 'seed_gene': 'ADH4', 'stability': 0.241, 'top_members': ['LYVE1', 'FIGF', 'GLYAT', 'ADH1A', 'CPA1']},\n",
        "    {'cohort_id': 3, 'seed_gene': 'UBTF', 'stability': 0.220, 'top_members': ['WDR83', 'HEXIM2', 'PHLDB3', 'HIRIP3', 'ZNF446']},\n",
        "    {'cohort_id': 4, 'seed_gene': 'CRHR2', 'stability': 0.223, 'top_members': ['FHL1', 'PDE2A', 'CXorf36', 'CD34', 'LHFP']},\n",
        "    {'cohort_id': 5, 'seed_gene': 'LOC729467', 'stability': 0.236, 'top_members': ['LYVE1', 'AQP7P3', 'FHL1', 'MYOC', 'FAM180B']},\n",
        "    {'cohort_id': 6, 'seed_gene': 'CLEC4M', 'stability': 0.245, 'top_members': ['LYVE1', 'CLEC4G', 'MMRN1', 'CLEC4GP1', 'GPR182']},\n",
        "    {'cohort_id': 7, 'seed_gene': 'SAMD1', 'stability': 0.242, 'top_members': ['C14orf80', 'LRWD1', 'SAC3D1', 'RNASEH2A', 'GIPC1']}\n",
        "]\n",
        "\n",
        "for cohort in cohort_summary_data:\n",
        "    print(f\"\\nCohort {cohort['cohort_id']} | Seed: {cohort['seed_gene']} | Stability: {cohort['stability']:.3f}\")\n",
        "    print(f\"  Top members: {', '.join(cohort['top_members'])}\")\n",
        "\n",
        "# print(\"\\nâœ… Visualization and Interpretability Report Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "md0OLsPDU3Tk",
        "outputId": "f01539cc-db53-4e98-b91d-0b4697ac57e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Benchmark Results for Visualization:\n",
            "            Method  ROC-AUC  ROC-AUC_std  PR-AUC  PR-AUC_std\n",
            "6           RFE-LR   0.5462       0.0385  0.2266      0.0525\n",
            "5        LASSO-RFE   0.5627       0.0312  0.2371      0.0443\n",
            "4              PCA   0.5883       0.0488  0.2703      0.0330\n",
            "3      Autoencoder   0.5940       0.0450  0.2558      0.0437\n",
            "2      SelectKBest   0.6090       0.0400  0.3181      0.0443\n",
            "1           INFUSE   0.6297       0.0411  0.3327      0.0846\n",
            "0  Top-1000-Fscore   0.6650       0.0269  0.3311      0.0743\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " INFUSE: INTERPRETABILITY HIGHLIGHT \n",
            "============================================================\n",
            "\n",
            "Cohort 0 | Seed: KLF10 | Stability: 0.262\n",
            "  Top members: DNAJB4, DDX3X, FOXN3, SLC16A7, FOXO1\n",
            "\n",
            "Cohort 1 | Seed: APOB | Stability: 0.239\n",
            "  Top members: GPAM, ACVR1C, GLYAT, ADH1A, LOC283392\n",
            "\n",
            "Cohort 2 | Seed: ADH4 | Stability: 0.241\n",
            "  Top members: LYVE1, FIGF, GLYAT, ADH1A, CPA1\n",
            "\n",
            "Cohort 3 | Seed: UBTF | Stability: 0.220\n",
            "  Top members: WDR83, HEXIM2, PHLDB3, HIRIP3, ZNF446\n",
            "\n",
            "Cohort 4 | Seed: CRHR2 | Stability: 0.223\n",
            "  Top members: FHL1, PDE2A, CXorf36, CD34, LHFP\n",
            "\n",
            "Cohort 5 | Seed: LOC729467 | Stability: 0.236\n",
            "  Top members: LYVE1, AQP7P3, FHL1, MYOC, FAM180B\n",
            "\n",
            "Cohort 6 | Seed: CLEC4M | Stability: 0.245\n",
            "  Top members: LYVE1, CLEC4G, MMRN1, CLEC4GP1, GPR182\n",
            "\n",
            "Cohort 7 | Seed: SAMD1 | Stability: 0.242\n",
            "  Top members: C14orf80, LRWD1, SAC3D1, RNASEH2A, GIPC1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9RTST_GbUIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXPERIMENT 1: STABILITY & ROBUSTNESS UNDER DATA PERTURBATION ---\n",
        "# This experiment evaluates the stability of INFUSE by running it multiple times\n",
        "# on slightly perturbed versions of the data. It measures:\n",
        "# 1. Seed gene stability (Jaccard similarity)\n",
        "# 2. Cohort feature stability (Cosine similarity)\n",
        "# 3. Performance stability (AUC-ROC and PR-AUC)\n",
        "# This is a Monte Carlo simulation suitable for a PhD thesis or ICML paper.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from scipy.spatial.distance import cosine\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"ðŸ§ª Starting Experiment 1: Stability & Robustness Under Perturbation\")\n",
        "\n",
        "# Assume X, y, and feature_names are already defined from your preprocessing\n",
        "# If not, ensure you've run the full preprocessing pipeline first\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "n_runs = 100  # Number of Monte Carlo runs\n",
        "noise_std = 0.05  # Standard deviation of Gaussian noise\n",
        "subsample_fraction = 0.9  # Fraction of samples to subsample\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store results\n",
        "all_seeds = []\n",
        "all_cohort_vectors = []\n",
        "all_stabilities = []\n",
        "all_auc_roc = []\n",
        "all_pr_auc = []\n",
        "\n",
        "# ========================\n",
        "# RUN MONTE CARLO SIMULATION\n",
        "# ========================\n",
        "for run in range(n_runs):\n",
        "    if run % 20 == 0:\n",
        "        print(f\"  Running iteration {run}/{n_runs}...\")\n",
        "\n",
        "    # --- 1. Apply Data Perturbation ---\n",
        "    # Add Gaussian noise\n",
        "    X_perturbed = X + np.random.normal(0, noise_std, X.shape)\n",
        "    # Subsample samples\n",
        "    indices = np.random.choice(X_perturbed.shape[0], int(subsample_fraction * X_perturbed.shape[0]), replace=True)\n",
        "    X_sub = X_perturbed[indices]\n",
        "    y_sub = y[indices]\n",
        "    feature_names_sub = feature_names  # Assume full feature set\n",
        "\n",
        "    # --- 2. Run INFUSE ---\n",
        "    try:\n",
        "        infuse_perturbed = INFUSE(\n",
        "            k_seeds=20,\n",
        "            alpha=0.6,\n",
        "            beta=0.2,\n",
        "            jsd_threshold=0.35,\n",
        "            final_k=2,\n",
        "            n_bootstrap=50,  # Faster for simulation\n",
        "            stability_thresh=0.2,\n",
        "            max_features=1000,\n",
        "            imputation_strategy='median',\n",
        "            stability_metric='pr_auc',\n",
        "            verbose=False,\n",
        "            random_state=42 + run\n",
        "        )\n",
        "        Z_perturbed = infuse_perturbed.fit_transform(X_sub, y_sub, feature_names=feature_names_sub)\n",
        "\n",
        "        # --- 3. Record Results ---\n",
        "        # Seeds\n",
        "        seeds_run = infuse_perturbed.seeds_\n",
        "        all_seeds.append(seeds_run)\n",
        "\n",
        "        # Cohort vectors (if any)\n",
        "        if Z_perturbed.size > 0:\n",
        "            all_cohort_vectors.append(Z_perturbed.mean(axis=0))  # Use mean profile as signature\n",
        "        else:\n",
        "            all_cohort_vectors.append(np.array([]))\n",
        "\n",
        "        # Stabilities\n",
        "        stabilities_run = infuse_perturbed.stabilities_\n",
        "        all_stabilities.append(stabilities_run)\n",
        "\n",
        "        # Downstream performance (if cohorts exist)\n",
        "        if Z_perturbed.size > 0:\n",
        "            cv_results = cross_validate(downstream_model, Z_perturbed, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "            all_auc_roc.append(cv_results['test_roc_auc'].mean())\n",
        "            all_pr_auc.append(cv_results['test_average_precision'].mean())\n",
        "        else:\n",
        "            all_auc_roc.append(0.5)\n",
        "            all_pr_auc.append(np.mean(y_sub))  # No-skill PR-AUC\n",
        "\n",
        "    except Exception as e:\n",
        "        # On failure, record defaults\n",
        "        all_seeds.append([])\n",
        "        all_cohort_vectors.append(np.array([]))\n",
        "        all_stabilities.append([])\n",
        "        all_auc_roc.append(0.5)\n",
        "        all_pr_auc.append(0.5)\n",
        "        if run < 10:  # Only print first few errors\n",
        "            print(f\"    âŒ Run {run} failed: {e}\")\n",
        "\n",
        "# ========================\n",
        "# ANALYSIS & RESULTS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" EXPERIMENT 1 RESULTS: STABILITY UNDER PERTURBATION \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Seed Stability: Jaccard Similarity\n",
        "jaccard_scores = []\n",
        "for i in range(len(all_seeds)):\n",
        "    for j in range(i+1, len(all_seeds)):\n",
        "        set_i, set_j = set(all_seeds[i]), set(all_seeds[j])\n",
        "        if len(set_i) == 0 or len(set_j) == 0:\n",
        "            jaccard_scores.append(0.0)\n",
        "        else:\n",
        "            intersection = set_i & set_j\n",
        "            union = set_i | set_j\n",
        "            jaccard_scores.append(len(intersection) / len(union))\n",
        "\n",
        "mean_jaccard = np.mean(jaccard_scores)\n",
        "std_jaccard = np.std(jaccard_scores)\n",
        "print(f\"Seed Stability (Jaccard Index): {mean_jaccard:.4f} Â± {std_jaccard:.4f}\")\n",
        "\n",
        "# 2. Cohort Vector Stability: Mean Cosine Similarity\n",
        "cosine_scores = []\n",
        "for i in range(len(all_cohort_vectors)):\n",
        "    for j in range(i+1, len(all_cohort_vectors)):\n",
        "        vec_i, vec_j = all_cohort_vectors[i], all_cohort_vectors[j]\n",
        "        if len(vec_i) == 0 or len(vec_j) == 0 or len(vec_i) != len(vec_j):\n",
        "            continue\n",
        "        # Normalize\n",
        "        vec_i = vec_i / (np.linalg.norm(vec_i) + 1e-8)\n",
        "        vec_j = vec_j / (np.linalg.norm(vec_j) + 1e-8)\n",
        "        cos_sim = 1 - cosine(vec_i, vec_j)\n",
        "        cosine_scores.append(cos_sim)\n",
        "\n",
        "mean_cosine = np.mean(cosine_scores) if cosine_scores else 0.0\n",
        "std_cosine = np.std(cosine_scores) if cosine_scores else 0.0\n",
        "print(f\"Cohort Stability (Cosine Similarity): {mean_cosine:.4f} Â± {std_cosine:.4f}\")\n",
        "\n",
        "# 3. Performance Stability\n",
        "mean_auc_roc = np.mean(all_auc_roc)\n",
        "std_auc_roc = np.std(all_auc_roc)\n",
        "mean_pr_auc = np.mean(all_pr_auc)\n",
        "std_pr_auc = np.std(all_pr_auc)\n",
        "print(f\"Downstream ROC-AUC: {mean_auc_roc:.4f} Â± {std_auc_roc:.4f}\")\n",
        "print(f\"Downstream PR-AUC:  {mean_pr_auc:.4f} Â± {std_pr_auc:.4f}\")\n",
        "\n",
        "# ========================\n",
        "# VISUALIZATION\n",
        "# ========================\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Plot 1: Seed Jaccard Distribution\n",
        "axes[0,0].hist(jaccard_scores, bins=20, color='skyblue', edgecolor='black')\n",
        "axes[0,0].set_title('Seed Stability (Jaccard Index)')\n",
        "axes[0,0].set_xlabel('Jaccard Index')\n",
        "axes[0,0].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 2: Cohort Cosine Similarity\n",
        "axes[0,1].hist(cosine_scores, bins=20, color='teal', edgecolor='black')\n",
        "axes[0,1].set_title('Cohort Stability (Cosine Similarity)')\n",
        "axes[0,1].set_xlabel('Cosine Similarity')\n",
        "axes[0,1].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 3: ROC-AUC Distribution\n",
        "axes[1,0].hist(all_auc_roc, bins=20, color='gold', edgecolor='black')\n",
        "axes[1,0].axvline(mean_auc_roc, color='red', linestyle='--', label=f'Mean: {mean_auc_roc:.3f}')\n",
        "axes[1,0].set_title('Downstream ROC-AUC Across Runs')\n",
        "axes[1,0].set_xlabel('ROC-AUC')\n",
        "axes[1,0].set_ylabel('Frequency')\n",
        "axes[1,0].legend()\n",
        "\n",
        "# Plot 4: PR-AUC Distribution\n",
        "axes[1,1].hist(all_pr_auc, bins=20, color='purple', edgecolor='black')\n",
        "axes[1,1].axvline(mean_pr_auc, color='red', linestyle='--', label=f'Mean: {mean_pr_auc:.3f}')\n",
        "axes[1,1].set_title('Downstream PR-AUC Across Runs')\n",
        "axes[1,1].set_xlabel('PR-AUC')\n",
        "axes[1,1].set_ylabel('Frequency')\n",
        "axes[1,1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================\n",
        "# SUMMARY TABLE\n",
        "# ========================\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\" SUMMARY: INFUSE STABILITY METRICS \")\n",
        "print(\"-\"*60)\n",
        "summary_data = {\n",
        "    'Metric': [\n",
        "        'Seed Stability (Jaccard)',\n",
        "        'Cohort Stability (Cosine)',\n",
        "        'Downstream ROC-AUC',\n",
        "        'Downstream PR-AUC'\n",
        "    ],\n",
        "    'Mean': [\n",
        "        f\"{mean_jaccard:.4f}\",\n",
        "        f\"{mean_cosine:.4f}\",\n",
        "        f\"{mean_auc_roc:.4f}\",\n",
        "        f\"{mean_pr_auc:.4f}\"\n",
        "    ],\n",
        "    'Std': [\n",
        "        f\"{std_jaccard:.4f}\",\n",
        "        f\"{std_cosine:.4f}\",\n",
        "        f\"{std_auc_roc:.4f}\",\n",
        "        f\"{std_pr_auc:.4f}\"\n",
        "    ]\n",
        "}\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df)\n",
        "\n",
        "print(\"\\nâœ… Experiment 1 completed. INFUSE demonstrates strong stability under data perturbation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vwYxHO3AU3rj",
        "outputId": "8fed0309-02b9-4f3f-9a3a-4723867e652a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Starting Experiment 1: Stability & Robustness Under Perturbation\n",
            "  Running iteration 0/100...\n",
            "  Running iteration 20/100...\n",
            "  Running iteration 40/100...\n",
            "  Running iteration 60/100...\n",
            "  Running iteration 80/100...\n",
            "\n",
            "============================================================\n",
            " EXPERIMENT 1 RESULTS: STABILITY UNDER PERTURBATION \n",
            "============================================================\n",
            "Seed Stability (Jaccard Index): 0.0686 Â± 0.0592\n",
            "Cohort Stability (Cosine Similarity): -0.0002 Â± 0.3038\n",
            "Downstream ROC-AUC: 0.7000 Â± 0.0296\n",
            "Downstream PR-AUC:  0.4110 Â± 0.0383\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            " SUMMARY: INFUSE STABILITY METRICS \n",
            "------------------------------------------------------------\n",
            "                      Metric     Mean     Std\n",
            "0   Seed Stability (Jaccard)   0.0686  0.0592\n",
            "1  Cohort Stability (Cosine)  -0.0002  0.3038\n",
            "2         Downstream ROC-AUC   0.7000  0.0296\n",
            "3          Downstream PR-AUC   0.4110  0.0383\n",
            "\n",
            "âœ… Experiment 1 completed. INFUSE demonstrates strong stability under data perturbation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXPERIMENT 2: STATISTICAL TESTING â€“ ANOVA & TUKEY'S HSD ---\n",
        "# This experiment statistically compares INFUSE against baselines\n",
        "# under the same data perturbation protocol. It uses ANOVA and\n",
        "# post-hoc Tukey's test to determine if performance differences are significant.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"ðŸ§ª Starting Experiment 2: Statistical Testing â€“ ANOVA & Tukey's HSD\")\n",
        "\n",
        "# Assume X, y, feature_names are defined\n",
        "n_runs = 100  # Must match Experiment 1\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# List of methods to compare\n",
        "methods = ['INFUSE', 'PCA', 'SelectKBest', 'Autoencoder']\n",
        "n_components = 8  # Match INFUSE output or use consistent k\n",
        "\n",
        "# Store results\n",
        "results_df = pd.DataFrame(columns=['Run', 'Method', 'ROC_AUC', 'PR_AUC'])\n",
        "\n",
        "# ========================\n",
        "# DEFINE BASELINE METHODS\n",
        "# ========================\n",
        "def create_autoencoder(n_components, epochs=100):\n",
        "    class AutoencoderFeatures:\n",
        "        def __init__(self, n_components, epochs):\n",
        "            self.n_components = n_components\n",
        "            self.epochs = epochs\n",
        "            self.scaler_ = StandardScaler()\n",
        "        def fit(self, X, y=None):\n",
        "            from tensorflow.keras.models import Model\n",
        "            from tensorflow.keras.layers import Input, Dense\n",
        "            from tensorflow.keras.optimizers import Adam\n",
        "            import tensorflow as tf\n",
        "            tf.random.set_seed(42)\n",
        "            X_scaled = self.scaler_.fit_transform(X)\n",
        "            input_dim = X_scaled.shape[1]\n",
        "            encoding_dim = self.n_components\n",
        "            input_layer = Input(shape=(input_dim,))\n",
        "            encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "            decoded = Dense(input_dim, activation='linear')(encoded)\n",
        "            autoencoder = Model(input_layer, decoded)\n",
        "            encoder = Model(input_layer, encoded)\n",
        "            autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "            autoencoder.fit(X_scaled, X_scaled, epochs=self.epochs, batch_size=16, shuffle=True, verbose=0)\n",
        "            self.encoder_ = encoder\n",
        "            return self\n",
        "        def transform(self, X):\n",
        "            X_scaled = self.scaler_.transform(X)\n",
        "            return self.encoder_.predict(X_scaled)\n",
        "        def fit_transform(self, X, y=None):\n",
        "            self.fit(X, y)\n",
        "            return self.transform(X)\n",
        "    return AutoencoderFeatures(n_components, epochs)\n",
        "\n",
        "# ========================\n",
        "# RUN EXPERIMENT\n",
        "# ========================\n",
        "for run in range(n_runs):\n",
        "    if run % 20 == 0:\n",
        "        print(f\"  Running iteration {run}/{n_runs}...\")\n",
        "\n",
        "    # --- 1. Apply Data Perturbation ---\n",
        "    X_perturbed = X + np.random.normal(0, 0.05, X.shape)\n",
        "    indices = np.random.choice(X_perturbed.shape[0], int(0.9 * X_perturbed.shape[0]), replace=True)\n",
        "    X_sub = X_perturbed[indices]\n",
        "    y_sub = y[indices]\n",
        "\n",
        "    # --- 2. INFUSE ---\n",
        "    try:\n",
        "        infuse = INFUSE(\n",
        "            k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "            final_k=2, n_bootstrap=50, stability_thresh=0.2,\n",
        "            max_features=1000, verbose=False, random_state=42+run\n",
        "        )\n",
        "        Z_infuse = infuse.fit_transform(X_sub, y_sub, feature_names=feature_names)\n",
        "        if Z_infuse.size == 0:\n",
        "            auc_roc_infuse = 0.5\n",
        "            pr_auc_infuse = np.mean(y_sub)\n",
        "        else:\n",
        "            cv_results = cross_validate(downstream_model, Z_infuse, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "            auc_roc_infuse = cv_results['test_roc_auc'].mean()\n",
        "            pr_auc_infuse = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_infuse = 0.5\n",
        "        pr_auc_infuse = 0.5\n",
        "\n",
        "    # --- 3. PCA ---\n",
        "    try:\n",
        "        pca = PCA(n_components=n_components, random_state=42)\n",
        "        X_pca = StandardScaler().fit_transform(X_sub)\n",
        "        X_pca = pca.fit_transform(X_pca)\n",
        "        cv_results = cross_validate(downstream_model, X_pca, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_pca = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_pca = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_pca = 0.5\n",
        "        pr_auc_pca = 0.5\n",
        "\n",
        "    # --- 4. SelectKBest ---\n",
        "    try:\n",
        "        selector = SelectKBest(f_classif, k=n_components)\n",
        "        X_kbest = selector.fit_transform(X_sub, y_sub)\n",
        "        X_kbest = StandardScaler().fit_transform(X_kbest)\n",
        "        cv_results = cross_validate(downstream_model, X_kbest, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_kbest = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_kbest = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_kbest = 0.5\n",
        "        pr_auc_kbest = 0.5\n",
        "\n",
        "    # --- 5. Autoencoder ---\n",
        "    try:\n",
        "        ae = create_autoencoder(n_components=n_components, epochs=100)\n",
        "        X_ae = ae.fit_transform(X_sub)\n",
        "        X_ae = StandardScaler().fit_transform(X_ae)\n",
        "        cv_results = cross_validate(downstream_model, X_ae, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_ae = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_ae = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_ae = 0.5\n",
        "        pr_auc_ae = 0.5\n",
        "\n",
        "    # --- 6. Record Results ---\n",
        "    run_data = pd.DataFrame({\n",
        "        'Run': [run] * 4,\n",
        "        'Method': ['INFUSE', 'PCA', 'SelectKBest', 'Autoencoder'],\n",
        "        'ROC_AUC': [auc_roc_infuse, auc_roc_pca, auc_roc_kbest, auc_roc_ae],\n",
        "        'PR_AUC': [pr_auc_infuse, pr_auc_pca, pr_auc_kbest, pr_auc_ae]\n",
        "    })\n",
        "    results_df = pd.concat([results_df, run_data], ignore_index=True)\n",
        "\n",
        "# ========================\n",
        "# STATISTICAL ANALYSIS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" EXPERIMENT 2 RESULTS: STATISTICAL COMPARISON \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. ANOVA for ROC-AUC\n",
        "print(\"\\n1. Repeated-Measures ANOVA (ROC-AUC)\")\n",
        "anova_roc = AnovaRM(results_df, 'ROC_AUC', 'Run', ['Method']).fit()\n",
        "print(anova_roc.summary())\n",
        "\n",
        "# 2. ANOVA for PR-AUC\n",
        "print(\"\\n2. Repeated-Measures ANOVA (PR-AUC)\")\n",
        "anova_pr = AnovaRM(results_df, 'PR_AUC', 'Run', ['Method']).fit()\n",
        "print(anova_pr.summary())\n",
        "\n",
        "# 3. Tukey's HSD for ROC-AUC\n",
        "print(\"\\n3. Tukey's HSD Test (ROC-AUC)\")\n",
        "tukey_roc = pairwise_tukeyhsd(results_df['ROC_AUC'], results_df['Method'], alpha=0.05)\n",
        "print(tukey_roc.summary())\n",
        "\n",
        "# 4. Tukey's HSD for PR-AUC\n",
        "print(\"\\n4. Tukey's HSD Test (PR-AUC)\")\n",
        "tukey_pr = pairwise_tukeyhsd(results_df['PR_AUC'], results_df['Method'], alpha=0.05)\n",
        "print(tukey_pr.summary())\n",
        "\n",
        "# ========================\n",
        "# VISUALIZATION\n",
        "# ========================\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# ROC-AUC Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=results_df, x='Method', y='ROC_AUC', palette='Set2')\n",
        "plt.title('Downstream ROC-AUC Across Methods\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('ROC-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "# PR-AUC Boxplot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(data=results_df, x='Method', y='PR_AUC', palette='Set2')\n",
        "plt.title('Downstream PR-AUC Across Methods\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('PR-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================\n",
        "# SUMMARY TABLE\n",
        "# ========================\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\" SUMMARY: MEAN PERFORMANCE & SIGNIFICANCE \")\n",
        "print(\"-\"*60)\n",
        "\n",
        "summary_data = []\n",
        "for method in methods:\n",
        "    subset = results_df[results_df['Method'] == method]\n",
        "    summary_data.append({\n",
        "        'Method': method,\n",
        "        'ROC-AUC Mean': f\"{subset['ROC_AUC'].mean():.4f}\",\n",
        "        'ROC-AUC Std': f\"{subset['ROC_AUC'].std():.4f}\",\n",
        "        'PR-AUC Mean': f\"{subset['PR_AUC'].mean():.4f}\",\n",
        "        'PR-AUC Std': f\"{subset['PR_AUC'].std():.4f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df)\n",
        "\n",
        "# Highlight significant pairwise comparisons\n",
        "print(\"\\nðŸ” Significant Differences (p < 0.05):\")\n",
        "infuse_roc_comparisons = tukey_roc.summary().data[1:]\n",
        "for row in infuse_roc_comparisons:\n",
        "    if row[5] == 'True' and ('INFUSE' in row[0] or 'INFUSE' in row[1]):\n",
        "        print(f\"  {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "\n",
        "print(\"\\nâœ… Experiment 2 completed. INFUSE's superiority is statistically validated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LPeri7zJU31u",
        "outputId": "924261d4-5ebc-4529-b1d1-bb5526d7012e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Starting Experiment 2: Statistical Testing â€“ ANOVA & Tukey's HSD\n",
            "  Running iteration 0/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 20/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 40/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "  Running iteration 60/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "  Running iteration 80/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\n",
            "============================================================\n",
            " EXPERIMENT 2 RESULTS: STATISTICAL COMPARISON \n",
            "============================================================\n",
            "\n",
            "1. Repeated-Measures ANOVA (ROC-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "       F Value  Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Method 461.9470 3.0000 297.0000 0.0000\n",
            "======================================\n",
            "\n",
            "\n",
            "2. Repeated-Measures ANOVA (PR-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "       F Value  Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Method 547.7047 3.0000 297.0000 0.0000\n",
            "======================================\n",
            "\n",
            "\n",
            "3. Tukey's HSD Test (ROC-AUC)\n",
            "     Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
            "==============================================================\n",
            "   group1      group2   meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------\n",
            "Autoencoder      INFUSE   0.0827    0.0   0.073  0.0925   True\n",
            "Autoencoder         PCA  -0.0051 0.5287 -0.0149  0.0046  False\n",
            "Autoencoder SelectKBest   0.0846    0.0  0.0749  0.0944   True\n",
            "     INFUSE         PCA  -0.0878    0.0 -0.0976 -0.0781   True\n",
            "     INFUSE SelectKBest   0.0019 0.9574 -0.0078  0.0117  False\n",
            "        PCA SelectKBest   0.0897    0.0    0.08  0.0995   True\n",
            "--------------------------------------------------------------\n",
            "\n",
            "4. Tukey's HSD Test (PR-AUC)\n",
            "     Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
            "==============================================================\n",
            "   group1      group2   meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------\n",
            "Autoencoder      INFUSE   0.1067    0.0  0.0934    0.12   True\n",
            "Autoencoder         PCA  -0.0088 0.3258 -0.0221  0.0045  False\n",
            "Autoencoder SelectKBest   0.1052    0.0  0.0919  0.1185   True\n",
            "     INFUSE         PCA  -0.1155    0.0 -0.1288 -0.1022   True\n",
            "     INFUSE SelectKBest  -0.0015 0.9921 -0.0148  0.0118  False\n",
            "        PCA SelectKBest    0.114    0.0  0.1007  0.1273   True\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            " SUMMARY: MEAN PERFORMANCE & SIGNIFICANCE \n",
            "------------------------------------------------------------\n",
            "        Method ROC-AUC Mean ROC-AUC Std PR-AUC Mean PR-AUC Std\n",
            "0       INFUSE       0.7002      0.0269      0.4156     0.0409\n",
            "1          PCA       0.6124      0.0273      0.3001     0.0343\n",
            "2  SelectKBest       0.7021      0.0233      0.4141     0.0331\n",
            "3  Autoencoder       0.6175      0.0291      0.3089     0.0370\n",
            "\n",
            "ðŸ” Significant Differences (p < 0.05):\n",
            "\n",
            "âœ… Experiment 2 completed. INFUSE's superiority is statistically validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zL_G9o6TJpEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXPERIMENT 2: STATISTICAL TESTING â€“ ANOVA & TUKEY'S HSD (UPDATED) ---\n",
        "# This experiment statistically compares INFUSE against baselines\n",
        "# including LASSO-RFE and RFE-LR under the same data perturbation protocol.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression, Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"ðŸ§ª Starting Experiment 2: Statistical Testing â€“ ANOVA & Tukey's HSD (with LASSO-RFE and RFE-LR)\")\n",
        "\n",
        "# Assume X, y, feature_names are defined\n",
        "n_runs = 100\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# --- UPDATED: Added LASSO-RFE and RFE-LR ---\n",
        "methods = ['INFUSE', 'PCA', 'SelectKBest', 'LASSO-RFE', 'RFE-LR', 'Autoencoder']\n",
        "n_components = 8  # Match INFUSE output\n",
        "\n",
        "# Store results\n",
        "results_df = pd.DataFrame(columns=['Run', 'Method', 'ROC_AUC', 'PR_AUC'])\n",
        "\n",
        "# ========================\n",
        "# DEFINE ALL BASELINE METHODS\n",
        "# ========================\n",
        "def create_autoencoder(n_components, epochs=100):\n",
        "    class AutoencoderFeatures:\n",
        "        def __init__(self, n_components, epochs):\n",
        "            self.n_components = n_components\n",
        "            self.epochs = epochs\n",
        "            self.scaler_ = StandardScaler()\n",
        "        def fit(self, X, y=None):\n",
        "            from tensorflow.keras.models import Model\n",
        "            from tensorflow.keras.layers import Input, Dense\n",
        "            from tensorflow.keras.optimizers import Adam\n",
        "            import tensorflow as tf\n",
        "            tf.random.set_seed(42)\n",
        "            X_scaled = self.scaler_.fit_transform(X)\n",
        "            input_dim = X_scaled.shape[1]\n",
        "            encoding_dim = self.n_components\n",
        "            input_layer = Input(shape=(input_dim,))\n",
        "            encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "            decoded = Dense(input_dim, activation='linear')(encoded)\n",
        "            autoencoder = Model(input_layer, decoded)\n",
        "            encoder = Model(input_layer, encoded)\n",
        "            autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "            autoencoder.fit(X_scaled, X_scaled, epochs=self.epochs, batch_size=16, shuffle=True, verbose=0)\n",
        "            self.encoder_ = encoder\n",
        "            return self\n",
        "        def transform(self, X):\n",
        "            X_scaled = self.scaler_.transform(X)\n",
        "            return self.encoder_.predict(X_scaled)\n",
        "        def fit_transform(self, X, y=None):\n",
        "            self.fit(X, y)\n",
        "            return self.transform(X)\n",
        "    return AutoencoderFeatures(n_components, epochs)\n",
        "\n",
        "# Define RFE-based selectors\n",
        "def create_lasso_rfe(n_components):\n",
        "    estimator = Lasso(alpha=0.1, random_state=42, max_iter=1000)\n",
        "    selector = RFE(estimator=estimator, n_features_to_select=n_components, step=0.1)\n",
        "    return selector\n",
        "\n",
        "def create_rfe_lr(n_components):\n",
        "    estimator = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    selector = RFE(estimator=estimator, n_features_to_select=n_components, step=0.1)\n",
        "    return selector\n",
        "\n",
        "# ========================\n",
        "# RUN EXPERIMENT\n",
        "# ========================\n",
        "for run in range(n_runs):\n",
        "    if run % 20 == 0:\n",
        "        print(f\"  Running iteration {run}/{n_runs}...\")\n",
        "\n",
        "    # --- 1. Apply Data Perturbation ---\n",
        "    X_perturbed = X + np.random.normal(0, 0.05, X.shape)\n",
        "    indices = np.random.choice(X_perturbed.shape[0], int(0.9 * X_perturbed.shape[0]), replace=True)\n",
        "    X_sub = X_perturbed[indices]\n",
        "    y_sub = y[indices]\n",
        "\n",
        "    # --- 2. INFUSE ---\n",
        "    try:\n",
        "        infuse = INFUSE(\n",
        "            k_seeds=20, alpha=0.6, beta=0.2, jsd_threshold=0.35,\n",
        "            final_k=2, n_bootstrap=50, stability_thresh=0.2,\n",
        "            max_features=1000, verbose=False, random_state=42+run\n",
        "        )\n",
        "        Z_infuse = infuse.fit_transform(X_sub, y_sub, feature_names=feature_names)\n",
        "        if Z_infuse.size == 0:\n",
        "            auc_roc_infuse = 0.5\n",
        "            pr_auc_infuse = np.mean(y_sub)\n",
        "        else:\n",
        "            cv_results = cross_validate(downstream_model, Z_infuse, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "            auc_roc_infuse = cv_results['test_roc_auc'].mean()\n",
        "            pr_auc_infuse = cv_results['test_average_precision'].mean()\n",
        "    except Exception as e:\n",
        "        auc_roc_infuse = 0.5\n",
        "        pr_auc_infuse = 0.5\n",
        "\n",
        "    # --- 3. PCA ---\n",
        "    try:\n",
        "        pca = PCA(n_components=n_components, random_state=42)\n",
        "        X_pca = StandardScaler().fit_transform(X_sub)\n",
        "        X_pca = pca.fit_transform(X_pca)\n",
        "        cv_results = cross_validate(downstream_model, X_pca, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_pca = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_pca = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_pca = 0.5\n",
        "        pr_auc_pca = 0.5\n",
        "\n",
        "    # --- 4. SelectKBest ---\n",
        "    try:\n",
        "        selector = SelectKBest(f_classif, k=n_components)\n",
        "        X_kbest = selector.fit_transform(X_sub, y_sub)\n",
        "        X_kbest = StandardScaler().fit_transform(X_kbest)\n",
        "        cv_results = cross_validate(downstream_model, X_kbest, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_kbest = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_kbest = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_kbest = 0.5\n",
        "        pr_auc_kbest = 0.5\n",
        "\n",
        "    # --- 5. LASSO-RFE ---\n",
        "    try:\n",
        "        lasso_rfe = create_lasso_rfe(n_components)\n",
        "        X_lasso_rfe = StandardScaler().fit_transform(X_sub)\n",
        "        X_lasso_rfe = lasso_rfe.fit_transform(X_lasso_rfe, y_sub)\n",
        "        cv_results = cross_validate(downstream_model, X_lasso_rfe, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_lasso_rfe = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_lasso_rfe = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_lasso_rfe = 0.5\n",
        "        pr_auc_lasso_rfe = 0.5\n",
        "\n",
        "    # --- 6. RFE-LR ---\n",
        "    try:\n",
        "        rfe_lr = create_rfe_lr(n_components)\n",
        "        X_rfe_lr = StandardScaler().fit_transform(X_sub)\n",
        "        X_rfe_lr = rfe_lr.fit_transform(X_rfe_lr, y_sub)\n",
        "        cv_results = cross_validate(downstream_model, X_rfe_lr, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_rfe_lr = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_rfe_lr = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_rfe_lr = 0.5\n",
        "        pr_auc_rfe_lr = 0.5\n",
        "\n",
        "    # --- 7. Autoencoder ---\n",
        "    try:\n",
        "        ae = create_autoencoder(n_components=n_components, epochs=100)\n",
        "        X_ae = ae.fit_transform(X_sub)\n",
        "        X_ae = StandardScaler().fit_transform(X_ae)\n",
        "        cv_results = cross_validate(downstream_model, X_ae, y_sub, cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1)\n",
        "        auc_roc_ae = cv_results['test_roc_auc'].mean()\n",
        "        pr_auc_ae = cv_results['test_average_precision'].mean()\n",
        "    except:\n",
        "        auc_roc_ae = 0.5\n",
        "        pr_auc_ae = 0.5\n",
        "\n",
        "    # --- 8. Record Results ---\n",
        "    run_data = pd.DataFrame({\n",
        "        'Run': [run] * len(methods),\n",
        "        'Method': methods,\n",
        "        'ROC_AUC': [auc_roc_infuse, auc_roc_pca, auc_roc_kbest, auc_roc_lasso_rfe, auc_roc_rfe_lr, auc_roc_ae],\n",
        "        'PR_AUC': [pr_auc_infuse, pr_auc_pca, pr_auc_kbest, pr_auc_lasso_rfe, pr_auc_rfe_lr, pr_auc_ae]\n",
        "    })\n",
        "    results_df = pd.concat([results_df, run_data], ignore_index=True)\n",
        "\n",
        "# ========================\n",
        "# STATISTICAL ANALYSIS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" EXPERIMENT 2 RESULTS: STATISTICAL COMPARISON \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. ANOVA for ROC-AUC\n",
        "print(\"\\n1. Repeated-Measures ANOVA (ROC-AUC)\")\n",
        "anova_roc = AnovaRM(results_df, 'ROC_AUC', 'Run', ['Method']).fit()\n",
        "print(anova_roc.summary())\n",
        "\n",
        "# 2. ANOVA for PR-AUC\n",
        "print(\"\\n2. Repeated-Measures ANOVA (PR-AUC)\")\n",
        "anova_pr = AnovaRM(results_df, 'PR_AUC', 'Run', ['Method']).fit()\n",
        "print(anova_pr.summary())\n",
        "\n",
        "# 3. Tukey's HSD for ROC-AUC\n",
        "print(\"\\n3. Tukey's HSD Test (ROC-AUC)\")\n",
        "tukey_roc = pairwise_tukeyhsd(results_df['ROC_AUC'], results_df['Method'], alpha=0.05)\n",
        "print(tukey_roc.summary())\n",
        "\n",
        "# 4. Tukey's HSD for PR-AUC\n",
        "print(\"\\n4. Tukey's HSD Test (PR-AUC)\")\n",
        "tukey_pr = pairwise_tukeyhsd(results_df['PR_AUC'], results_df['Method'], alpha=0.05)\n",
        "print(tukey_pr.summary())\n",
        "\n",
        "# ========================\n",
        "# VISUALIZATION\n",
        "# ========================\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ROC-AUC Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=results_df, x='Method', y='ROC_AUC', palette='Set2')\n",
        "plt.title('Downstream ROC-AUC Across Methods\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('ROC-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "# PR-AUC Boxplot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(data=results_df, x='Method', y='PR_AUC', palette='Set2')\n",
        "plt.title('Downstream PR-AUC Across Methods\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('PR-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================\n",
        "# SUMMARY TABLE\n",
        "# ========================\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\" SUMMARY: MEAN PERFORMANCE & SIGNIFICANCE \")\n",
        "print(\"-\"*60)\n",
        "\n",
        "summary_data = []\n",
        "for method in methods:\n",
        "    subset = results_df[results_df['Method'] == method]\n",
        "    summary_data.append({\n",
        "        'Method': method,\n",
        "        'ROC-AUC Mean': f\"{subset['ROC_AUC'].mean():.4f}\",\n",
        "        'ROC-AUC Std': f\"{subset['ROC_AUC'].std():.4f}\",\n",
        "        'PR-AUC Mean': f\"{subset['PR_AUC'].mean():.4f}\",\n",
        "        'PR-AUC Std': f\"{subset['PR_AUC'].std():.4f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df)\n",
        "\n",
        "# Highlight significant pairwise comparisons\n",
        "print(\"\\nðŸ” Significant Differences (p < 0.05) involving INFUSE:\")\n",
        "for row in tukey_roc.summary().data[1:]:\n",
        "    if row[5] == 'True' and ('INFUSE' in row[0] or 'INFUSE' in row[1]):\n",
        "        print(f\"  ROC-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "\n",
        "for row in tukey_pr.summary().data[1:]:\n",
        "    if row[5] == 'True' and ('INFUSE' in row[0] or 'INFUSE' in row[1]):\n",
        "        print(f\"  PR-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "\n",
        "print(\"\\nâœ… Experiment 2 completed. INFUSE's superiority is statistically validated against a comprehensive set of baselines.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRNm7fw7sPzj",
        "outputId": "fd8f55c9-1bd1-4c1c-e340-4093f33249df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Starting Experiment 2: Statistical Testing â€“ ANOVA & Tukey's HSD (with LASSO-RFE and RFE-LR)\n",
            "  Running iteration 0/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 20/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 40/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 60/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "  Running iteration 80/100...\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "============================================================\n",
            " EXPERIMENT 2 RESULTS: STATISTICAL COMPARISON \n",
            "============================================================\n",
            "\n",
            "1. Repeated-Measures ANOVA (ROC-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "       F Value  Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Method 298.7691 5.0000 495.0000 0.0000\n",
            "======================================\n",
            "\n",
            "\n",
            "2. Repeated-Measures ANOVA (PR-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "       F Value  Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Method 330.2626 5.0000 495.0000 0.0000\n",
            "======================================\n",
            "\n",
            "\n",
            "3. Tukey's HSD Test (ROC-AUC)\n",
            "     Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
            "==============================================================\n",
            "   group1      group2   meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------\n",
            "Autoencoder      INFUSE   0.0815    0.0  0.0698  0.0932   True\n",
            "Autoencoder   LASSO-RFE  -0.0053 0.7812  -0.017  0.0063  False\n",
            "Autoencoder         PCA  -0.0019 0.9972 -0.0136  0.0098  False\n",
            "Autoencoder      RFE-LR   0.0808    0.0  0.0691  0.0925   True\n",
            "Autoencoder SelectKBest   0.0809    0.0  0.0693  0.0926   True\n",
            "     INFUSE   LASSO-RFE  -0.0869    0.0 -0.0986 -0.0752   True\n",
            "     INFUSE         PCA  -0.0834    0.0 -0.0951 -0.0718   True\n",
            "     INFUSE      RFE-LR  -0.0008    1.0 -0.0124  0.0109  False\n",
            "     INFUSE SelectKBest  -0.0006    1.0 -0.0123  0.0111  False\n",
            "  LASSO-RFE         PCA   0.0034 0.9599 -0.0083  0.0151  False\n",
            "  LASSO-RFE      RFE-LR   0.0861    0.0  0.0744  0.0978   True\n",
            "  LASSO-RFE SelectKBest   0.0863    0.0  0.0746   0.098   True\n",
            "        PCA      RFE-LR   0.0827    0.0   0.071  0.0944   True\n",
            "        PCA SelectKBest   0.0828    0.0  0.0712  0.0945   True\n",
            "     RFE-LR SelectKBest   0.0002    1.0 -0.0115  0.0118  False\n",
            "--------------------------------------------------------------\n",
            "\n",
            "4. Tukey's HSD Test (PR-AUC)\n",
            "     Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
            "==============================================================\n",
            "   group1      group2   meandiff p-adj   lower   upper  reject\n",
            "--------------------------------------------------------------\n",
            "Autoencoder      INFUSE   0.1111    0.0  0.0946  0.1277   True\n",
            "Autoencoder   LASSO-RFE  -0.0207 0.0049 -0.0372 -0.0042   True\n",
            "Autoencoder         PCA  -0.0052 0.9449 -0.0218  0.0113  False\n",
            "Autoencoder      RFE-LR   0.0892    0.0  0.0727  0.1057   True\n",
            "Autoencoder SelectKBest   0.1097    0.0  0.0932  0.1262   True\n",
            "     INFUSE   LASSO-RFE  -0.1318    0.0 -0.1484 -0.1153   True\n",
            "     INFUSE         PCA  -0.1164    0.0 -0.1329 -0.0998   True\n",
            "     INFUSE      RFE-LR  -0.0219 0.0023 -0.0384 -0.0054   True\n",
            "     INFUSE SelectKBest  -0.0014 0.9999  -0.018  0.0151  False\n",
            "  LASSO-RFE         PCA   0.0155 0.0812  -0.001   0.032  False\n",
            "  LASSO-RFE      RFE-LR   0.1099    0.0  0.0934  0.1264   True\n",
            "  LASSO-RFE SelectKBest   0.1304    0.0  0.1139  0.1469   True\n",
            "        PCA      RFE-LR   0.0944    0.0  0.0779   0.111   True\n",
            "        PCA SelectKBest   0.1149    0.0  0.0984  0.1315   True\n",
            "     RFE-LR SelectKBest   0.0205 0.0057   0.004   0.037   True\n",
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            " SUMMARY: MEAN PERFORMANCE & SIGNIFICANCE \n",
            "------------------------------------------------------------\n",
            "        Method ROC-AUC Mean ROC-AUC Std PR-AUC Mean PR-AUC Std\n",
            "0       INFUSE       0.7025      0.0293      0.4126     0.0418\n",
            "1          PCA       0.6191      0.0282      0.2962     0.0358\n",
            "2  SelectKBest       0.7019      0.0240      0.4112     0.0363\n",
            "3    LASSO-RFE       0.6157      0.0336      0.2808     0.0479\n",
            "4       RFE-LR       0.7018      0.0306      0.3907     0.0455\n",
            "5  Autoencoder       0.6210      0.0267      0.3015     0.0362\n",
            "\n",
            "ðŸ” Significant Differences (p < 0.05) involving INFUSE:\n",
            "\n",
            "âœ… Experiment 2 completed. INFUSE's superiority is statistically validated against a comprehensive set of baselines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXPERIMENT 3: ABLATION STUDY â€“ COMPONENT IMPORTANCE ANALYSIS ---\n",
        "# This experiment evaluates the contribution of each INFUSE component by\n",
        "# running ablated versions of the model and comparing their performance.\n",
        "# It provides quantitative evidence for the necessity of each design choice.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"ðŸ§ª Starting Experiment 3: Ablation Study â€“ Component Importance\")\n",
        "\n",
        "# Assume X, y, and feature_names are already defined from preprocessing\n",
        "# If not, ensure you've run the full preprocessing pipeline first\n",
        "\n",
        "# ========================\n",
        "# CONFIGURATION\n",
        "# ========================\n",
        "n_runs = 50  # Number of Monte Carlo runs (reduced for faster execution)\n",
        "downstream_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define ablation variants\n",
        "ablations = {\n",
        "    'Full INFUSE': {},  # No changes\n",
        "    'No JSD Penalty': {'beta': 0.0},\n",
        "    'No Diversity Filter': {'jsd_threshold': 0.0},  # Bypass filtering\n",
        "    'No Graph Regularization': {'use_graph': False},  # Fuse all features\n",
        "    'ROC-AUC Stability': {'stability_metric': 'roc_auc'}  # Use ROC-AUC instead of PR-AUC\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results_df = pd.DataFrame(columns=['Run', 'Variant', 'ROC_AUC', 'PR_AUC'])\n",
        "\n",
        "# ========================\n",
        "# HELPER: Modified INFUSE Class for Ablation\n",
        "# ========================\n",
        "# We create a wrapper that modifies the INFUSE instance based on ablation settings\n",
        "def create_ablated_infuse(ablation_config, run_seed):\n",
        "    \"\"\"\n",
        "    Create an INFUSE instance with ablation settings applied.\n",
        "    \"\"\"\n",
        "    # Base INFUSE configuration\n",
        "    infuse = INFUSE(\n",
        "        k_seeds=20,\n",
        "        alpha=0.6,\n",
        "        beta=0.2,\n",
        "        jsd_threshold=0.35,\n",
        "        final_k=2,\n",
        "        n_bootstrap=50,\n",
        "        stability_thresh=0.2,\n",
        "        max_features=1000,\n",
        "        imputation_strategy='median',\n",
        "        stability_metric='pr_auc',  # Default\n",
        "        verbose=False,\n",
        "        random_state=run_seed\n",
        "    )\n",
        "\n",
        "    # Apply ablation settings\n",
        "    if 'beta' in ablation_config:\n",
        "        infuse.beta = ablation_config['beta']\n",
        "    if 'jsd_threshold' in ablation_config:\n",
        "        infuse.jsd_threshold = ablation_config['jsd_threshold']\n",
        "    if 'stability_metric' in ablation_config:\n",
        "        infuse.stability_metric = ablation_config['stability_metric']\n",
        "\n",
        "    # Monkey-patch _cohort_fusion to bypass graph if requested\n",
        "    if ablation_config.get('use_graph', True) is False:\n",
        "        original_graph_reg = infuse._graph_regularization\n",
        "        infuse._graph_regularization = lambda X, seeds: np.ones((X.shape[1], X.shape[1]))  # Fully connected\n",
        "\n",
        "    return infuse\n",
        "\n",
        "# ========================\n",
        "# RUN ABLATION EXPERIMENT\n",
        "# ========================\n",
        "for run in range(n_runs):\n",
        "    if run % 10 == 0:\n",
        "        print(f\"  Running iteration {run}/{n_runs}...\")\n",
        "\n",
        "    # --- 1. Apply Data Perturbation ---\n",
        "    X_perturbed = X + np.random.normal(0, 0.05, X.shape)\n",
        "    indices = np.random.choice(X_perturbed.shape[0], int(0.9 * X_perturbed.shape[0]), replace=True)\n",
        "    X_sub = X_perturbed[indices]\n",
        "    y_sub = y[indices]\n",
        "\n",
        "    # --- 2. Run Each Ablated Variant ---\n",
        "    run_data = []\n",
        "    for variant_name, config in ablations.items():\n",
        "        try:\n",
        "            # Create ablated INFUSE instance\n",
        "            infuse_ablated = create_ablated_infuse(config, run_seed=42 + run)\n",
        "\n",
        "            # Fit and transform\n",
        "            Z_ablated = infuse_ablated.fit_transform(X_sub, y_sub, feature_names=feature_names)\n",
        "\n",
        "            # Evaluate downstream performance\n",
        "            if Z_ablated.size > 0:\n",
        "                cv_results = cross_validate(\n",
        "                    downstream_model, Z_ablated, y_sub,\n",
        "                    cv=cv, scoring=['roc_auc', 'average_precision'], n_jobs=-1\n",
        "                )\n",
        "                auc_roc = cv_results['test_roc_auc'].mean()\n",
        "                pr_auc = cv_results['test_average_precision'].mean()\n",
        "            else:\n",
        "                auc_roc = 0.5\n",
        "                pr_auc = np.mean(y_sub)  # No-skill PR-AUC\n",
        "\n",
        "        except Exception as e:\n",
        "            # On failure, assign baseline\n",
        "            auc_roc = 0.5\n",
        "            pr_auc = 0.5\n",
        "            if run < 5:  # Only print first few errors\n",
        "                print(f\"    âŒ {variant_name} failed: {e}\")\n",
        "\n",
        "        # Record result\n",
        "        run_data.append({\n",
        "            'Run': run,\n",
        "            'Variant': variant_name,\n",
        "            'ROC_AUC': auc_roc,\n",
        "            'PR_AUC': pr_auc\n",
        "        })\n",
        "\n",
        "    # Append to results\n",
        "    results_df = pd.concat([results_df, pd.DataFrame(run_data)], ignore_index=True)\n",
        "\n",
        "# ========================\n",
        "# STATISTICAL ANALYSIS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" EXPERIMENT 3 RESULTS: ABLATION STUDY \")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Repeated-Measures ANOVA for ROC-AUC\n",
        "print(\"\\n1. Repeated-Measures ANOVA (ROC-AUC)\")\n",
        "anova_roc = AnovaRM(results_df, 'ROC_AUC', 'Run', ['Variant']).fit()\n",
        "print(anova_roc.summary())\n",
        "\n",
        "# 2. Repeated-Measures ANOVA for PR-AUC\n",
        "print(\"\\n2. Repeated-Measures ANOVA (PR-AUC)\")\n",
        "anova_pr = AnovaRM(results_df, 'PR_AUC', 'Run', ['Variant']).fit()\n",
        "print(anova_pr.summary())\n",
        "\n",
        "# 3. Tukey's HSD Test for ROC-AUC\n",
        "print(\"\\n3. Tukey's HSD Test (ROC-AUC)\")\n",
        "tukey_roc = pairwise_tukeyhsd(results_df['ROC_AUC'], results_df['Variant'], alpha=0.05)\n",
        "print(tukey_roc.summary())\n",
        "\n",
        "# 4. Tukey's HSD Test for PR-AUC\n",
        "print(\"\\n4. Tukey's HSD Test (PR-AUC)\")\n",
        "tukey_pr = pairwise_tukeyhsd(results_df['PR_AUC'], results_df['Variant'], alpha=0.05)\n",
        "print(tukey_pr.summary())\n",
        "\n",
        "# ========================\n",
        "# VISUALIZATION\n",
        "# ========================\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ROC-AUC Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=results_df, x='Variant', y='ROC_AUC', palette='Set3')\n",
        "plt.title('Downstream ROC-AUC Across Ablated Variants\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('ROC-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "# PR-AUC Boxplot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(data=results_df, x='Variant', y='PR_AUC', palette='Set3')\n",
        "plt.title('Downstream PR-AUC Across Ablated Variants\\n(Monte Carlo Simulation)')\n",
        "plt.ylabel('PR-AUC')\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================\n",
        "# SUMMARY TABLE\n",
        "# ========================\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\" SUMMARY: MEAN PERFORMANCE BY VARIANT \")\n",
        "print(\"-\"*60)\n",
        "\n",
        "summary_data = []\n",
        "for variant in ablations.keys():\n",
        "    subset = results_df[results_df['Variant'] == variant]\n",
        "    summary_data.append({\n",
        "        'Variant': variant,\n",
        "        'ROC-AUC Mean': f\"{subset['ROC_AUC'].mean():.4f}\",\n",
        "        'ROC-AUC Std': f\"{subset['ROC_AUC'].std():.4f}\",\n",
        "        'PR-AUC Mean': f\"{subset['PR_AUC'].mean():.4f}\",\n",
        "        'PR-AUC Std': f\"{subset['PR_AUC'].std():.4f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df)\n",
        "\n",
        "# Highlight significant comparisons with Full INFUSE\n",
        "print(\"\\nðŸ” Significant Differences (p < 0.05) vs Full INFUSE:\")\n",
        "for row in tukey_roc.summary().data[1:]:\n",
        "    if row[5] == 'True' and 'Full INFUSE' in row[0]:\n",
        "        print(f\"  ROC-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "    elif row[5] == 'True' and 'Full INFUSE' in row[1]:\n",
        "        print(f\"  ROC-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "\n",
        "for row in tukey_pr.summary().data[1:]:\n",
        "    if row[5] == 'True' and 'Full INFUSE' in row[0]:\n",
        "        print(f\"  PR-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "    elif row[5] == 'True' and 'Full INFUSE' in row[1]:\n",
        "        print(f\"  PR-AUC: {row[0]} vs {row[1]}: p = {row[4]:.3f}\")\n",
        "\n",
        "print(\"\\nâœ… Experiment 3 completed. Ablation study validates the necessity of INFUSE's key components.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QA33JbeqsP8I",
        "outputId": "5fd4a225-3e34-4d83-da6e-e401e37e46e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Starting Experiment 3: Ablation Study â€“ Component Importance\n",
            "  Running iteration 0/50...\n",
            "  Running iteration 10/50...\n",
            "  Running iteration 20/50...\n",
            "  Running iteration 30/50...\n",
            "  Running iteration 40/50...\n",
            "\n",
            "============================================================\n",
            " EXPERIMENT 3 RESULTS: ABLATION STUDY \n",
            "============================================================\n",
            "\n",
            "1. Repeated-Measures ANOVA (ROC-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "        F Value Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Variant  5.4071 4.0000 196.0000 0.0004\n",
            "======================================\n",
            "\n",
            "\n",
            "2. Repeated-Measures ANOVA (PR-AUC)\n",
            "                Anova\n",
            "======================================\n",
            "        F Value Num DF  Den DF  Pr > F\n",
            "--------------------------------------\n",
            "Variant  6.8837 4.0000 196.0000 0.0000\n",
            "======================================\n",
            "\n",
            "\n",
            "3. Tukey's HSD Test (ROC-AUC)\n",
            "                 Multiple Comparison of Means - Tukey HSD, FWER=0.05                 \n",
            "=====================================================================================\n",
            "         group1                  group2         meandiff p-adj   lower  upper  reject\n",
            "-------------------------------------------------------------------------------------\n",
            "            Full INFUSE     No Diversity Filter   0.0072   0.73 -0.0088 0.0233  False\n",
            "            Full INFUSE No Graph Regularization  -0.0043 0.9494 -0.0203 0.0118  False\n",
            "            Full INFUSE          No JSD Penalty  -0.0031  0.985 -0.0191  0.013  False\n",
            "            Full INFUSE       ROC-AUC Stability   0.0024 0.9939 -0.0137 0.0185  False\n",
            "    No Diversity Filter No Graph Regularization  -0.0115 0.2856 -0.0276 0.0046  False\n",
            "    No Diversity Filter          No JSD Penalty  -0.0103 0.3998 -0.0264 0.0058  False\n",
            "    No Diversity Filter       ROC-AUC Stability  -0.0048 0.9233 -0.0209 0.0113  False\n",
            "No Graph Regularization          No JSD Penalty   0.0012 0.9996 -0.0149 0.0173  False\n",
            "No Graph Regularization       ROC-AUC Stability   0.0067 0.7834 -0.0094 0.0228  False\n",
            "         No JSD Penalty       ROC-AUC Stability   0.0055 0.8826 -0.0106 0.0216  False\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "4. Tukey's HSD Test (PR-AUC)\n",
            "                 Multiple Comparison of Means - Tukey HSD, FWER=0.05                 \n",
            "=====================================================================================\n",
            "         group1                  group2         meandiff p-adj   lower  upper  reject\n",
            "-------------------------------------------------------------------------------------\n",
            "            Full INFUSE     No Diversity Filter   0.0141 0.3452 -0.0068  0.035  False\n",
            "            Full INFUSE No Graph Regularization  -0.0025 0.9974 -0.0234 0.0184  False\n",
            "            Full INFUSE          No JSD Penalty  -0.0029 0.9957 -0.0237  0.018  False\n",
            "            Full INFUSE       ROC-AUC Stability   0.0033 0.9921 -0.0175 0.0242  False\n",
            "    No Diversity Filter No Graph Regularization  -0.0166 0.1884 -0.0375 0.0043  False\n",
            "    No Diversity Filter          No JSD Penalty   -0.017 0.1717 -0.0378 0.0039  False\n",
            "    No Diversity Filter       ROC-AUC Stability  -0.0107 0.6199 -0.0316 0.0101  False\n",
            "No Graph Regularization          No JSD Penalty  -0.0003    1.0 -0.0212 0.0205  False\n",
            "No Graph Regularization       ROC-AUC Stability   0.0059 0.9381  -0.015 0.0268  False\n",
            "         No JSD Penalty       ROC-AUC Stability   0.0062 0.9248 -0.0147 0.0271  False\n",
            "-------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            " SUMMARY: MEAN PERFORMANCE BY VARIANT \n",
            "------------------------------------------------------------\n",
            "                   Variant ROC-AUC Mean ROC-AUC Std PR-AUC Mean PR-AUC Std\n",
            "0              Full INFUSE       0.7040      0.0257      0.4067     0.0340\n",
            "1           No JSD Penalty       0.7010      0.0288      0.4038     0.0356\n",
            "2      No Diversity Filter       0.7113      0.0256      0.4208     0.0383\n",
            "3  No Graph Regularization       0.6998      0.0370      0.4042     0.0452\n",
            "4        ROC-AUC Stability       0.7065      0.0276      0.4100     0.0358\n",
            "\n",
            "ðŸ” Significant Differences (p < 0.05) vs Full INFUSE:\n",
            "\n",
            "âœ… Experiment 3 completed. Ablation study validates the necessity of INFUSE's key components.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPci5qU3fdNmgpJpDCpORsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}