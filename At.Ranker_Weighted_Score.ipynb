{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO4wkJbQ6y3LQYXz8/+pm1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfDee92/Cancer-3IPMLM/blob/main/At.Ranker_Weighted_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyZSmzVgpuoW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranker- The model that ranks article based on researcher defined weights of the relevance of words in the titile and abstract.\n",
        "\n",
        "Download your articles based on your research using specific search string from relevant database(s). Deduplicate to remove inherent cross-database redundancy. Then load into Ranker applying your defined weights based on the importance or relevance of specific words/tests, and Ranker will automatically apply your defined weights based on selected workds of relevance to your study. With this, it is easier to have higher precision in study Quality Assessemnt."
      ],
      "metadata": {
        "id": "TjAw9E5Vpvlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "from typing import Dict, Optional, Sequence, Union, Iterable\n",
        "\n",
        "# ---- Utility: detect likely text and year columns ----\n",
        "def detect_columns(df: pd.DataFrame):\n",
        "    # Detect text-like columns: those with longer string values\n",
        "    text_candidates = []\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object or pd.api.types.is_string_dtype(df[col]):\n",
        "            avg_len = df[col].dropna().astype(str).map(len).mean() if not df[col].dropna().empty else 0\n",
        "            if avg_len > 5:  # heuristic: exclude IDs/codes\n",
        "                text_candidates.append(col)\n",
        "    # Use all candidate text columns if found\n",
        "    text_cols = text_candidates if text_candidates else [df.columns[0]]\n",
        "\n",
        "    # Detect a likely year column\n",
        "    year_col = None\n",
        "    for col in df.columns:\n",
        "        if re.search(r'year', col, flags=re.IGNORECASE):\n",
        "            year_col = col\n",
        "            break\n",
        "    return text_cols, year_col\n",
        "\n",
        "# ---- Weighted ranking function (tidied from above) ----\n",
        "def rank_and_filter(\n",
        "    df: pd.DataFrame,\n",
        "    weights: Dict[str, float],\n",
        "    text_cols: Union[str, Sequence[str]],\n",
        "    year_col: Optional[str] = None,\n",
        "    core_keywords: Optional[Iterable[str]] = None,\n",
        "    score_col: str = \"Weighted_Score\",\n",
        "    exclude_threshold: Optional[float] = 2.0,\n",
        "    guard_threshold: Optional[float] = 4.0,\n",
        ") -> pd.DataFrame:\n",
        "    def _norm(s: object) -> str:\n",
        "        s = \"\" if s is None or (isinstance(s, float) and pd.isna(s)) else str(s)\n",
        "        s = unicodedata.normalize(\"NFKC\", s).lower()\n",
        "        return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "    if isinstance(text_cols, str):\n",
        "        text_cols = [text_cols]\n",
        "    text = df[text_cols].astype(str).applymap(_norm).agg(\" \".join, axis=1)\n",
        "\n",
        "    flags = re.IGNORECASE\n",
        "    compiled = [(re.compile(rf\"\\b{re.escape(k)}\\b\", flags), float(w)) for k, w in weights.items()]\n",
        "\n",
        "    score = pd.Series(0.0, index=text.index)\n",
        "    for pat, w in compiled:\n",
        "        score += text.str.count(pat) * w\n",
        "    df_out = df.copy()\n",
        "    df_out[score_col] = score\n",
        "\n",
        "    # Core keyword hits\n",
        "    core_hit = None\n",
        "    if core_keywords:\n",
        "        core_patterns = [re.compile(rf\"\\b{re.escape(k)}\\b\", flags) for k in core_keywords]\n",
        "        core_counts = sum(text.str.count(p) for p in core_patterns)\n",
        "        core_hit = core_counts.gt(0)\n",
        "        df_out[\"CoreHit\"] = core_hit\n",
        "\n",
        "    # Deterministic filter flags\n",
        "    if exclude_threshold is not None or guard_threshold is not None:\n",
        "        keep_mask = pd.Series(True, index=df_out.index)\n",
        "        if exclude_threshold is not None:\n",
        "            keep_mask &= df_out[score_col].gt(exclude_threshold)\n",
        "        if guard_threshold is not None and core_hit is not None:\n",
        "            guard_mask = df_out[score_col].gt(guard_threshold) | core_hit\n",
        "            keep_mask &= guard_mask\n",
        "        df_out[\"PreFilter_Keep\"] = keep_mask\n",
        "\n",
        "    # Sort\n",
        "    if year_col is not None and year_col in df_out.columns:\n",
        "        df_out = (\n",
        "            df_out.assign(_year_sort=pd.to_numeric(df_out[year_col], errors=\"coerce\"))\n",
        "                  .sort_values([score_col, \"_year_sort\"], ascending=[False, False])\n",
        "                  .drop(columns=\"_year_sort\")\n",
        "        )\n",
        "    else:\n",
        "        df_out = df_out.sort_values(score_col, ascending=False)\n",
        "    return df_out.reset_index(drop=True)\n",
        "\n",
        "# ---- End-to-end runner ----\n",
        "def process_file(\n",
        "    file_path: str,\n",
        "    weights: Dict[str, float],\n",
        "    core_keywords: Optional[Iterable[str]] = None,\n",
        "    output_path: Optional[str] = None\n",
        "):\n",
        "    # Load\n",
        "    ext = os.path.splitext(\"/content/Camera Ready Final SLR.xlsx\")[1].lower()\n",
        "    if ext in [\".csv\", \".txt\"]:\n",
        "        df = pd.read_csv(file_path)\n",
        "    elif ext in [\".xlsx\", \".xls\"]:\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Use CSV or Excel.\")\n",
        "\n",
        "    # Detect columns\n",
        "    text_cols, year_col = detect_columns(df)\n",
        "    print(f\"Detected text columns: {text_cols}, year column: {year_col}\")\n",
        "\n",
        "    # Rank & filter\n",
        "    ranked = rank_and_filter(df, weights=weights, text_cols=text_cols,\n",
        "                             year_col=year_col, core_keywords=core_keywords)\n",
        "\n",
        "    # Save\n",
        "    if output_path is None:\n",
        "        base, ext = os.path.splitext(file_path)\n",
        "        output_path = f\"{base}_ranked.csv\"\n",
        "    ranked.to_csv(output_path, index=False)\n",
        "    print(f\"Saved ranked file to: {output_path}\")\n",
        "    return ranked\n",
        "\n",
        "# ---- Example usage ----\n",
        "if __name__ == \"__main__\":\n",
        "    weights = {\n",
        "        \"multi-omics\": 3,\n",
        "        \"integration\": 3,\n",
        "        \"transcriptomic\": 3,\n",
        "        \"multi-omics\": 2,\n",
        "        \"Bayesian\": 2,\n",
        "        \"deep learning\": 2\n",
        "    }\n",
        "    core_keywords = [\"pan-cancer\", \"multi-cancer\"]\n",
        "    ranked_df = process_file(\"/content/Camera Ready Final SLR.xlsx\", weights, core_keywords)\n",
        "    print(ranked_df.head(30))\n"
      ],
      "metadata": {
        "id": "odqycOCEpvzP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}